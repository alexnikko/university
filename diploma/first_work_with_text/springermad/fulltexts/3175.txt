Introduction
The United States Food and Drug Administration (FDA) released landmark documents to guide the manufacturing practices of pharmaceutical companies in 2004. The central document is entitled “Pharmaceutical Current Good Manufacturing Practices (CGMPs) for the 21st Century—A Risk-Based Approach [ ].” The objective of this document was to modernize regulation of the pharmaceutical industry. This would be accomplished, in part, by encouraging the incorporation of new quality management techniques and emerging quality assurance technologies. The specifics regarding implementation of emerging technologies were described by the FDA’s document entitled “Guidance for Industry: PAT—A Framework for Innovative Pharmaceutical Development, Manufacturing, and Quality Assurance [ ].” The PAT guidance offers direction regarding the implementation of process analytical technology (PAT) as a means of designing and developing well-understood processes to ensure predefined quality at the end of a manufacturing process. Such procedures are based on the tenets of quality by design (QbD). Similarly, the International Council for Harmonization of Technical Requirements for Pharmaceuticals for Human Use (ICH) released an initial draft of “ICH Q8: Pharmaceutical Development [ ].” This document echoes many of the principles in the FDA guidance. Recently, the European Medicines Agency (EMA) released an updated guidance on the use of NIRS procedures in the pharmaceutical industry, directly referencing ICH Q8, Q9, and Q10 [ ]. Together, these documents facilitate the industry’s efforts to provide quality pharmaceuticals to the public.
The pharmaceutical industry has demonstrated a typically conservative approach in its integration of PAT into routine manufacturing. This is in part due to the significant regulatory concerns inherent to the manufacturing of high-risk products such as medications. Also, in general, the industry required additional investments in infrastructure to support PAT systems. In addition to infrastructure, PAT methods require a significant amount of practical, application-specific research to support the development, implementation, and maintenance of these modern techniques.
Spectroscopic methods are commonly used in PAT applications for in-line, on-line, and at-line applications. These methods have been widely applied to assure product quality [ , ]. Spectroscopic PAT is of particular interest to the pharmaceutical industry due to the potential for non-destructive analysis coupled with high throughput. The specific methodology discussed in this work is transmission Raman spectroscopy for the quantification of active pharmaceutical ingredient (API) concentration within solid oral dosage forms. Transmission Raman spectroscopy (TRS) is typically regarded as having minimal sensitivity to physical changes and interference from water, and for offering highly specific signals for most small organic molecules [ ]. Readily discernable spectral peaks that can be assigned to specific functional groups are an additional advantage of Raman spectroscopy. This provides the opportunity for suitable quantitative model performance in pharmaceutical analysis. However, quantitative Raman spectroscopy is hindered by fluorescence effects that have the potential to overwhelm useful signal [ ].
Quantitative predictions based on Raman spectroscopy often require multivariate models [ , ]. These models are developed using data collected from carefully designed samples. Partial least squares (PLS) is a commonly used technique for multivariate model development. However, PLS models are sensitive to uncorrelated variance in spectra that can lead to reduced model performance. An example of uncorrelated variance is spectroscopic shapes introduced via different spectrometers. Thus, when a model is transferred from one spectrometer to another, model performance can suffer.
Analytical spectra, including Raman spectra, include both signal and noise. The noise portion of a signal contributes unwanted information. Pelletier described root causes of noise in Raman spectroscopy. They were separated into three sources: sample, spectrometer, and operator [ , ].
Instrument-generated noise depends largely on instrument design. Its sources include detector noise such as thermal noise, wavenumber dependence of quantum efficiency, and read noise [ ]. Drift in wavenumber or intensity axis calibration adds noise to Raman spectra that can be important for repetitive measurements and for the long-term stability of analytical models.
Sources of instrumental error have been explored by other researchers. The effects of laser power, instrument variability, sample homogeneity, and over-all method error on the quantitative analysis of crystallinity have been previously studied [ ]. The results showed that laser power and instrument variability were small sources of error but nevertheless present. Other researchers have demonstrated that laser spot size variability can lead to increases in predication variance due to differences in the volume of integration [ ]. Research has also been conducted to explore what effect different irradiance patterns had on quantitative measurements of intact immediate release tablets [ ]. Results demonstrated that the area of irradiation is related to the magnitude of error and linked to the uniformity of the test sample.
Successful multivariate calibration model transfer minimizes prediction error for transferred models. In ideal cases, method transfer does not require significant mathematical manipulation to facilitate calibration transfer between instruments; in such situations, the preprocessing used to optimize model performance can effectively mitigate inter-instrument variability. This allows for the calibration from the first instrument to be simply copied to a second instrument. This is referred to as a direct calibration transfer. This type of strategy, as reviewed by Feudale et al., can be considered a “nonstandardization method” for calibration transfer [ ].
The use of a global model is an alternative approach to calibration transfer that may be more suitable when instrument-to-instrument performance variability is anticipated. This approach seeks to incorporate the variance associated with the transfer into the data used for calibration model development. A global modeling approach relies on collecting calibration data that reflects, as well as possible, all future sources of variance [ ]. This can be achieved by including calibration data from different instruments at unique sites over different seasons to introduce the expected variability arising from instruments and potential differences in the operating conditions from site-to-site.
This study sought to compare two approaches for the transfer of a multivariate quantitative method for determining acetaminophen, as a model API, in tablets. Direct transfer:
Data from one instrument is used to calculate a model. The model is then used on the second instrument without modification. Global calibration:
Data from both instruments is used to calculate a model.
The direct transfer approach utilized conventional preprocessing methods to mitigate interfering variance, thus focusing the model on the analyte of interest. Root-mean-square errors (RMSEs) were calculated for both methods, and the results were compared using a modified t test.
This work provides an example of the transfer of a quantitative Raman calibration model between two spectrometers located in distinct locations.
Methods and Materials
Materials
The study involved a six component system consisting of the model API, acetaminophen, and the following excipients: Aerosil (silicon dioxide, SiO 2 ), magnesium stearate (MgSt), Avicel (microcrystalline cellulose, MCC), calcium diphosphate (DiTab), and lactose. Acetaminophen was purchased from Mallinckrodt Pharmaceuticals (Damastown, Mulhuddart, Dublin, Ireland). Aerosil (Evonik, Parsippany, NJ) and MgSt were purchased from Spectrum (Henderson, NV). MCC was received from FMC Biopolymer (Philadelphia, PA). DiTab was purchased from Himed (Old Bethpage, NY). All materials were used as received.
Sample Preparation
The design employed a central composite design (CCD). These designs are more efficient than full factorial or mixture designs in terms of the number of samples. The CCD incorporates a two-level full factorial design, augmented with axial points thus improving the estimation of the curvature. An advantage of CCDs is that they can be performed sequentially; wherein the axial points and center can be augmented to estimate and reduce the effect of the curvature [ , ].
The test set was inscribed within the circumscribed calibration set (Fig. 1 ; calibration—blue filled circles; test—red open circles) [ ]. Three factors (acetaminophen, lactose, and MCC concentrations) were varied across five levels (24.95, 27.00, 30.00, 33.00, and 35.05, all as % w / w ). Acetominophen was first preblended for 20 min with Aerosil to improve flow. The remaining materials for each design point in Tables 1 and 2 were weighed on a lab balance (Data Range, Model AX504DR, Mettler Toledo, Columbus, OH, USA) to a target mass of 10 g and transferred into 40 mL plastic vials. The materials within the vials were mixed for 20 min at 15 rpm in a retrofitted bin blender (L.B. Bohle, Ennigerloh, Germany). Fig. 1 Calibration used a circumscribed central composite design (CCD) to define the variance in API and excipient concentrations (% w / w ). Calibration—blue filled circles; test—red open circles Table 1 Calibration set concentrations (%, w / w ) Design point APAP SiO2 MCC LACT DiTab MgSt 1 27.00 0.22 27.00 27.00 18.28 0.50 2 27.00 0.22 27.00 33.00 12.28 0.50 3 27.00 0.22 33.00 27.00 12.28 0.50 4 27.00 0.22 33.00 33.00 6.28 0.50 5 33.00 0.27 27.00 27.00 12.23 0.50 6 33.00 0.27 27.00 33.00 6.23 0.50 7 33.00 0.27 33.00 27.00 6.23 0.50 8 33.00 0.27 33.00 33.00 0.23 0.50 9 24.95 0.21 30.00 30.00 14.34 0.50 10 35.05 0.29 30.00 30.00 4.16 0.50 11 30.00 0.25 24.95 30.00 14.30 0.50 12 30.00 0.25 35.05 30.00 4.20 0.50 13 30.00 0.25 30.00 24.95 14.30 0.50 14 30.00 0.25 30.00 35.05 4.20 0.50 15 30.00 0.25 30.00 30.00 9.25 0.50 Table 2 Test set concentrations (%, w / w ) Design point APAP SiO2 MCC LACT DiTab MgSt 1 28.22 0.24 28.22 28.22 14.62 0.50 2 28.22 0.24 28.22 31.78 11.05 0.50 3 28.22 0.24 31.78 28.22 11.05 0.50 4 28.22 0.24 31.78 31.78 7.48 0.50 5 31.78 0.26 28.22 28.22 11.02 0.50 6 31.78 0.26 28.22 31.78 7.45 0.50 7 31.78 0.26 31.78 28.22 7.45 0.50 8 31.78 0.26 31.78 31.78 3.88 0.50 9 27.00 0.22 30.00 30.00 12.28 0.50 10 33.00 0.27 30.00 30.00 6.23 0.50 11 30.00 0.25 27.00 30.00 12.25 0.50 12 30.00 0.25 33.00 30.00 6.25 0.50 13 30.00 0.25 30.00 27.00 12.25 0.50 14 30.00 0.25 30.00 33.00 6.25 0.50 15 30.00 0.25 30.00 30.00 9.25 0.50
Test and calibration tablets were manufactured using an automatic, single-stage, Carver Press (Model #:3887 Wabash, IN) and a 13-mm right cylindrical die from the previously designed blends. Nine tablets were compressed at each design point for the calibration set. Six tablets were made at each design point for the test set. The 15 calibration design points were compacted at three applied loads (1814, 2267, and 2721 kg) in triplicate, at each compression force, for a total of 135 calibration tablets. Test tablets were also compressed in triplicate using forces between the calibrations (2041 and 2494 kg) resulting in 90 test tablets. The target tablet mass was 400 mg. Triplicate samples were created to capture inter-tablet variability.
Transmission Raman Spectroscopy
In the present study, the goal was to isolate calibration transfer challenges to those related to the differences in spectrometers by minimizing the error contributed from sample and operator factors. Potential sample factors were addressed through timely shipping of original samples. This minimized chemical and physical changes to the sample between measurement locations and spectrometers. A comprehensive experimental protocol included equivalent instrument settings and automated sampling to minimized operator error.
Tablets were first scanned at location A (Pittsburgh, PA, USA) and subsequently shipped to location B (New Brunswick, NJ, USA) for data collection. Transmission Raman spectra were collected using two equivalently configured Cobalt TRS100 instruments (Oxfordshire, UK). Specifically, the settings for spectral collection were standardized as follows, power setting for the laser was 0.5 W, exposure time was 0.5 s, the number of accumulations was 45, the spot size was 4 mm, and the collection optics were set to medium. The collected spectra ranged from 39 to 2422 cm −1 .
HPLC
Acetaminophen reference values for all compacts were determined using high-pressure liquid chromatography (HPLC; Waters Alliance 2790, Milford, MA, USA), followed by UV detection (Waters 2487). Reference testing was performed after all tablets were scanned. The time between final tablet scanning and HPLC performance was within a stable 2-month period [ ].
A method modified from USP monograph 29 (acetaminophen tablets) was employed. A 4.6-mm, 3-μm, C18 column was used with a water: methanol: acetic acid (80: 17: 3) mobile phase. The detection wavelength was 243 nm. Working standards were diluted with water to a concentration range from 0.01 to 2.0 mg/mL with an injection volume of 10 μL. The error of the laboratory was estimated to be 0.917% w / w .
PLS Model Development
Modeling of the data was performed using PLS in MATLAB (v. R2011a, The MathWorks, Natick, MA, USA) running Eigenvector PLS_Toolbox (v. 6.2, Eigenvector Research, Inc., Manson, WA, USA) using the SIMPLS algorithm [ ]. Preprocessing and latent variable selection was refined on the basis of minimizing the root mean square error of calibration (RMSEC) and cross-validation (RMSECV). Cross validation (CV) was performed using a randomized subset method where the CV set was made up of ten samples per split and was performed over five iterations. Transferability of a given model was assessed by comparing the root mean square error of prediction (RMSEP) and bias of the model for the two spectrometers. RMSE was calculated using Eq. 1 . In the equation, y i is the measured acetaminophen concentration, \( {\widehat{y}}_{\mathrm{i}} \) is the predicted acetaminophen concentration, p is the number of latent variables, and n is the number of samples. $$ \mathrm{RMSE}=\sqrt{\frac{\sum_{\mathrm{i}=1}^{\mathrm{n}}{\left({\widehat{y}}_{\mathrm{i}}-{y}_{\mathrm{i}}\right)}^2}{n-1-p}} $$ (1)
Model Construction, Transfer, and Comparison
Three models were constructed for this study. First, a model (A) was generated using calibration tablet spectra collected at the same location where the tablets were manufactured (location A). Next, a second model (B) was calibrated using spectra collected from the previous instrument at location B was generated. The third, “global” model (G) was constructed by combining calibration spectra from the two instruments into one calibration model. The test samples were analyzed in the same manner at both locations. Test spectra were used only for evaluation of model performance and not model development. Reference data for calibration and test sets were determined via HPLC after spectral collection was completed at the two sites. Direct calibration transfer was facilitated using only preprocessing techniques.
Model performance comparisons were made using the test sets from each instrument were used to evaluate how well a model performed in a transfer scenario after calibration models were constructed. The first model (A) was evaluated using test spectra from instruments A and B separately. This procedure was also performed for models B and G.
In this study, modeling efforts required an evaluation method for the mitigation of peak shift. Two separate techniques were used to investigate the significance of the wavenumber shift regarding method transferability. One technique was zero padding the wavenumber axis on a single instrument. This technique allowed for wavenumber corrections to be applied on the order of the data’s spectral resolution. The other technique employed the “alignspectra” command in PLS_Toolbox® which uses a windowed approach to locate the max values of a reference spectra and identify them as peaks. The observed maxima of test spectra were compared to the expected peak locations, and the differences are fitted using a spline interpolation algorithm. In this way, the frequency shift corrections outside of the spectral resolution could be applied. The factors of this method were optimized using a routine that minimized the mean differential spectra between instruments.
The ultimate transferability of models was compared primarily based on RMSEP comparison using a method outlined by Fearn for the comparison of models created using different prediction methods [ , ]. This method compares models by separating the RMSEP into the standard error of prediction ( SEP ) and bias . Specifically, a confidence interval (CI) is calculated for the difference in bias, and the ratio of SEPs. Biases were considered statistically equivalent when the 95% CI for the difference in biases of the two models contained 0. The SEPs were considered statistically equivalent when the 95% CI corresponding to the ratio of SEPs for two models contained 1. The Bonferroni method was used to adjust the critical t value to mitigate the probability of a Type 1 error following multiple comparisons.
Results and Discussion
Spectral Response
The spectral features observed on individual instruments were similar based on a comparison of the mean spectra. This was expected given the use of identical samples, a minimal lag time between data collection at the different locations and by using two spectrometers. A single mean calibration spectrum, after preprocessing, is illustrated in Fig. 2 . Spectral features of acetaminophen dominate the mean spectra; the Raman signal of the other constituents was comparatively weak. Fig. 2 I Spectrum of pure acetaminophen and II mean calibration spectrum from instrument A
Investigations were performed to characterize the differences in spectral responses between the instruments. Peak intensity differences were evident upon initial examination. The identification of subtle differences was performed through principal component analysis (PCA), where calibration spectra from instrument A was augmented with test spectra from instrument B (see “ PLS Model Development ” section for truncation and preprocessing description). The PCA scores were completely separated according to instrumental origin by the first principal component (PC) when conventional Raman preprocessing was applied (i.e., normalization, baseline removal, mean centering). This first PC was largely defined by first derivative shapes (see Fig. 3 ; lowest plot). This indicates a systemic wavenumber shift between the instruments. The selected windows in Fig. 3 show that the magnitude of the peak shift was on average 0.8 cm −1 . This value was 25% of the spectral resolution (i.e., 3 cm −1 ). Therefore, the utility of zero padding was limited by the resolution of the spectra. Fig. 3 The black data in the lowest plot is the difference in mean spectral responses from instruments A and B using from the calibration and test samples, respectively. The gray data below the black data in this plot is the first PC of a data set consisting of calibration samples from instrument A that have been augmented with the test samples from instrument B. The plot above is the overlaid mean spectral data of calibration samples from instrument A and test samples from instrument B after conventional Raman preprocessing (i.e., normalization followed by mean centering)
Studies were performed to assess model robustness to peak shifts. This was accomplished by using the PLS model from instrument A to predict the artificially peak shifted test spectra of instrument A (the magnitude of the shift was up to the spectral resolution). The magnitude of the shift required to cause a significant difference in model performance was roughly half the spectral resolution (data not shown). Therefore, specific wavenumber shift corrections were not necessary. This is advantageous, as additional steps in the calibration transfer process are to be avoided when possible.
Diagnostic Statistics
When PLS modeling was performed using calibration spectra from a single instrument and test spectra from the alternative instrument, Hotelling’s T 2 values for the test set were within the 95% CI for the calibration samples (interval calculated using f -distribution and values from the calibration). However, the resulting Q residuals for the test spectra were outside the 95% CI for the calibration samples. This jeopardizes the conventional Q residuals use for the qualification of incoming spectra for prediction (i.e., this statistic summarizes the amount of unmodeled information in a spectrum). This is unless a unique Q residual range was established for each instrument. Alternatively, the qualification of incoming samples could be performed using PCA classification. When principal component analysis was used to decompose calibration spectra from instrument A and test spectra from instrument B, the selected pretreatments moved the PCA test scores to the center of the calibration space (Fig. 4 ). Thus, assuring the reliability for the transferred model could be aided by checking that each incoming spectrum lies within the same PC score space as the calibration samples. Fig. 4 Distribution of calibration PCA scores from instrument A and prediction scores from instrument B before pretreatment ( a ) and after pretreatment ( b )
An approach to maintain the utility of the Q residual was explored. Peak shift corrections were performed following interval PLS (iPLS) on test samples that were analyzed on an independent instrument [ ]. Here, iPLS served to facilitate peak correction efforts by a cross-validation performance-based selection of spectral intervals. Following the adjustment for peak shifts, the Q residuals of the test samples were shifted inside the 95% CI for the calibration samples (data not shown). However, the shifted data resulted in a 10% increase in the RMSEP in both directly transferred scenarios. Therefore, it was not considered a viable option.
PLS Model Development
Spectral pretreatments were determined based on visual inspection of the spectra and the results from RMSECV testing. During initial, single-instrument modeling activities, the spectra were truncate to eliminate low signal to noise regions of the spectra at high and low wavenumbers. Further pretreatment procedures were developed. Since the data from both instruments were available at the onset of model development, several inter-instrument differences in spectral response were observed as illustrated in the top plot of Fig. 5 . Peak intensity differences were mitigated by unit area normalization (see bottom plot of Fig. 5 ). Following this, differences in baseline shape were observed between the two instruments. Baseline shape differences were removed using a second order baseline correction. These pretreatment methods were carried over to the global models. In summary, the order of pretreatments for both the global model and directly transferred model was truncation to 180–1800 cm −1 , normalization to unit area, second order detrending, and lastly, mean centering. Normalization to unit area preceded combination of the spectra when constructing the global model. Fig. 5 Raw spectral data collected on instruments A and B (upper) and combined preprocessed spectra (lower)
Using the knowledge of inter-instrumental differences (gained from single-instrument modeling efforts) at the time of global model development does not invalidate a direct model transfer. Rather, it illustrates how a direct model transfer benefits from a general understanding of common sources of variance imparted by instrumental change. Gathering this information however does not require a full global model. In fact, this type of general understanding could typically be gathered by a single exploratory sample as systemic differences are generally overt (e.g., baseline offset or peak shifting).
PLS modeling concluded with the removal of five outlier samples from the initial 135 calibration samples. These were removed due to PLS predicted concentration values that differed significantly from the reference values. This was likely due to errors that occurred during one faulty session of HPLC reference value collection.
Latent variables selection was performed using plots of RMSEC and RMSECV vs. latent variables (Fig. 6 ) for both the global model and single-instrument models. The plots consistently suggested the use of two latent variables for the single-instrument models. The first two latent variables captured 95% of the variance in the spectral data and 90% of the Y variance. To limit overfitting, additional latent variables were not included in the single-instrument models. For the global model, the plots identified the first three latent variables for inclusion in the model. Here, these latent variables captured 96 and 90% of the variance (X and Y variance), respectively. Fig. 6 RMSE versus number of latent variables for individual spectrometer and global PLS models. Top left—model a ; top right—model b ; bottom—global model
When loading vectors for the global calibration model were inspected, relevant spectral features were evident in the first three vectors (Fig. 6 ). The first loading vector contains features that were highly correlated with the acetaminophen spectra (correlation coefficient: 0.96). This high degree of correlation (> 0.95) between the first loading vector and the spectra of acetaminophen was also observed in the single-instrument models. The second and third loading vectors of the global model contained features that were similar to the pure components in Fig. 2 . This may infer that the second and third loading vectors served to not only describe the chemical variance but also the minor wavenumber shift between instruments. The modeling algorithms of the single-instrument models were never exposed to any instrument associated peak shifts and therefore did not demonstrate this feature.
Model Comparison
The RSMEC, RMSECV, RSMEP, and number of LVs are reported in Table 3 . Table 3 Model performance (%, w / w ). Quantitative model performance statistics ID (Cal➔test) LVs RMSEC RMSECV RMSEP SEP Pred. bias A ➔ A 2 0.0100 0.0103 0.0099 0.0079 0.0030 A ➔ B 2 0.0100 0.0103 0.0085 0.0096 0.0033 G ➔ B 3 0.0100 0.0102 0.0101 0.0098 0.0031 B ➔ B 2 0.0097 0.0099 0.0085 0.0095 0.0032 B ➔ A 2 0.0097 0.0099 0.0101 0.0078 0.0031 G ➔ A 3 0.0100 0.0101 0.0084 0.0078 0.0031 LVs number of latent variables, SEP standard error of prediction
Single instrument calibration models were used to predict test spectra from the alternative instrument to determine whether the model performance was significantly affected by the instrumental source of the test spectra. This performance was then compared to the performance that resulted from the prediction of test spectra collected on the original calibration instrument. The resulting RMSEPs were all equivalent, i.e., the 95% CI for the ratios of SEP contained 1, and the 95% CI for the difference in bias contained 0 (Table 4 ). These results indicate that the preprocessing methods effectively mitigated the differences between instruments for the purposes of predicting the test set. Figures 7 and 8 are visual representations of the predicted vs. measured concentration of acetaminophen (% w / w ). Note that satisfactory linearity was observed throughout the calibrated range. Table 4 summarizes the comparisons performed on the model performance statistics. Table 4 95% confidence intervals for model comparison ( w / w , %). Comparison of the differences in model biases and SEP ratios using a 95% confidence interval ID Bias (upper) Bias (lower) SEP ratio (upper) SEP ratio (lower) A ➔ A vs. B ➔ B 0.00166 − 0.0014 1.003 0.656 A ➔A vs. A➔B 0.00136 − 0.0015 1.003 0.672 B ➔ B vs. B ➔ A 0.001137 − 0.0017 1.009 0.670 A ➔ A vs. B ➔ A 0.00058 − 0.0003 1.100 0.924 B ➔ B vs. A ➔ B 0.00052 − 0.0002 1.045 0.937 A ➔ B vs. G ➔ B 0.00032 − 0.0003 1.025 0.933 B ➔ A vs. G ➔ A 0.00030 − 0.0007 1.095 0.913 Fig. 7 Global model loading vectors. The percentage in the parentheses represents the explained spectral variance of the latent variable Fig. 8 Predicted vs. measured w /w% of acetaminophen. The bracketed term describes the calibration and test spectra (“calibration data”➔”test data”). I Calibration data from instrument B, test data from instrument B; II calibration data from instrument B, test data from instrument A; III calibration data from instrument A, test data from instrument A; IV calibration data from instrument B, test data from instrument B; V calibration data from instruments A and B (G; global), test data from instrument A; VI calibration data from instruments A and B (G; global), test data from instrument B
Conclusion
Transfer of calibration models between transmission Raman instruments for the measurement of acetaminophen did not require specific transfer algorithms other than typical spectral preprocessing. The reduction of RMSECV and a general knowledge of the spectral features of unique instruments was adequate to identify the appropriate preprocessing. While peak alignment methods could have been used to enable the use of common chemometric diagnostic statistics in this study, such methods did not improve overall model performance. These characteristics allowed for transferred single-instrument models to perform equivalently to a global model. The utility of directly transferring a calibration model is significant, in part, because global models are not always feasible; they often require significant planning and resources. The consistent instrument performance observed in this study facilitated direct calibration transfer that would simplify the use of a spectral PAT method over the life cycle of a solid oral dosage form.
Summary
The goal of this study was to compare direct transfer vs. global modeling as strategies for quantitative method transfer between two transmission Raman spectroscopy (TRS) instruments. The calibration and test samples were pharmaceutical compacts of acetaminophen and excipients. Quantitative models were constructed using partial least squares regression and typical preprocessing methods. Differences in instrumental responses were described but ultimately deemed inconsequential in this system. Models were compared using a t test-based method to evaluate performance statistics. Statistical analysis demonstrated equivalent performance of the global modeling and direct transfer methods. This work demonstrated that a quantitative transmission Raman model could be directly transferred across instruments, thus avoiding the challenges and resources necessary to create global models.