Introduction
Pharmacokinetics is the field that studies the time evolution of absorption, distribution, metabolism and excretion (ADME) of drugs in humans and animals. Prof. Macheras has contributed extensively and opened new research directions in the field [ ]. He actually introduced and developed this field in Greece and founded the Laboratory of Biopharmaceutics and Pharmacokinetics at the University of Athens, Faculty of Pharmacy. Since then, many researchers from the pharmaceutics research area and beyond have been motivated by his work to become engaged in the field of pharmacokinetics.
One of the main tools in studying the pharmacokinetics of an organism is compartmental modeling, which models a biological system through interconnected subunits. Depending on the available data and the goal of the modeling process, there are two broad classes of compartmental models: empirical models, which are build to fit observations and follow a “top down” approach, and the physiologically-based pharmacokinetic (PBPK) models, which make use of prior physiological knowledge and take a “bottom up” approach [ ]. The space between these two classes that represent the two ends of a spectrum is occupied by semi-mechanistic models. In empirical models, the number of compartments is chosen based on goodness of fit. Thus, parameter values have no physiological interpretation and those models can mainly be used for interpolation of drug concentration within the studied population and statistical evaluation of its apparent kinetics [ ]. On the other hand, PBPK models are mechanistic; they break a complex system into individual parts whose functioning and interaction is determined by the underlying physiology and mechanistic data on their specific parameters.
The main parameters of a PBPK model are tissue volumes and blood flows and as a consequence, the structural model is confined to the physiology of the species under examination [ ]. Besides these drug-independent physiological parameters, PBPK models incorporate information about the drug as well, through the drug-related parameters. Whole body PBPK models (WBPBPK) are a category of particular interest where the body is represented by a closed circulation system consisting of several tissues that are important for the ADME processes. Mass balance equations are used to describe regional blood flows, the arterial and venous blood pools connect the tissues, and a lung compartment closes the blood loop [ ]. The number and type of compartments included is determined by several factors such as the target compound, the animal species and the administration route. Increasing the number of compartments and sub-compartments increases complexity since more information is needed to determine the model parameters, making large models impractical.
The mechanistic nature of the PBPK models offers many advantages. First of all, it allows the prediction not only of plasma but also of tissue pharmacokinetic profiles, before conducting in vivo experiments. This is enabled by the modular scheme; information can be gathered for each compartment separately through in vitro experiments or from literature sources. Adding to that, the complex structure that includes both drug-related and physiological parameters permits the creation of more informative models, where data from independent sources (especially for the physiological parameters) can be integrated together with the drug specific experimental results to create a model with more robust inference capabilities [ ]. The fact that most physiological parameters can be found in literature, coupled with the fact that most mammals share the same PBPK structure leads to the ability to perform both inter and intra-species extrapolation. These tools allow for example to extrapolate pharmacokinetics from rats to humans and from adults to children. PBPK modeling can also be used for predicting drug–drug interactions [ ].
As stated above, the physiological parameters of a PBPK model can be derived from several sources. The drug-related parameters can be obtained from in vitro experiments or in silico methods. Therefore, PBPK modeling can be used in the drug development phase as a simulation tool [ ]. However, extrapolation to humans is a sensitive process and fine tuning to clinical data is needed in order to produce more robust inferences.
There are several methods for estimating drug-related parameters based on the information provided by clinical data [ ]. Among them, Bayesian inference is a powerful natural route for refining an estimation based on new data. In this case, preclinical data constitute the prior belief which is updated with the clinical data, resulting in a new estimation in the form of a (posterior) distribution. One of the major advantages of the Bayesian approach is the inherent way in which the quantification of the estimation uncertainty is handled, through the shape of the posterior distribution. This increases the estimation reliability and is also very important in the extrapolation procedure, where it enables the incorporation of uncertainty in the model predictions. Moreover, if the Bayesian framework is combined with hierarchical modeling, then both the individual and population levels can be described by the model [ , ]. In that way, the inter-individual variability can be quantified and thus it can be separated from the inherent uncertainty of the data [ , ]. One way to account for inter-individual variability is to create a covariate model for the physiological parameters and to assign them random effects, considering all drug-related parameters as fixed effects having a “global” impact [ ]. An alternative approach is to use again a covariate model for explaining a part of the inter-individual variability, with physiological parameters as fixed effects and drug-related parameters as random effects [ ]. This can be extended to include intra-individual or inter-study variability [ , ].
The cases where Bayesian inference can be implemented directly through the use of the Bayes’ theorem are limited due to the difficulty of approximating the denominator, which—in most cases—is a multidimensional integral. This is the reason why Bayesian inference is usually conducted through Markov chain Monte Carlo (MCMC). MCMC is a class of algorithms that, under certain assumptions, sample directly from the unknown target distribution (posterior), which is summarized at the end of the procedure by the collected samples [ ]. There are two main groups of MCMC algorithms: the random walk MCMC and the non-random walk MCMC. In the first group the most popular methods are the Metropolis–Hastings algorithm, the Gibbs sampler and the reversible jump MCMC, while the most known non-random walk MCMC is the Hamiltonian Monte Carlo (HMC).
There exist many free software platforms that allow the user to design the statistical model and perform Bayesian inference through variants of the MCMC method. Among them, the GNU MCSim software [ ] has been used successfully in estimating parameters in PBPK modeling problems. GNU MCSim uses a Metropolis–Hastings algorithm to perform stochastic simulations. The GNU MCSim project began in 1991, but is consistently updated and extended with updated releases each year. Stan [ ] is a newer software language for statistical inference, and was initially released in 2012. MCMC sampling in Stan is typically performed using the no-U-turn sampler [ ], which is an adaptive variant of Hamiltonian Monte Carlo, but the user can also chose to implement static HMC. Stan has been applied in various areas, such as social sciences and finance, as well as pharmacometrics and PKPD modeling [ ], but to the best of our knowledge, no applications have been published on the use of Stan in PBPK modeling. In this paper, the two software platforms are used to deploy a hierarchical Bayesian model and estimate the drug-related parameters of an existing WBPBPK model, based on published clinical data, extending the comparison between NONMEM and Winbugs performed by Langdon et al. [ ].
Materials and methods
The modeling approach of this work builds on the work of Gueorguieva et al. [ ]. The same clinical data were used [ ] in order to update prior pharmacokinetic knowledge gained from preclinical rat experiments. We use a slightly different statistical model and a covariate model to explain part of the inter-individual variability of the study population.
Clinical data
The available concentration data refer to two different groups of healthy adults, which have been described in a previous study [ ], one group of 12 healthy male and female volunteers and another group of 11 healthy male volunteers. All patients received a single dose of diazepam via intravenous infusion over 15–30 s. The dose was 5 to 10 mg and was adjusted for body weight. Following the administration of the drug, venous plasma samples were collected at 0.083, 0.25, 0.5, 0.75, 1, 1.5, 2, 3, 4, 6, 8, 10, 12, 24, 30, 36, 48 and 72 h. In addition to the plasma data, the age, body weight and gender of each individual were available. Fig. 1 Schematic presentation of the WBPBPK model of diazepam [ ]
Structural model
The detailed description of the PBPK model used can be found in [ ]. Its schematic representation can be seen in Fig. 1 . It consists of 11 compartments describing the concentration of the drug in various tissues, namely liver ( LI ), kidney ( KI ), brain ( BR ), intestine ( IN ), stomach ( ST ), muscle ( MU ), adipose ( AD ), skin ( SK ), gonads ( GO ), heart ( HT ) and lungs ( LU ), one compartment to model the rest of the body ( RE ) as well as two blood pools; venous ( VEN ) and arterial ( ART ). The parameters of the model are divided into drug-dependent and physiological (drug-independent) parameters. The first category comprises twelve tissue-to-plasma partition coefficients ( Kp ), fraction unbound in plasma ( fu ), blood-to-plasma ratio ( R ), and intrinsic hepatic clearance ( \(CL_{int}\) , in L/h). The physiological parameters of the model are simply the regional tissue blood flows ( Q ) and tissue volumes ( V ).
For the current analysis, the same parameterization as in [ ] was followed. Specifically, \(f_u\) was set to 0.015 and R was assumed to be equal to 0.65. Moreover, the Kp values were scaled by assuming that the unbound equilibrium tissue-to-venous blood concentration ratio ( \(Kp_{UB}\) ) are identical for humans and rats. Therefore, Kp values were obtained by scaling the rat posterior results of winbugs (Table III of [ ]) using Eq. 1 (except for Kp for the rest of the body, which was set to 2.2 as in [ ]). The Kp values are presented in Table 1 . $$\begin{aligned} {\left\{ \begin{array}{ll} f_{u_{rat}} = 0.15, R_{rat} = 1 [20]\\ Kp_{UB_{rat}} = Kp_{UB_{human}}\\ Kp_{UB} =Kp \cdot R \end{array}\right. } \Rightarrow Kp_{human} = \frac{Kp_{rat}}{6.5} \end{aligned}$$ (1) Table 1 Kp values after scaling the posterior results of the rat model of [ ] Tissue Kp Lungs 0.71 Intestines 0.53 Stomach 0.75 Liver 1.35 Brain 0.32 Heart 0.86 Kidney 0.73 Skin 0.46 Muscle 0.56 Adipose 3.34 Gonads 0.76 Rest of the body 2.2
Covariate model for body mass-dependent parameters
Physiological parameters were calculated for each subject using body mass and gender. Blood flows were calculated as a percentage of total cardiac output (TCO), using the coefficients provided by [ ] (Table 2 ). The total cardiac output of each individual was in turn considered to be a function of the body mass calculated as: $$\begin{aligned} TCO = 11.22\cdot BM_{tot}^{0.81} \end{aligned}$$ (2) where CO is the total cardiac output in L/h and \(BM_{tot}\) the subject’s body mass in kg [ ]. Table 2 Percentage of TCO received by each tissue [ ] Tissue Percentage of TCO (%) Lungs 100 Intestines 14 Stomach 1 Liver 6.5 Brain 12 Heart 4 Kidney 19 Skin 5 Muscle 17 Adipose 5 Testes 0.5 Uterus 0.2
To calculate tissue volumes, the method described in [ ] was used. A 5th degree polynomial gave the percentage of total body mass of each tissue (Eq. 3 ) as a function of the body mass, up to 75 kg for males and 65 kg for females. $$\begin{aligned} BM_i=&X_0+X_1\cdot BM_{tot}+X_2\cdot BM_{tot}^2+ X_3\cdot BM_{tot}^3\\&+\,X_4\cdot BM_{tot}^4 +X_5\cdot BM_{tot}^5 \end{aligned}$$ (3) where \(BM_i\) is the percentage of tissue i with respect to total body mass, and \(BM_{tot}\) is the body mass of the subject in grams . For higher body masses, constant percentages were used as described in [ ]. The polynomial coefficients, \(X_i\) , are different for males and females and can be found in Appendix 1 .
Statistical model
Statistical inference was made on three parameters: \(CL_{int}\) , the metabolic clearance of the drug; \(Kp_{AD}\) , the adipose tissue-to-plasma partition coefficient; and fKp , a scaling factor multiplying the rest of the Kp values.
A three stage hierarchical model was adopted to describe the data collection process. This enabled the description of both the inter-individual variability and uncertainty of the selected drug-related parameters, as well as the quantification of the residual variability which is mainly a result of model misspecification and measurement errors [ ]. The first stage of the model described the model likelihood, where proportional errors were modeled by a log-normal distribution (Eq. 4 ). The second stage of the model, presented in Eq. 5 , refers to the individual level, where log-normality around a population mean was assumed for all parameters. The third stage of the model consisted of distributional assumptions of the population level, i.e., priors placed on the population parameters (Eq. 6 ).
Suppose that N blood samples, indexed by j , were drawn for each of the M individuals indexed by i . Let the j th measurement of individual i be denoted by \(y_{ij}\) , the associated time by \(t_{ij}\) and the related individual dose by \(D_i\) . Denote by \(\theta _i\) the p-dimensional vector of drug-related parameters of individual i , by \(\sigma ^2\) the residual variance of the model, and by \(f(\cdot )\) the structural model. The hierarchical model is then:
First stage $$\begin{aligned}&p\big (\log {(y_{ij})} |\theta _i, \sigma ^2\big ) \propto N\Big (\log {\big (f(D_i;t_{ij};\theta _i)\big )}, \sigma ^2\Big ) \end{aligned}$$ (4) Second stage $$\begin{aligned}&p(\theta _{tr_i} | \mu , \Omega ) = MVN_p(\mu , \Omega ) \\&\theta _i = e^{\theta _{tr_i}} \end{aligned}$$ (5) Third stage $$\begin{aligned} &p(\mu ) = MVN_p(\eta , H) \\&\Omega = diag(s) \cdot C \cdot diag(s) \\&p(s) = N_{half}(0,1) \\&p(C) = LKJ(a) \\&p(\sigma ) = N_{half}(0,1) \end{aligned}$$ (6) where \(MVN_p\) stands for the p -variate normal distribution, \(\Omega\) is the population variance-covariance matrix (size \(3 \times 3\) ), s a vector of dimension 3, \(N_{half}\) is the half-normal distribution, and C a prior correlation matrix. As suggested in [ ], a Lewandowski–Kurowicka–Joe (LKJ) prior was assigned to the correlation matrix [ ]. The hyper-parameter values were: $$\begin{aligned} &\tilde{\eta } = (70.8, 1, 3.34) \\&\tilde{\eta }_{std} = (62.5, 1, 0.44) \\&\eta = log{\Bigg (\frac{\tilde{\eta }^2}{\sqrt{{\tilde{\eta }_{std}}^2+\tilde{\eta }^2}}\Bigg )}\\&H_{mn} = {\left\{ \begin{array}{ll} \log {\Big (\frac{\tilde{\eta }_{std}^2}{\tilde{\eta }^2}+1 \Big ) }, \quad \text {for} \quad m = n \\ 0, \quad \quad \quad \quad \quad \text {otherwise} \end{array}\right. } \\&a ={15} \end{aligned}$$ (7) The standard deviations, as well as the prior mean of the clearance were identical to the ones used in [ ] for comparison reasons. The above approach describes a centered parameterization of the statistical model. Besides this most common parameterization, a non-centered parameterization was also investigated to assess its impact on results. Model parameterization, especially in hierarchical structures, has a decisive role in the performance of the sampler [ ]. The centered form can be converted to the non-centered one through the transformation given by Eq. 8 . The non-centered parameterization was used to model the random effects, i.e. the individual level. $$\begin{aligned}&X \sim N(\mu ,\sigma ^2) \rightarrow X=\mu + \sigma \cdot y \\&y \sim N(0,1) \end{aligned}$$ (8) The above model was slightly simplified for the GNU MCSim , which does not offer MVN or LKJ sampling. In that case, Eq. 5 first line was simplified as: $$\begin{aligned} p(\theta _{tr_i} | \mu , \Omega ) = N(\mu , \Omega ) \end{aligned}$$ (9) while Eq. 6 became: $$\begin{aligned} p(\mu _i) &= N(\eta _i, H_i) \\ \Omega _i & = N_{half}(0,1) \\ p(\sigma ) &= N_{half}(0,1)\end{aligned}$$ (10) where H and \(\Omega\) are now vectors. In order to maintain comparability between Stan and GNU MCSim and to directly compare the impact of prior assumptions—multivariate and univariate—on the posterior, a univariate model was additionally fitted in Stan .
Software tools for Bayesian inference
The first Bayesian tool used for obtaining the posterior distribution of the parameters was Stan , which is a statistical modeling language that can be used through many interfaces such as R , Python and Matlab and includes MCMC sampling, variational inference and penalized maximum likelihood estimation with optimization. Its major difference with other MCMC tools is that it avoids random walk. This is managed through the utilization of Hamiltonian dynamics for the proposal. Imagine a particle with some position and momentum moving over time in a frictionless space. The model parameters correspond to the position vector and an auxiliary vector is also introduced, representing the momentum vector. The potential and kinetic energy related to the position and momentum vector constitute the total energy (equal to the Hamiltonian in the HMC context), which remains constant over time due to the absence of friction. The position and momentum of the particle can be calculated by solving the Hamilton’s equations (a system of partial differential equations) [ ]. In each iteration, the particle is given a random momentum and is left to move in space for a certain amount of time. In the Stan implementation of HMC, the proposal is obtained by sampling a point from the entire trajectory. The solution of the Hamiltonian system requires a discretization, so the trajectories are characterized by a step size and a number of steps. These tuning parameters are crucial for the success of the algorithm and need to be tuned by the user in static HMC implementations. If the trajectory is too small, the algorithm will use a very small pace or will not be able to explore the entire parametric space. On the contrary, if the trajectory is too long, it will backtrack and waste computational resources [ ]. Other important properties of HMC are the precision with which the Hamilton’s equations are solved, the mass matrix and the distribution from which the momentum is sampled [ , ]. Stan uses the No-U-Turn sampler (NUTS), an adaptive sampler that automatically tunes these parameters through the warm-up period.
The nature of the HMC algorithm allows Stan to offer some very helpful diagnostic tools, which generate alerts in the process of model fitting that are reported at the end of each run. These diagnostic tools reveal pathologies that are model-inherent but cannot be recognized by tools that do not apply HMC. Divergence transitions ( check_divergences() in Stan ) is one diagnostic tool that indicates pathological neighborhoods of the posterior which are not sufficiently explored by the simulated Hamiltonian trajectories. In this case the Markov chains do not completely explore the posterior and the MCMC estimators are biased. Another tool is the maximum tree depth ( check_tree_depth() in Stan ) that is related with NUTS. A non-zero value of this diagnostic metric suggests that the posterior includes regions of very low curvature, which is another type of pathology [ ]. Finally, reviewing the energy Bayesian Fraction of Missing Information (E-BFMI) ( check_energy() in Stan ) informs the user about problems in the pace of exploration. In general, if any of these tools suggests that there are pathologies, the user can refit the model by changing the parameters of NUTS or by reparameterizing the model.
Another major advantage of the HMC algorithm is that it informs the proposal about the target distribution through numerical approximation of its gradient. This is in contrast to usual MCMC methods where the proposal is unrelated to the target distribution (posterior). Therefore, HMC performs better in high dimensional problems where the posterior has high curvature compared to other MCMC methods which get stuck or tend to explore the posterior at a very low rate. Stan offers both static HMC and NUTS. The reader is referred to [ , , ] for a detailed description of HMC and to [ ] for an in-depth review of the NUTS sampler. The interface used in this study was RStan v.2.17.3. For sampling, NUTS was preferred to (static) HMC.
Stan offers three approaches for solving a system of differential equations: numerical solution via a non-stiff solver ( integrate_ode_rk45 ), which uses the Runge Kutta Dopri algorithm with the implementation from Boost, a stiff solver ( integrate_ode_bdf ), which uses the backward differentiation formula (BDF) method with the implementation from CVODES, and the matrix exponential method ( matrix_exp ), which uses a Pade approximation coupled with scaling and squaring [ ]. In the latter case, the system must be linear (which is the case for the diazepam model) and has to be cast in a matrix form, A , whose solution is given by Eq. 11 : $$\begin{aligned} x(t) &= e^{tA} \cdot x_0 \\ e^{tA} &= \sum _{k=0}^{\infty } \frac{1}{k!} {(tA)}^k \\ \end{aligned}$$ (11) For a more detailed review on methods to solve ODEs in Stan , the reader is referred to [ ].
The second Bayesian tool was GNU MCSim [ , ]. It offers a simulation language, Monte Carlo and MCMC sampling, tempered MCMC sampling, stochastic optimization and experimental design optimization. User-defined models are compiled, as in Stan . Numerical integration of differential equations can be performed by the very efficient stiff ODE solvers LSODES or CVODES [ ]. We used here Lsodes (for stiff ODEs, with relative and absolute tolerances of \(10^{-6}\) ) and the simple component by component Metropolis–Hasting sampler. The (Gaussian) proposal kernels are adapted automatically to yield a satisfactory jump frequency for each sampled parameter.
Model specifications
The models on both platforms were run with 4 chains with 5000 samples each. The model that was built with GNU MCSim had a warm-up period (initial samples that are discarded, also termed burn-in period) of 1000 iterations, while the models in Stan used 400 warm-up iterations. The role of warm-up period is different in the two software tools: in GNU MCSim , its length is chosen by the user and simply reduces the output size; the user has to check convergence to the target distribution independently. In Stan the warm-up period spans both convergence and tuning of the HMC parameters if NUTS is used. The warm-up period in Stan is more time consuming per iteration than the sampling period because of the adaptation of computational parameters, which are then used in all sampling iterations. Finally, the start parameterization was random in both software tools. In GNU MCSim , the initial chain values were sampled from the priors and in Stan the default initialization was followed, which randomly generates initial values between − 2 and 2 on the unconstrained support.
Both models were run on a computer with an Intel Core i7-8700 (3.2 GHz), 16 GB RAM and windows 10 OS. Their computational efficiency was measured in terms of the effective sample size ( \(N_{\text {eff}}\) ), an estimate of the number of independent samples drawn. Smaller effective sample sizes lead to less accurate posterior distribution estimates. Since each parameter has a different \(N_{\text {eff}}\) , two metrics were used: the average effective samples over all parameters (85 parameters in total: 3 population means, 3 population variances, 9 correlation coefficients, 69 individual parameters, and model error) and the minimum number of effective samples (i.e., \(N_{\text {eff}}\) for the least efficiently sampled parameter). There are also several ways to calculate \(N_{\text {eff}}\) : to be consistent, the same RStan function monitor() , which uses both cross-chain and within-chain calculations [ ], was used to obtain \(N_{\text {eff}}\) for both outputs.
Results
Comparison on computational efficiency
The MCMC samplers were compared with respect to the posterior parameter distributions they yielded, as well as their computational efficiency. Efficiency results are presented in Table 3 , where time refers to the computer time (in seconds) taken to compute all 4 chains in parallel. It is evident that the NUTS sampler is more efficient than the sampling method used in GNU MCSim . It is indicative that in all but two parameters the Stan output had \(N_{\text {eff}}\) = \(N_{\text {sample}}\) , which demonstrates the low autocorrelation in the produced chains. Nevertheless, the execution time of GNU MCSim is much shorter, resulting in a higher overall computational efficiency of produced effective samples per unit time. Table 3 Comparison of computational efficiency between Stan and GNU MCSim Platform Time (s) \(\overline{N_{\text {eff}}}\) \(\overline{N_{\text {eff}}}/\text {s}\) \(N_{\text {eff}_{\text {min}}}\) \(N_{\text {eff}_{\text {min}}}/\text {s}\) Stan multivariate 4850 19,926 4.11 16,240 3.35 Stan univariate 4800 19,935 4.15 15,109 3.15 GNU MCSim 160 2533 15.8 1221 7.63
With regard to solving the system of linear differential equations in Stan , the most robust method proved to be the stiff solver ( integrate_ode_bdf ), with relaxed tolerances. Specifically, the lowest time record of 4850 s for 5000 samples (multivariate model), was obtained for relative tolerance, absolute tolerance and maximum number of steps equal to \(10^{-4}\) , \(10^{-2}\) and \(10^5\) respectively. Use of Stan ’s default values ( \(10^{-6}\) , \(10^{-6}\) and \(10^{6}\) ) deteriorated the performance and registered an execution time around 40,000 s. On the other hand, the matrix exponential method ( matrix_exp ) was much slower, recording 31,000 s execution time. Use of the non-stiff solver ( integrate_ode_rk45 ) was extremely slow and did not yield any results after a significant amount of time. Note the in [ ] computation times were 7200 s with NONMEM and 601,200 s with WINBUGS, but on a different computer, clocked at 450 MHz. Fig. 2 Comparison of individual parameter estimates between GNU MCSim and Stan Fig. 3 Comparison of population estimates between GNU MCSim and Stan . The red crosses represent the mean population estimates while the blue crosses represent the population variance estimates
Comparison on parameter estimation
Comparison of the posterior covariance matrices obtained from the univariate and multivariate prior distributional assumptions revealed that the diagonal elements were almost identical, while off-diagonal elements were very small in both matrices. More specifically, the highest absolute difference observed among the two posterior covariance matrices was 0.02, while the mean absolute difference was 0.0002. These slight differences had no considerable effect on the inference. Therefore, in the rest of the paper we will present only results referring to Stan ’s multivariate model. The parameter estimates obtained with the two software tools were practically identical. This can be seen in Fig. 2 , where the log-transformed estimates of the individual parameters of Stan are plotted against those of GNU MCSim and all fall on the identity line. The size of the crosses quantifies estimation uncertainty, which is virtually the same for both programs. Figure 3 depicts the population estimates, where the red crosses represent the population means and the blue crosses represent the population variances. Detailed estimation results can be found in Appendix 2 . Moreover, when comparing the two univariate models with noninformative priors (uniform (− 5,10) for \(\mu _i\) and uniform (0.01,10) for \(\Omega _i\) ) the two models produced similar results (see Appendix 4 ). Fig. 4 Traceplots of the three population parameters (mu[1] = \(log(CL_{int})\) , mu[2] = log ( fKp ), mu[3] = \(log(Kp_{AD})\) and s[1], s[2], s[3] the corresponding population variances). (The plots correspond to the Stan model. Similar plots were generated from the GNU MCSim model)
Traceplots were used to graphically inspect convergence of the simulated Markov chains. Figure 4 presents the traceplots of the population parameters in Stan ( GNU MCSim produced similar traceplots). The absence of patterns and regions were the chains remain static as well as the similar behaviour for all chains suggest that convergence has been achieved. However, graphical diagnostics of convergence are usefully complemented by quantitative criteria. One such criterion is the potential scale reduction factor ( \(\hat{R}\) ), which suggests that convergence has been practically reached if all model parameters have \(\hat{R}<1.2\) [ ]. In this case, split \(\hat{R}\) was used, which splits the chains in half (after discarding the warm-up samples) and checks both mixing and stationarity. All parameters had a value of \(\hat{R}<1.005\) , with both Stan and GNU MCSim . The HMC-related diagnostic tools did not reveal any pathology, which further enhanced the validity of the produced results. Fig. 5 Posterior vs prior densities of the three population parameters. (The plots correspond to the Stan model. Similar plots were generated from the GNU MCSim model)
Figure 5 illustrates the posterior vs the prior distributions of the population means. It is evident that the information contained in the data reduced significantly the prior uncertainty of \(CL_{int}\) and fKp . On the contrary, the variance of \(Kp_{AD}\) was considerably increased by the clinical data integration. So in fact, our prior on that parameter was too precise. These results also mean that the parameters chosen were identifiable, given the available data.
Regarding the model fit to the data, Figs. 6 and 7 present the individual plots for all patients. Most of the patients’ data were adequately described by the PBPK model. Fig. 6 Individual plots presenting the fitted model and the observations for the first 12 patients. (The plots correspond to the Stan model. Similar plots were generated from the GNU MCSim model) Fig. 7 Individual plots presenting the fitted model and the observations for the last 11 patients. (The plots correspond to the Stan model. Similar plots were generated from the GNU MCSim model)
Figures 8 and 9 present visual predictive check (VPC) plots corresponding to the two models, which assess their efficiency in describing inter-individual variability at the population level. The circles represent the data from all subjects, the green dotted line depicts the 5th percentiles of the data, the solid red line the median and the dotted blue line the 95th percentiles. These lines were obtained by ordering all observations at each time instance and extracting the respective quantiles. The colored ribbons were created by simulating 1000 sets of 23 virtual patients with physiological characteristics identical to the real patients. For the Stan model, in each set, population means ( \(\mu\) ) and variances ( \(\Omega\) ) for \(CL_{int}\) , fKp , and \(Kp_{AD}\) were drawn from their posterior distributions and then, for each virtual patient, a triplet of individual parameters was drawn from \(MVN_p(\mu , \Omega )\) . The same procedure was followed in the GNU MCSim VPC plot, with the difference that both the population and individual parameters were drawn from univariate distributions. In each set, the 5th, 50th and 95th prediction percentiles were calculated and by ordering the percentiles produced by all 1000 sets, the 95% confidence interval (CI) was calculated for each of the three percentiles. Thus the pink ribbon on the bottom of the VPC represents the 95% CI of the 5th percentile of the model, the gray ribbon represents the 95% CI of the 50th percentile of the model and finally the green ribbon depicts the 95% CI of the 95th percentile of the model.
Similarly to parameter estimation results, the Stan and the GNU MCSim VPC plots are almost identical, which implies that the population structure is correctly modeled when an independence assumption is made at the population level. In both plots, the 5th, 50th and 95th percentiles of the observations fall within the 95% CI of the respective percentiles of the model predictions, which illustrates that the models describe adequately inter-individual variability. Fig. 8 Visual predictive check of inter-individual variability produced by the Stan model. Circles represent the data on all individuals (note the log–log scale). The Ribbons correspond to model predictions (see text) Fig. 9 Visual predictive check of inter-individual variability produced by the GNU MCSim model. Circles represent the data on all individuals (note the log–log scale). The Ribbons correspond to model predictions (see text)
Choice of parameterizations and priors
As stated above, two different model parameterizations were tested in Stan ; the centered and the non-centered one. The centered parameterization proved to be more efficient, as it was faster and produced a higher \(N_{\text {eff}}\) metric for the estimated parameters. More specifically, computation time was 10,000 s for the non-centered model vs 4850 s for the centered one. Different computational time affected the \(N_{\text {eff}}\) metric, which for the non-centered model was 1.73 \(\overline{N_{\text {eff}}}/\text {s}\) , i.e. less than half of this metric for the centered model. Increased computational time for the non-centered model was due to the extra parameters at the individual level. If the data did not contain significant information, then the original posterior would have a geometry with high curvature and the non-centered parameterization would result in simpler geometries [ ], contributing to a speed-up of the posterior exploration. For the studied combination of PBPK model, data and statistical model, the resulting geometries did not include any regions of high curvature (which was suggested by several graphical inspections) and this is most probably the reason why the non-centered model was slower. In addition, the parameter estimates of the centered and non-centered models were all the same with the exception of fKp , which differed in both the population and individual level. More specifically, the non-centered model considered a higher fKp , which resulted in slightly worse individual plots and VPC plots.
We also tested the impact of assigning different distributions to the correlation matrix and to the standard deviation of the population level (denoted by C and s respectively in Eq. 6 ). For s , we compared the results obtained when using a half-normal vs a half-Cauchy distribution (see Fig. 10 ). The half-normal distribution was tested with scale 1, 10, 100 and the half-Cauchy with scale 2.5 and 5. No differences can be seen in the posterior means, but posterior variances are affected. Naturally, the flatter the prior, the higher the posterior uncertainty. Fig. 10 Impact of different priors on the standard deviation of the population level. The x-axis contains the priors, where hN and hC encode the half-normal and half-Cauchy distribution respectively
Regarding C , many values for the shape parameter ( a ) of the LKJ distribution were tested. The impact of the shape parameter can be seen in Fig. 11 , where the plot presents the prior distribution assigned to the non-diagonal element C [1, 2] for each correlation matrix. As a increases, the prior assigns less correlation between parameters and gets closer to the unit correlation matrix, while for values equal or less than 1, it yields a distribution with shape close to uniform. The effect of the prior selection on the posterior of the correlation matrix can be seen in Fig. 12 . The posterior is heavily dependent on the prior shape, but the uncertainty of the estimation is such that it does not allow any robust inference; zero correlation among parameters cannot be ruled out. The only suggestion that can be supported by the graph is the higher correlation between fKp and \(Kp_{AD}\) with respect to the other two correlation pairs, which was expected beforehand. Moreover, the different priors did not affect significantly any of the remaining parameters, only small variations were observed. Examination of the individual plots and the VPC graph for each scenario did not reveal significant changes either. This comes in good agreement with the similarity between the results of the multivariate model followed in Stan and the univariate produced by GNU MCSim . The results presented above refer to \(a=15\) , because that shape value produced an output that was found to be slightly more computationally efficient, as seen in Appendix 3 . Fig. 11 Impact of shape parameter a on the LJK prior. The appearing distribution is applied on each non-diagonal element of the correlation matrix C
Finally, another option for building the statistical model is the Cholesky factorization: One can declare the correlation matrix to be a cholesky_factor_corr and then adopt multi_normal_cholesky instead of multi_normal for the 2nd stage of the model. This approach yielded the same results but the resulting distribution of the correlation matrix had a diagonal that slightly deviated from the unit diagonal and this is the reason why it was not preferred. Fig. 12 Impact of the prior shape selection on the posterior of the correlation matrix. The bars represent the 95% credible interval. The LKJ shape parameter a values tested were: 0.5, 1, 2, 5, 10, 15, 20, 40, 50
Discussion
We re-analyzed with two software programs diazepam population kinetic data with a PBPK model in a purely Bayesian framework. We chose to infer on diazepam metabolic clearance, the adipose tissue-to-plasma partition coefficient, and a scaling factor multiplying the rest of the Kp values. This choice was based on the fact that clearance had the least informed prior, the adipose tissue had the slowest distribution and the highest partition coefficient a priori (making it an important storage compartment), and that all other partition coefficients should be scaled with it for coherence (prior information was as much about the relative values of the Kp ’s than about their magnitude). The small number of selected parameters is also directly connected to the structural and statistical identifiability problems potentially affecting complex PBPK models [ , ]. We exercised our judgment here, and another approach would be to select the most influential parameters through sensitivity analysis [ ]. We did try alternative choices. For instance, we added the rest of the body Kp to the parameters to infer on (prior information about it is weak, as there was no such parameter in the rat model), but we gained no insight about its true value (its prior remained unchanged).
The models used in this study have two major differences with the approach followed in Langdon et al. [ ]. The first is the use of a covariate model for body mass-dependent parameters in order to partly explain inter-individual variability. The second concerns the choice of the parameters for the statistical model. These two differences are responsible for obtaining different results. More specifically, \(CL_{int}\) was found to be 96 L/h instead of about 75 L/h in [ ] and all Kp s had different posterior estimations (see Table 3 in [ ]). Almost all partition coefficients in [ ] had posterior partition coefficient values lower than their (rat) prior central estimates. In particular, the partition coefficient of the “carcass” (a large compartment by volume) had a vague prior and very low posterior values (around 0.07) in [ ], much different from the others, which were typically between 0.5 and 1. Our partition coefficient estimates are all lowered equally by the scaling coefficient fKp , and therefore they are more coherent, while avoiding identifiability problems. Still, our estimate of the partition coefficient for adipose tissue, \(Kp_{AD}\) , is similar to the one reported in [ ], which indicates that this parameter is reasonably identified from the data.
Several parameterizations of the hierarchical model were also tested and we retained the one giving the most stable results. More specifically, we tried different prior combinations for the correlation matrix and the standard deviation of the population level. The shape parameter of the LKJ prior had a substantial impact on the posterior of the correlation matrix, which, however, did not affect the posterior of any other parameter and, therefore, the goodness-of-fit of the model on both individual and population levels. Regarding the priors assigned to the population standard deviations, they did not affect the produced posterior. The comparison of the centered and non-centered model revealed that the centered model was more efficient. For the specific combination of model, data and priors, the posterior of the centered model proved to be easily explored. This is not always the case. Non-centered parameterizations are supposed to perform better in hierarchical structures where the data does not carry strong information [ ]. The problem arises when small variations of the bottom layer of the structure introduce high variations at the top levels. That leads to a posterior distribution of high curvature that is difficult to explore. In such cases, a non-centered parameterization introduces transformations between layers, ending up with less correlated variables and a simpler posterior geometry.
One of the main advantages of Stan lies in its HMC-specific diagnostic tools. A user can receive significant help by consulting the output of the diagnostics. If the posterior contains pathologies, then the user is alerted and is advised to reparameterize the model or change priors. These pathologies cannot be located by global diagnostics, so users of other MCMC methods cannot be informed by potential biases included in the produced fits.
However, for models based on differential equations, such as PBPK models, the algorithms implemented in Stan appear quite slow. This is in part inherent to the HMC algorithm: the Jacobian of the solution with respect to the model parameters must be computed at each step, either by finite differencing or by integration of additional differential equations [ ]. Since integration time typically increases quadratically with the number of ODEs, HMC incurs a high computational cost when dealing with ODE models. In this case, straightforward MCMC simulations are a competitive alternative. But for simpler algebraic models Stan is usually faster. Moreover, it performs better in cases where the posterior geometry is difficult, with regions of high curvature, where algorithms like Metropolis–Hastings explore in a slow pace or even get stuck [ ].
Note again that GNU MCSim does not offer multivariate sampling and therefore assumed independence, at the second and third levels of the hierarchy, between the three parameters sampled. That must have contributed to better computational performance. However, more importantly, the results obtained under either independence or correlation assumptions were practically the same (see Figs. 3 , 2 ). Therefore, it seems superfluous to use multivariate distributions for the specific combination of structural model and information (data and priors). This is probably due to the mechanistic nature of the PBPK parameters which do not lump several processes into a unique value. This can be taken as a further advantage of PBPK model. The parameters of empirical models (e.g. classical compartmental models) get more easily entangled because they share lumped processes. In that case, more complex multivariate models are required for correct inference.
The model codes can be found in https://github.com/ntua-unit-of-control-and-informatics/Diazepam-case-study .
Conclusions
Two Bayesian software inference tools namely, Stan and GNU MCSim , were compared in this work on updating the parameters of a Diazepam population PBPK model. The two software tools produced almost identical parameter estimates and both exhibited very good individual and population fits. Therefore, it was shown that consideration of multivariate distributional assumptions is superfluous in this problem. In order to generalise this statement for population PBPK models, more evidence is needed and therefore it remains an open question. It was also observed that centered parameterization is better suited than non-centered parameterization in this kind of parameter estimation problems. The goodness-of-fit of the model was not affected by the change in the posterior results of the correlation matrix, which was completely dependent on the prior, indicating the lack of information about parameter correlation in the data. Stan was very efficient in terms of the effective sample size \(\overline{N_{\text {eff}}}\) , which in all but two parameters was equal to the total number of samples. However, GNU MCSim mixed much faster and outperformed Stan in the overall computation efficiency \(\overline{N_{\text {eff}}}/\text {s}\) metric. The model fitting phase was found to be more user-friendly in Stan due to its HMC-specific diagnostic tools that alert the user for potential biases that are included in the final model.
In a future work, we are planning to investigate how the addition of more parameters affects the results of the two software tools. Additionally, the response of the models when only sparse data are available will be studied.