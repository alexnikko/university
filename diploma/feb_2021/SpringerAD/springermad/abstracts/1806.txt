When trying to gain intuitions about the computations implemented in neural circuits, we often use comparisons with electronic circuits. However, one fundamental difference to hard-wired electronic circuits is that the structure of neural circuits undergoes constant remodeling. Here, we discuss recent findings highlighting the dynamic nature of neural circuits and the underlying mechanisms. The dynamics of neural circuits follows rules that explain steady state statistics of synaptic properties observed at a single time point. Interestingly, these rules allow the prediction of future network states and extend the insights gained from serial sectioning electron microscopy of brain samples, which inherently provides information from only a single time point. We argue how the connectome’s dynamic nature can be reconciled with stable functioning and long-term memory storage and how it may even benefit learning.