Introduction
The concept of quality by design (QbD) has been adopted in the pharmaceutical industry since the introduction of several initiatives such as the US Food and Drug Administration Pharmaceutical cGMPs for the 21st Century and the International Conference on Harmonization guidelines Q8, Q9, and Q10 [ , , , ]. QbD is a systematic approach to development that begins with predefined objectives and emphasizes product and process understanding and process control, based on sound science and quality risk management. As a direct result of the regulatory expectations, the product risk assessment should link the active pharmaceutical ingredient (API) and excipients’ critical material attributes and process parameters to the product critical quality attributes (CQAs). An assessment of the CQAs leads to the correct attributes being measured and help establish appropriate controls to mitigate and manage risk [ ].
One key aspect of QbD is the use of process analytical technology (PAT) to increase process understanding and implementation of in-process controls rather than solely relying on end-product testing [ ]. PAT tools can be non-destructive and often do not require sample preparation. They provide real-time data due to their fast acquisition and processing times and are often non-invasive. Spectroscopic-based PAT tools offer a green alternative as they minimize waste compared to traditional wet chemistry. Their use allows the timely analysis of API and/or excipients in a drug product batch or continuous process based on statistical analysis of hundreds of data points (i.e., during each revolution in a bin blender or hundreds of tablets during tablet compression). They provide information to generate a design space and enable process monitoring.
Near-infrared (NIR) and Raman spectroscopies are promising analytical approaches for the timely monitoring of processes and the implementation of PAT. NIR has routinely been used to increase understanding of the manufacturing process and the CQAs pertaining to efficacy and performance of solid dosage oral products. A large fraction of pharmaceutical products are prepared as tablets and consequently important CQAs such as tablet assay and dissolution have been extensively explored by NIR and Raman spectroscopies [ , , , , ]. At-line tablet NIR and Raman methods have the potential to be implemented as part of real-time release testing (RTRt) strategies. RTRt is a system of testing throughout the manufacturing process that gives assurance that the product is of intended quality and that each manufacturing step delivers appropriate intermediate material properties to support the subsequent step. Such approaches expand the manufacturer’s product knowledge and enhances process understanding [ , ]. The majority of publications for non-destructive spectroscopic methods for at-line tablet assays and CU in support of RTRt strategies have been based on NIR [ , , , ].
Transmission Raman spectroscopy (TRS) is suitable for quantitative assessment of bulk contents such as capsules and tablets and has the potential to be implemented for RTRt [ , , , , , , , , , , , ]. Raman spectra have higher chemical specificity than NIR, are insensitive to water, and have the potential for higher analysis speed. The TRS method works by illuminating the sample on one side and collecting the transmitted light on the other, reducing the subsampling effect observed in backscattering Raman [ , ]. The resulting transmission Raman spectrum is highly representative of the sample mixture, enabling sensitive, accurate, and fast quantitative measurement of the whole object. Monte Carlo simulations and experimental results demonstrated that TRS sampling is biased towards the middle of opaque samples [ , , ]. Everall et al. demonstrated that the absolute transmitted signal in TRS significantly decreases with sample thickness but objects in the bulk yielded higher signals than those at either surface [ ]. Zhang et al. studied the relationship of the API content and the TRS spectral response in bilayered pharmaceutical tablets. The authors found that with increasing thickness of a non-API layer, the API Raman signal displayed an exponential decay as a function of the non-API layer thickness as well as the total tablet thickness. When increasing the weight/thickness of the API layer and keeping the non-API layer constant, the Raman signal reaches a maximum at a particular thickness and then decays as tablets become thicker [ ]. Quantitative TRS methods have been used to determine crystalline API content in amorphous solid dispersions from hot-melt extrusion (HME) processes [ ], for the rapid quantification of polymorph content in a solid dosage forms [ , ], and for the quantification of tablets with multiple APIs [ ].
Chemometric models based on TRS spectra and partial least squared (PLS) have been developed for the quantitative determination of API in tablets [ , , ]. For the purposes of regulatory submissions, an important factor to consider is the model’s contribution in assuring the quality of the product [ ]. Low- and medium-impact models (typically used to support product and/or process development) can be useful in assuring quality of the product but are not the sole indicators of product quality. A TRS at-line model for tablet assay and CU intended for RTRt release is considered a high-impact model. High level of oversight is expected due to the level of risk associated with the use of the model. It is important to ensure that variable ranges evaluated during model development are representative of conditions that would be expected during operation [ ]. To design a robust calibration model, tablets in a range of API concentration (typically 70–130%) are manufactured. Risk assessment and literature review showed important factors in designing a robust calibration, pertaining to the tablet physical properties such as thickness, hardness, and porosity. These parameters are all interrelated since they all inherently contribute to pathlength changes in the sample. Similarly, changes in the API particle size could alter the scattering behavior of the sample [ ]. The analytical method DS included any combination of these input variables to the method to provide assurance of the quality of the data produced by the method [ ]. A preliminary failure mode and effect analysis (FMEA) and literature review were performed to identify high-risk factors in the model prediction. An often-cited factor in quantitative spectroscopic method (such as NIR and TRS) is the impact of the change in optical scattering due to physical tablet properties and API particle size variations [ , , , , ]. Higher risk factors determined were the API particle size and the tablet weight, thickness, and hardness. To model this and help minimize their effect on method performance, tablets with attributes in the ranges shown in Table 1 were included in the calibration set. Table 1 Attributes and ranges for calibration tablets used during PLS method development Attribute Target Range API level (%) API level (% w / w ) 100 20 70–130 14–26 API particle size (D 50 , μm) 44 17–71 Tablet weight (mg) 300 275–328 Tablet hardness (SC) 12 8–16 Tablet thickness (mm) £ 4.6 4.0–5.1 £ Range of thickness given by ranges of weight and hardness
The aim of the present study was to investigate the feasibility of developing a fast at-line TRS method for the determination of core tablet potency and CU, in support of a product’s RTRt control strategy. The simultaneous effect of changes in the tablet hardness and weight (and indirectly tablet thickness), API particle size, and concentration was studied by using a novel experimental design method, generalized subset designs (GSDs). A classical full factorial design with more than two levels requires many additional experiments to provide results from all combinations. GSD designs can handle multilevel multifactor designs in calibrations with a reasonable number of experimental runs and orthogonal conditions [ ]. A design of experiments (DoE) based on GSD was proposed that is suited to create orthogonal arrays for a typical calibration verification with various factor levels and types. A method operable design region (MODR) was studied and proposed. The TRS method was fully validated, following ICH Q2 and EMEA NIR guidelines [ ]. To the best of the authors’ knowledge, this is the first report of analytical QbD applied to a high-impact model based on TRS spectra, including a design space to demonstrate assurance of quality and verification of method robustness. The applicability of the method to development batches was demonstrated and compared to a previously developed and validated NIR method.
Materials and Methods
Materials
A target formulation comprising 20.0% w / w API, fillers, disintegrant, glidant, and lubricant was prepared. Calibration standards were prepared at a 2.0-kg scale, using the same manufacturing procedure as production batches. Tablets were compressed from blends obtained from a blend-roller compaction-blend process to ensure good blend flow into the tablet press, as described in [ ]. The API concentration in the calibration blends encompassed the range of 14 to 26% w / w . Two kilograms of each final lubricated blend was compacted using a Piccola 8-station rotary press (Model BD, Riva S.A., Buenos Aires, Argentina). Target tablet weight was 300 mg for a target tablet assay of 60 mg/tablet. Tablet hardness was controlled during compression and tested using a tablet hardness tester (HT-300, Key International Inc.). From each calibration level, 10 tablets were selected. After collecting tablet weight and thickness, the tablets were tested by TRS and later tested by a standard HPLC. API content was expressed as percent weight per weight and used in the development of the PLS calibration models as the reference values. Tablets with varying hardness, weight (varying thickness), and API particle sizes were also prepared to be included in the calibration set and as an independent validation test set. The particular ranges from each attribute are listed in Table 1 .
Calibration Sets
Three different calibration models were developed. Model no. 1 was developed from tablets compressed using final blends encompassing the range of 14 to 26% w / w (70–130% of the target concentration) as described in the “ Materials ” section. Only API of the largest particle size (71 μm) was included in this calibration. Only tablets compressed at target tablet weight (300 mg) and hardness (8 SCU) were included in the model (giving a target thickness of 4.5 mm). Spectra from 10 individual tablets per concentration level (70, 80, 90, 100, 110, 120, and 130%) were used for a total of 70 calibration tablets. Tablets were analyzed by the HPLC reference method and concentration was expressed as percent weight per weight (% w / w HPLC ref).
In model nos. 2 and 3, tablets from the DoE design in Table 2 were incorporated in the calibration, besides the 70 calibration tablets used in model no. 1. Three individual tablets from each of the 31 experimental conditions in Table 2 were tested by TRS for a total of 163 tablets (including tablets from model no. 1). Tablets were analyzed by the HPLC reference method and concentration was expressed as percent weight per weight (% w / w HPLC ref) by weight adjusting the HPLC determined assay. Table 2 GS design Exp no. Weight (mg) Hardness (SCU) API size (D50, μm) Cal level (%nominal) % w / w (HPLC ref) % w / w (TRS Pred) API %recovery Thickness (mm) 1 284.2 8 17 70 13.53 13.44 99.33 4.32 2 285.3 8 17 90 17.7 18.02 101.81 4.30 3 283.8 8 17 110 21.72 21.81 100.41 4.37 4 283.4 8 17 130 25.39 25.57 100.71 4.37 5 287.0 16 17 80 15.72 15.61 99.30 4.05 6 285.0 16 17 100 19.87 19.78 99.55 4.09 7 282.2 16 17 120 23.74 23.61 99.45 4.07 8 316.8 8 17 80 15.67 15.82 100.96 5.13 9 316.6 8 17 100 19.92 20.15 101.15 5.14 10 315.8 8 17 120 23.9 24.22 101.34 5.10 11 316.1 16 17 70 13.51 13.58 100.52 5.10 12 315.5 16 17 90 17.69 17.59 99.43 4.65 13 313.8 16 17 110 21.76 21.74 99.91 4.65 14 316.0 16 17 130 25.3 25.12 99.29 4.67 15 285.0 8 71 80 16.1 16.00 99.38 4.76 16 285.7 8 71 100 19.87 20.09 101.11 4.49 17 284.1 8 71 120 23.82 23.62 99.16 4.54 18 287.3 16 71 70 13.52 13.51 99.93 4.26 19 284.1 16 71 90 17.68 17.81 100.74 4.16 20 285.4 16 71 110 21.61 21.73 100.56 4.20 21 285.8 16 71 130 25.31 25.00 98.78 4.21 22 315.0 8 71 70 13.53 13.68 101.11 5.29 23 317.2 8 71 90 17.71 17.68 99.83 5.14 24 317.4 8 71 110 21.64 21.82 100.83 5.00 25 316.0 8 71 130 25.54 25.47 99.73 5.14 26 315.9 16 71 80 15.71 15.55 98.98 4.76 27 316.4 16 71 100 19.78 19.94 100.81 4.60 28 314.8 16 71 120 23.96 23.99 100.13 4.65 29 300.4 12 44 100 19.98 20.08 100.50 4.56 30 301.0 12 44 100 19.85 19.91 100.30 4.53 31 299.9 12 44 100 19.89 20.06 100.85 4.53
Test Set
An independent test set was used comprised of tablets from the 31 experimental runs from the DoE. Four independent tablets from each experimental design were tested by TRS and later by HPLC to determine the percent weight per weight of API in each tablet, for a total of 124 tablets.
Validation Set
An independent set of tablets with API and excipient lots not previously used in the calibration or test sets was manufactured and used for validation.
Transmission Raman Instrumentation
Transmission Raman spectra were collected using a Cobalt TRS 100 spectrometer (Cobalt Light systems Ltd., UK). The system operates at 830-nm laser excitation wavelength. The laser power was set to 600 mW for all of the experiments. The single scan acquisition time was 3 s per measurement and three co-additions were employed to improve signal to noise ratio for thicker tablets, resulting in a total scan time of 9 s for each sample.
Spectra were collected from approximately 40 to 2400 cm −1 at a resolution of 0.2 nm. A constant laser beam illumination diameter of 8.0 mm and a Raman collection diameter of 6.0 mm were employed. All tablets were placed onto an opening in an x, y multi-well autosampler. This custom multiwell autosampler was designed to maximize the tablet irradiation area (8.0 mm), since preliminary feasibility results and literature data [ ] showed that lower prediction errors were observed by irradiating a high sample area. The laser source always comes from the bottom. Spectra were recorded as Grams spc files and imported into either SIMCA 14 (Sartorius Stedim Data Analytics) or TQ Analyst/OMNIC (Thermo Fisher Scientific, Madison, WI) software packages for data inspection and quantitative analysis.
NIR Instrumentation
Thermo® Antaris MDS II FT-NIR with an InGaAs detector was used. The instrument uses a MultiPro® carousel-type autosampler with a custom wheel built specifically for this particular core tablet. Dual detection mode was used (reflectance and transmission spectra). In the transmission mode, the wavelength range was 12,000–7500 cm −1 . The resolution was 8 cm −1 . The number of sample scans was 128. The number of background scans was 256.
HPLC Reference Method
An HPLC method was used to quantitate the active in tablet. The tablet is extracted using water:acetonitrile:TFA (80:20:0.05) via sonication followed by shaking, or using Distek Prep Engine. The separation is achieved on an XSelect CSH C18, 30 mm × 3 mm i.d., 3.5-μm particle size column with UV detection and 254 nm. External standard is used for quantitation.
Tablet Hardness
After the weight and dimensions of the tablets were ascertained, the crushing strength was determined using a tablet hardness tester (HT-300 hardness tester form Key International, Inc.) and the units were reported in Strong-Cobb Units (SCU). Tablet hardness was measured on a unique set of tablets made under equivalent conditions (collected during the particular batch manufacturing) since this test is destructive.
Calibration Design Space
A preliminary failure mode and effect analysis (FMEA) and literature review were performed to identify high-risk factors in the model prediction. An often-cited factor in quantitative spectroscopic method (such as NIR and TRS) is the impact of the change in optical scattering due to physical tablet properties and API particle size variations. Higher risk factors determined were the API particle size and the tablet weight, thickness, and hardness. The impact of these risks factors in transmission NIR tablet methods has been studied [ , , , , , ]. To model this and help minimize their effect on method performance, tablets in the ranges shown in Table 1 were compressed and included in the calibration model nos. 2 and 3.
A DoE experiment setup based on a generalized multifactorial screening design strategy was used. This DoE type named generalized subset designs (GSDs) from MODDE Pro (Sartorius Stedim Data Analytics) is suited to create orthogonal arrays for a typical calibration verification with various factor levels and types [ ]. The total number of possible combinations of factor settings for a two-level design on tablet weight, tablet hardness, and API particle size and a seven-level design on API concentration is 56 (7×2×2×2). The DoE objective was to select a rational subset of all possible combinations and still prove that all individual API calibration levels would work properly with enough experiments for a good statistical assessment. A subset of 28 experiments plus three replicate center points was selected for a total of 31 experiments (Table 2 ). Samples 29 to 31 correspond to three replicate center points excluded in the initial design of the GSD approach. This subset is as close to a perfect subset of all 56 as possible, with good statistical assessment capabilities.
This design enables the evaluation of all linear terms and two-factor interactions with high precision and a possible quadratic effect of the CQA API concentration.
The design enables a complete analysis of the probability of the method of meeting the specifications, as established in the analytical target profile (ATP). Table 2 shows the factors (weight, hardness, API particle size, and calibration level) and the responses (% w / w HPLC, % w / w TRS, and thickness). Although calibration model nos. 2 and 3 were both appropriate and showed a RMSEP within the ATP (≤ 3%), calibration model no. 3 was selected to calculate the API % recovery values (as shown in Eq. 1 ), since the RMSEP for calibration model no. 2 was very close to the specification given in the ATP. $$ \%\mathrm{Recovery}=\frac{\%w/w\ \left(\mathrm{TRS}\right)}{\%w/w\left(\mathrm{HPLC}\right)}\times 100 $$ (1)
Results and Discussion
Method Requirements and Performance Criteria
One of the first steps in the method design and development is to define the method requirements and the performance criteria of the analytical procedure. It is important for manufacturers to understand the factors that can affect the performance and suitability of the procedures and the approaches that can be used to validate them [ ]. The requirements are usually independent of the analytical technology, with the focus to ensure that the CQAs are measured with an appropriate level of quality.
The concept of QbD applied to analytical methods was introduced a decade ago and has been increasingly applied to support pharmaceutical products [ , , , , , ]. In the framework of the analytical QbD, the ATP defines the design requirements for the performance of an analytical procedure and is independent of the analytical technology [ ]. A robust TRS model intended for RTRt applications should meet high standards of performance (high-impact model) since the prediction from the model is a significant indicator of the quality of the product [ ].
Table 3 shows the ATP for at-line TRS method for tablet potency and CU. Method requirements include specificity, range, linearity, accuracy, and precision. The analysis time and availability for at-line data acquisition are also considered. Another important requirement is method robustness. Accurate potency prediction over the expected range of these parameters is a requirement in the ATP. Table 3 ATP for at-line TRS method for tablet potency and CU Parameter Desired method performance Specificity API quantification in presence of excipients. Rejection of samples outside of its defined scope Range 70–130% LC (14–26% w / w ; 42–78 mg/tab) Linearity R 2 ≥ 0.98. Slope ≥ 0.95 and ≤ 1.05 Accuracy Prediction between 97 and 103% RTR (< ± 3.0% relative error) Precision % RSD of 10 replicate measurements ≤ 2% Analysis time Acquisition time in the order of 1 min Robustness Accurate prediction at specified range of API particle size Robust to range of tablet weight, hardness, thickness
Method Development
Preliminary feasibility work demonstrated that the API is a particularly good Raman scatterer. Figure 1 shows the Raman spectra of the API and main excipients in the formulation. Fig. 1 Raman spectra of croscarmellose sodium (1, red), API (2, pink), microcrystalline cellulose (3, purple), magnesium stearate (4, blue), and lactose anhydrous (5, green)
As shown in Fig. 1 , there is good selectivity to the API, with strong and medium Raman frequencies at higher wavenumbers where there is small overlap from the excipients above 1500 cm −1 . Part of the preliminary feasibility work was to determine optimal experimental conditions such as exposure time, number of acquisitions, diameter of the incident probe beam, and the Raman collection diameter. A constant laser illumination diameter of 8.0 mm and a Raman collection diameter of 6.0 mm were found to be optimal. Excellent signal to noise ratio was determined with 3 s, 3 co-additions, for a total of 9 s analysis/tablet.
Figure 2 shows the raw Raman intensity vs. tablet thickness. The range of tablet weight and tablet hardness used in the study (Table 1 ) produced tablets with thickness in the range 4.0–5.1 mm with low tablet weight (mg/(low)) and high tablet weight (mg/(high)). Fig. 2 Tablet thickness vs. raw Raman intensity at 1611 cm −1 at low tablet weight (mg/(low) in green) and high tablet weight (mg/(high) in blue)
As previously observed, the absolute transmitted signal in TRS significantly decreased with sample thickness as shown in Fig. 2 . The API Raman signal displayed an exponential decay as a function of the total tablet thickness [ , , ].
Calibration Design
Tablets used for calibration were prepared as described in the “ Transmission Raman Instrumentation ” section. Figure 3 a shows the Raman spectra from tablets in Table 2 . As observed in the figure, the observed Raman signal intensity at 1611 cm −1 increases with increasing API concentration. To remove pathlength differences and spectral interference, chemometric preprocessing methods are often used including standard normal variate (SNV), multiplicative scatter correction (MSC), and derivatives (first and second derivatives). Figure 3 b shows the spectra in Fig. 3 a after preprocessing (baseline offset, unit area normalization, SG 11 pt., first derivative, second-order polynomial). Fig. 3 Raw Raman spectra from tablets included in the calibration model ( a ) and after preprocessing (baseline offset, unit area normalization, SG 11 pt., first derivative) ( b )
Figure 4 shows the % w / w reference (HPLC) vs. predicted (TRS) calibration models, using the preprocessing conditions listed in Table 4 . Figure 4 a shows calibration model no. 1, developed by incorporating only tablets with one API particle size (D 50 , 71 μm). The preprocessing consisted of SNV, Savitzky–Golay smoothing (11 points), first derivative, second-order polynomial. The wavelength range of loadings for this method was 1050–1680 cm −1 . This model showed an excellent correlation coefficient ( R 2 ) and very low root mean squared error of calibration (RMSEC) and root mean squared error of cross-validation (RMSECV) with only one factor or latent variable (first loading corresponding to API spectrum). However, the ability of the model to accurately predict tablets with other API particle sizes (API D 50 , 44 and 17 μm) was poor (prediction error up to 10.8%). The prediction error using model no. 1 for tablets with high weight/low hardness (highest thickness of 5.1 mm) and tablets with low weight/high hardness (lowest thickness of 4.05 mm) at target concentration was around 10%. These samples showed high leverage in calibration model nos. 2 and 3 as shown later in this section. Fig. 4 Calibration model no. 1 ( a ), calibration model no. 2 ( b ), and calibration model no. 3 ( c ). Blue circles represent samples in the calibration set; and orange triangles, samples in the test set Table 4 TRS PLS models of performance parameters Model no. Pretreatment Region (cm −1 ) R 2 Slope RMSEC (%) RMSECV (%) Factors (LV) RMSEP batches 1 SNV, SG 11 points, 1st der. (only API D 50 , 71), 2nd order polynomial 1050–1680 0.992 1.027 1.75 1.76 1 10.8% (API D 50 , 44 and 17) 2 SNV, SG 11 points, 1st der. 2nd order polynomial 1050–1680 0.982 0.985 2.15 2.13 3 2.56% 3 Baseline offset, area normaliz., SG 11 points, 1st der., 2nd order polynomial 1050–1680 0.990 0.990 1.65 1.73 3 1.74%
Figure 4 b shows the calibration model no. 2 using the 163 tablets described in calibration tablet set in the “ Calibration Sets ” section. The data preprocessing consisted of spectral normalization (standard normal variate SNV over the 200–1680 cm −1 region), followed by first derivative, Savitzky–Golay 11 data point window, and second-order polynomial. The wavelength range used for this method was 1050–1680 cm −1 . The RMSEC was 2.15% and RMSECV was 2.13% with three PLS components. The predictive capability of samples in the test set is within the ATP (RMSEP, 3.0%). For this model, the highest RMSEP was observed in tablets with low weight and high hardness (lower thickness) and high weight and low hardness (highest thickness) with an RMSEP around 2.5%.
The most successful model is shown in Fig. 4 c. Model no. 3 shows the calibration plot using the same 163 tablets used in model no. 2 but different preprocessing. The spectral preprocessing consisted of baseline offset, followed by area normalization in the 1050 to 1680 cm −1 region, Savitzky–Golay smoothing 11 points, first derivative, and second-order polynomial. For this model, the RMSEC was 1.65% and the RMSECV was 1.73 with three factors. The loading plots showed that the first loading explains 92.70% of the variance, the second loading explains 98.96%, and the third loading explains 99.7% of the variance. The predictive capability of samples in the test set was within the ATP (RMSEP, 1.74%). Johansson et al. found similar benefits when truncating the modeling range [ ].
Effect of Tablet Weight, Hardness, API Particle Size, and Concentration
The statistical significance of the tablet weight, hardness, API particle size, and API calibration level on the %Recovery was determined. For this purpose, MODDE Pro (Sartorius Stedim Data Analytics) was used as described in the “ Calibration Design Space ” section. Statistically significant effects were identified if the calculated p value was ≤ 0.05. Table 5 shows the coefficients and the significance test. Table 5 Coefficients’ (scaled and centered) overview list for %RTR API %RTR Coeff. SC Std. Err. P Conf. int (±) Constant 100.464 0.173 0.000 0.357 Weight (mg) 0.169 0.124 0.183 0.255 Hardness (SCU) − 0.330 0.122 0.013 0.253 API PS (D50) − 0.076 0.122 0.538 0.253 Cal level (%nominal) − 0.073 0.122 0.557 0.253 Cal level×Cal level − 0.285 0.128 0.036 0.265 Har×PS 0.256 0.119 0.042 0.246
Significant values are in italicized. As shown in Table 5 , hardness, the two-factor cross-term hardness×particle size, and the quadratic term cal level×cal level showed to be statistically significant. Figure 5 shows the factor effects in a graphical representation (prediction plots). Fig. 5 The factor effects plots for tablet weight ( a ) and API PS ( b ) at 95% prediction interval
The prediction plots display the predicted values of the selected responses (continuous line), when the factors vary over their respective ranges (upper and lower 95% confidence intervals shown as a white area). As shown in the figure, the investigated factor average effects are well within the specifications. The tablet hardness was found to have some small impact on tablet prediction accuracy; however, the magnitude was ± 1.0% w / w across the range of 8–16 SCU, which is close to the intermediate precision of the method. Tablet weight and API particle size were demonstrated to have no practical impact on method prediction.
In Table 5 , it is shown that it was possible to detect some additional significant effects; the first one is a quadratic effect of API concentration and the second one is an interaction between tablet hardness and API particle size. A complete analysis of the probability to get data outside the specifications for API prediction can be done by using the model and predict the probability of being outside specification for all combinations in the DoE area covered by the investigated factors (MODDE Pro, Sartorius Stedim Data Analytics). As an illustration of the probability analysis, the most critical factors are illustrated in Fig. 6 . Figure 6 a shows the factor effect plot for tablet hardness and Fig. 6 b shows the factor effect plot for tablet concentration at 95% prediction interval. Fig. 6 Factor effect plots for tablet hardness ( a ) and concentration ( b ) at 95% prediction interval
The plots display the predicted values of the selected responses: when the factor varies over its range, all other factors in the design are held constant at their averages. The points displayed in this plot are the observations from Table 2 . As observed in the figure, all response measurements are inside the specification limit.
The complete four-dimensional (four factors) probability map provides evidence that the analytical method can meet the specification with respect to the investigated CQA with high probability [ ]. The most critical two-dimensional space out of the four-dimensional space is illustrated in Fig. 7 . In this figure, factors’ weight and API particle size that represent dimensions 3 and 4 are set to 300 mg and 17 μm, representing a worst case scenario. The approach takes into account the model parameter uncertainty and provides information about how often the specification will be met (MODDE Pro 12). Fig. 7 Probability of failure map (API %nominal) for hardness vs. calibration level
The estimate reflects the probability of meeting the specification imposed in the CQA (in this case 97–103% nominal). The highest probability of getting a result outside the specification is 0.5%, covering only 0.04% of the investigated region. This concludes a very robust method.
NIR Method Development
Transmission spectra were used to build the NIR PLS model. The spectral data preprocessing consisted of SNV in the region of 8580–11,620 cm −1 followed by Savitzky–Golay smoothing (19 points), first derivative, and second-order polynomial. The wavelength range of loadings was 8700–9300 cm −1 . The number of factors was 3. The RMSEC was approximately 1.07% w / w . NIR method development and validation was previously described [ ].
Validation
As any other analytical method for product release, NIR and TRS methods should be fully validated. There is not a specific guideline for method validation for TRS. The TRS method was validated using the general recommendations from the ICH Q2 [ ] validation guideline and the EMEA NIR guideline [ ]. Table 6 shows the validation parameters and results. Table 6 Validation parameters, acceptance criteria, and results for the NIR and TRS model no. 3 Parameter Procedure Result NIR Result TRS Acceptance criteria Specificity The correlation coefficient ( R ) between the 1St loading and the API spectrum R , 0.952 R , 0.983 R ≥ 0.950 Linearity and range 7 levels (~ 70 to ~ 130%). Analyze tablets by NIR and TRS and HPLC. Plot the HPLC potency vs. NIR or TRS predicted potency R 2 = 0.995 R 2 = 0.990 R 2 ≥ 0.96 Accuracy Use samples at 70%, 100 and 130%LC. Determine average %difference (%diff) NIR or TRS vs. HPLC % Diff 70%, 0.45% % Diff 70%, − 0.95% % Diff ≤ 3% % Diff 100%, 0.73% % Diff 100%, 0.92% % Diff 130%, 1.9% % Diff 130%, − 1.2% Precision-scan repeatability Reproducibility in placement position 1. Calculate %RSD %RSD, 0.25% %RSD, 0.65% %RSD ≤ 2% Reproducibility in placement position 10. Calculate %RSD %RSD, 0.32% %RSD, 0.60% %RSD ≤ 2% Intermediate precision Scan multiple tablets at 90, 100, and 110% LC by two different analysts on two different days. Calculate the root mean squared %difference (RMSD) Analyst-to-analyst RMSD, 0.8% Analyst-to-analyst RMSD, 1.1% %RMSD ≤ 3%. Day-to-day RMSD, 1.0% Day-to-day RMSD, 1.8% Robustness Demonstrate the robustness of the method to tablet thickness and hardness %Diff low hardness, 0.7% Demonstrated in the “ Effect Of Tablet Weight, Hardness, API Particle Size, And Concentration ” section %diff ≤ 3%. %Diff high hardness, 0.4%
The analytical method validated included the instrument parameters (hardware, mode of detection, number of scans, wavelength region, software, data archival, sampling device) and the PLS chemometric model (calibration model no. 3). The method included factors that must be met to enable analysis, related to the instrument performance, the suitability of the spectra used for prediction, and the sample (sometimes called system suitability tests). When the PLS model was used to predict a new unknown sample, the uncertainty and identity values were used to detect out-of-scope samples [ ]. ID and uncertainty values can be trended over time and used to determine the method’s fitness for purpose (or in-scope predictions). In some cases, changes in API or excipient properties not covered in the MODR force the inclusion of additional calibration standards to the model to account for a new source of variability. This may force the use of different preprocessing conditions, e.g., normalization, derivatives, smoothing, etc. In this case, a revalidation of the method is required, since it is outside of its scope.
Application of Model to Development Batches
For batches 1 to 4, 30 core tablets were sampled at the end of the compression process. From this sample, 10 tablets were analyzed by TRS. The same tablets were analyzed by NIR and later submitted to HPLC analysis for potency and CU determination. For batches 5 to 7, 10 core tablets were collected from 15 evenly spaced time points throughout the compression operation, for a total of 150 tablets.
The mean predicted values by NIR and TRS (%LC) were plotted in Fig. 8 and compared to the mean HPLC values. As observed in the figure, the mean prediction for all the batches was within 1% of the HPLC value. Both methods (NIR and TRS) were suitable for application or RTRt of core tablets. One significant difference is the analysis time. For a typical sampling plan of 150 tablets, a total of 225 min is needed to complete the tablet analysis by NIR. TRS is an order of magnitude faster, completing the same analysis in 22.5 min. This translates in less operator time. Fig. 8 Comparison of predicted potency for seven process development batches predicted with TRS PLS model no. 3 (squares), NIR PLS model (circles), and HPLC (diamonds)
CU was determined following the USP <905> procedure [ ]. For this purpose, the mean potency (% label claim), the standard deviation (SD), and the acceptance value (AV) were calculated. Results are shown in Table 7 . For all batches, only L1 level testing was required (K 2.4, AV < 15%). Table 7 CU results for batches 1 to 4 as per USP <905> Batch no. HPLC NIR TRS %LC SD AV (%) Pass/fail %LC SD AV (%) Pass/fail %LC SD AV (%) Pass/fail 1 99.75 1.25 2.99 Pass 99.63 1.31 3.15 Pass 100.72 1.01 2.42 Pass 2 99.00 1.29 3.10 Pass 98.80 1.30 3.12 Pass 99.51 1.15 2.75 Pass 3 99.97 1.56 3.75 Pass 99.82 1.36 3.26 Pass 98.72 1.34 3.22 Pass 4 99.01 0.40 0.96 Pass 99.30 0.48 1.16 Pass 98.61 0.56 1.34 Pass
The question of how to sample a batch for RTRt and what the acceptance criteria are is important to the utility of the application. Acceptance criteria tests have been proposed to be used as a batch-release specification when testing a large number of dosage units. One example is the Modified PhRMA SET Large N Test [ ] which is a test included in the European Pharmacopeia Chapter 2.9.47 [ ]. This test is a one-stage counting test where the number of results (C) outside 85 to 115% LC is counted and assessed against a threshold [ ]. During compression of batches 5 to 7, 10 samples were collected at 15 evenly spaced time points throughout the compression process, for a total of 150 tablets per batch. These tablets were evaluated for potency, first by TRS and NIR and then by HPLC, keeping a one to one tablet relationship so that the two datasets could be compared. Table 8 shows the CU results for batches 5 to 7 as per Modified PhRMA SET Large N Test. The acceptance limits (CV, %) for content uniformity ( N = 150, target 100) guarantee, with 90% assurance, that at least 95% of the samples tested for content uniformity will pass the USP test. As shown in Tables 7 and 8 , all batches passed CU criteria. Table 8 CU results for batches 5 to 7 as per Modified PhRMA SET Large N Test Batch no. HPLC NIR TRS %LC SD CV (%) Pass/fail %LC SD CV (%) Pass/fail %LC SD CV (%) Pass/fail 5 99.87 0.61 5.43 Pass 99.30 0.69 5.33 Pass 100.12 1.33 5.42 Pass 6 100.05 0.72 5.31 Pass 99.30 0.74 5.33 Pass 100.96 1.64 5.16 Pass 7 100.17 1.15 5.40 Pass 99.99 1.06 5.44 Pass 99.13 0.83 5.28 Pass
Conclusions
A fast non-destructive TRS method for at-line tablet potency and CU was developed and validated. The effects of tablet hardness, weight, API particle size, and concentration were studied simultaneously. Few experimental runs were required based on an orthogonal design (GSD). The GSD handled a multilevel multifactor design for calibration with a reasonable number of experimental runs. A minimum number of experiments (31 runs) allowed for the evaluation of model robustness within the MODR. Both methods showed some influence to tablet physical properties. These were minimized by appropriate selection of chemometric preprocessing and wavelength region and by including tablets with different ranges of weight, hardness, and API particle size in the calibration set.
Two calibration models (calibration model nos. 2 and 3) were appropriate and showed RMSEP within the ATP (≤ 3%). Calibration model no. 3 was selected to calculate the %Recovery. The %Recovery was used to determine the statistical significance of the tablet weight, hardness, API particle size, and API calibration level. Statistically significant effects were identified if the calculated p value was ≤ 0.05. The main effect of hardness, the cross-term hardness×particle size, and the quadratic term cal level×cal level showed to be statistically significant. These terms were found to have a small impact on prediction accuracy (≤ ± 1.0% w / w ) across the MODR (close to the intermediate precision of the method) and had no practical impact on method performance established in the ATP. The TRS method was fully validated, following ICH Q2 and EMEA guidelines. The applicability of the method to process development batches was demonstrated and compared to a previously developed and validated NIR method. Core tablets from seven development batches were analyzed by TRS and NIR and later by HPLC. The average prediction for all the batches was within 1% of the HPLC reference value. For a typical sampling plan of 150 tablets, TRS analysis was an order of magnitude faster than NIR.