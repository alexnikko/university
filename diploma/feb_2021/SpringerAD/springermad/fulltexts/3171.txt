Introduction
Since the approval and commercialization of the first therapeutic monoclonal antibody in 1986, Orthoclone OKT3, which was used for prevention of kidney transplant rejection, therapeutic monoclonal antibodies and antibody-related products such as Fc-fusion protein, antibody fragments, and antibody-drug conjugates have become the dominant class within the biopharmaceutical industry [ ]. In 2013, global sales revenue for all monoclonal antibody products was nearly $75 billion [ ], which represented approximately half of the total sales of all pharmaceutical products. Monoclonal antibody (mAb) has experienced strong growth in the biopharmaceutical market, with indications expanding across multiple therapeutic areas, including immunology, oncology, infectious diseases, and other areas [ ]. Merck’s Keytruda and Bristol-Myers Squibb’s Opdivo have shown breakthrough results in the treatment of melanoma and small cell lung cancer. In fact, the continued interest in antibody product development is partially driven by the rapid advancement of our understanding of disease at a molecular level. Compared to small molecule products, or chemically synthesized products, monoclonal antibodies often show higher efficacy, because they provide the most rapid route to a clinical proof-of-concept for activating, inhibiting, or blocking disease targets [ ].
Monoclonal antibodies are typically produced by mammalian cell culture in bioreactors that range in scale of 1–20 m 3 . Regardless of scale, the production and purification of mAb present important challenges [ ]. Such a complex multistep process, which encompasses several seed and production bioreactors, as well as a number of chromatography and filtration steps, needs to be carefully monitored and controlled as many of the in-process variables can impact the product quality. Recent developments at the FDA recommend the application of risk-based approaches to control product quality based on an enhanced process and product understanding [ ]. In our previous studies, we had established a framework that integrates design of experiments (DoE) and principal component analysis (PCA) to identify process parameters that have significant impact on critical process attributes [ ]. Hence, we can now control the process by ensuring that these parameters are operated within the acceptable range, and thus improving process robustness and consistency. Furthermore, since any quality issues in manufacturing will delay the release of a batch and can sometimes disrupt the supply chain, we developed a systematic framework to predict future manufacturing performance or product quality using a Bayesian approach [ ]. Therefore, in cases where we suspect a potential deviation in the future manufacturing batches, appropriate mitigation strategies can be developed in advance to reduce risks or batch failures.
In addition to identifying critical process parameters, and developing a framework to predict drug manufacturing process performance, it is very important to have appropriate impurity acceptance criteria for process intermediates. In fact, defining the in-process acceptance criteria is part of a control strategy, which will eventually go into the drug validation regulatory package. While there is considerable literature describing the different approaches to define acceptance criteria or specification for the final drug substance, which directly links to the clinical efficacy and safety [ ], the industry is still learning the different ways to set process intermediates acceptance criteria. These acceptance criteria lead to a tradeoff between the likelihood a consumer will acquire a suboptimal dose and the likelihood a lot will fail release [ ]. Although narrower acceptance criteria are more likely to ensure a successful batch release, and to achieve pre-defined safety and efficacy, it could potentially reject batches that would otherwise have met the final drug specification. Hence, it is critical to establish accurate and appropriate acceptance criteria.
While the end goal of drug manufacturing is to meet the final drug specification by having stringent control of process intermediates, there are several ways of establishing in-process acceptance criteria. A widely used approach is to use the final drug substance or product specification as a reference, and deduce the specification for products from previous steps based on the process capability of those steps. For instance, if the final process step has a constant 3% impurity reduction, and if the specification for the final product is 2%, then the product of the step before the final step, or the input to the final process step should have impurity level no greater than 5%. However, the difficulty here is in knowing what the impurity reduction for each step is.
One approach is to develop a mechanistic model of a specific process, and leverage this model to predict the input specification based on the final output specification. However, this approach is very process specific, and would involve significant amount of time and effort for model development. Hence, this approach is rarely used for acceptance criteria setting. Another way to understand process capability is to do a worst case scenario study. In such study, we challenge the chromatography column or filter with a significant higher than typical amount of impurity, and find out the maximum impurity reduction this step can achieve. A challenge with this approach is that sometimes it could be difficult to find a feed stream with such a high impurity level while ensuring these impurities are representative. In addition, a lot of experiments need to be conducted before we are able to reach the saturation point. Another other simpler approach used in the industry to understand process capability is to compare the average impurity levels of the feed and the product, and the average reduction is used to calculate the in-process acceptance criteria. While this is relatively straightforward, one caveat is that it assumes that the impurity clearance is independent of the feed impurity level. For instance, two feeds with different impurity levels are assumed to undergo the same degree of reduction; however, this is not always the case, as shown later in our study.
Building on our prior modeling work in pharmaceutical manufacturing [ , , , ], we propose an alternative way to calculate process capability, by using neural network to characterize the relationship between the feed and the product quality attributes of a process step. It is a promising modeling technique especially for datasets having the kind of non-linear relationships that are frequently encountered in pharmaceutical processes.
Contrast to what is commonly practiced in the industry, we do not have to assume that the impurity reduction is independent of the feed. The neural network model can identify and learn correlative patterns between feed and product data pairs. Once trained, it may be used to predict the product impurity level based on the feed impurity level, or vice versa. One of the most useful properties of neural networks is their ability to generalize.
Diagnostic plots will be used to evaluate the goodness of fit before arriving at the final neural network model. In addition, we will compare this approach with the conventional approach practiced in the industry, and determine if there is any difference in model prediction accuracy. Finally, we will discuss how we can use both approaches in setting acceptance criteria for process intermediates.
Methodology
Overview of Monoclonal Antibody Production Process
A typical monoclonal antibody production process consists of an upstream process (USP) section and a downstream process (DSP) section, as shown in Fig. 1 . While the USP includes inoculation, cell culture, and primary recovery, the DSP consists of Protein A chromatography, followed by two ion exchange steps (follow-through and bind-and-elute), virus filtration and ultrafiltration. In general, biological molecules are much more complex than small molecules, or chemically synthetic molecules, and they are very sensitive to changes in the production process. Therefore, it is imperative to closely monitor the critical quality attributes for process intermediates, such as Protein A product (or IEX I feed), or IEX I product (or IEX II feed), to ensure the final drug substance and product meets the predetermined specification. In our case study, we focus on the clearance of protein aggregate through various downstream chromatography steps. Protein aggregation is a key challenge in the development of protein biotherapeutics. Aggregates are defined as any physically associated or chemically linked non-native species of two or more protein monomers, as shown in Fig. 2 [ ]. It is widely accepted in the scientific literature that protein aggregation can augment a protein-specific immune response, and therefore lead to the formation of anti-drug antibodies (ADA) [ , ], which can cause adverse events, such as neutralization of endogenous protein or reduce efficacy of a biotherapeutic [ ]. Hence, it is critical to reduce protein aggregate level, to ensure maximum drug efficacy. Fig. 1 Typical monoclonal antibody manufacturing process Fig. 2 Overview of protein aggregate formation
Data Collection
The data from the case study are a combination of actual data from several monoclonal antibody manufacturing processes and simulated data. All data and simulated models have been validated by internal quality control group. These data have been scaled for confidentiality purposes but the general trends are preserved.
Approach to Estimate Process Capability
Conventional Approach
The conventional approach, or what is commonly practiced in the industry, to understand process capability, or the impurity reduction of a particular step, is as follows: $$ {\widehat{Y}}_{prod,i}={Y}_{feed,i}-{\overline{Y}}_{red} $$ where the product aggregate level ( \( {\widehat{Y}}_{prod,i}\Big) \) is estimated as the difference between the feed aggregate level ( Y feed , i ) and the average aggregate reduction ( \( {\overline{Y}}_{red}\Big) \) .
Alternative Approach—Neural Network
Although the conventional method is relatively straightforward, it assumes the impurity reduction is constant regardless of the feed impurity level. However, this is not true in all cases. For example, protein aggregates usually consist of a mixture of multi-mers, such as dimer, trimer, and other higher-order multi-mers. The higher-order aggregates are usually easier, and the first to be purified while dimers are much more challenging to be reduced. Hence, it is often the case that if the feed stream has a higher level of aggregates, we observe a higher percent of aggregate reduction, since most of the higher-order aggregates are being removed. On the other hand, if the feed stream has very low level of aggregate, which is most likely comprised of dimers, the impurity reduction might be much smaller since the dimers are difficult to remove. Hence, for the same purification step, impurity clearance could vary based on the feed impurity level, and using the conventional estimation method would not be able to reflect this phenomenon.
Here we propose the use of neural network to relate the feed impurity level to the product impurity level, such that the product impurity level is a function of the feed impurity level. The model is built and simulated using MATLAB®.
The neural network models are composed of simple elements operating in parallel. The connection between elements largely determines the network function. A neural network can be trained to perform a particular function by adjusting the value of the connections (weights) between elements [ ]. Hence, neural networks are able to recognize patterns even from noisy and complex data in which there is a considerable degree of variation and to estimate non-linear relationships.
The use of neural networks is an expanding area in the field of pharmaceutical research. Some of the important applications are in molecular modeling, pharmacokinetic and pharmacodynamics modeling, and in vitro / in vivo correlation [ , , , ]. However, the application of neural networks in understanding process capability and define process specification is still limited. In our study, we develop neural network models to correlate the feed aggregate level with the corresponding product aggregate of several chromatography steps.
Neural Network Model Selection and Evaluation
Typically, neural networks are adjusted, or trained, so that a particular input leads to a specific output [ ]. As shown in Fig. 3 , the network is trained, by comparing the model-predicted output with the target, until most of the network outputs match the targets. Many such input-target pairs are needed to train a network [ ]. Fig. 3 Overview of Neural Network
In our study, the neural network is trained by backpropagation algorithm, which is the most widely used neural network learning method [ ]. As shown in Fig. 4 , the input layer communicates with the external environment and presents the pattern to the neural network [ ]. The hidden layer is the collection of neurons which has transfer function (usually sigmoidal function), applied on it, as well as provides an intermediate layer between input and output layer [ ]. In order to ensure the performance of the neural network, it is critical to select an appropriate topology, and two of the important governing elements are the training algorithm within the backpropagation family, as well as the number of hidden layer and nodes. 1. Training Algorithm: The training algorithm depends on whether the network is being used for pattern classification or function approximation. Since we are trying to approximate the correlation between the feed and product aggregate, some of the common algorithms are Levenberg-Marquardt (LM), Scaled Conjugate Gradient (SCG), and BFGS Quasi-Newton (BFG). For function approximation problems, LM has the fastest convergence. The performance of BFG is similar to that of LM, but it does not require as much storage as LM. However, the computation required for BFG increases geometrically with the size of the network. SCG algorithm seems to perform well over a wide variety of problems, particularly for networks with a large number of weights [ ]. Fig. 4 Neural Network Architecture
2. Hidden Layer and Nodes: The standard network that is used for function fitting is a two-layer feedforward network, with a sigmoid transfer function in the hidden layer and a linear transfer function in the outer layer. Since in our study, we have a continuous mapping from one finite space (feed aggregate level) to another (product aggregate level), we have chosen a single hidden layer [ ]. The number of nodes in the hidden layer is set to a default of 10. This number can be increased to enable a better model fit.
To select an appropriate algorithm for a dataset, we divide the data into three groups, 70% of the data is used for training, while 15% of the data is used for validation and the remaining 15% is used for testing. The number of nodes in the hidden layer is initially set to default. Each dataset is run using all three algorithms (LM, SCG, and BFG), and the sum of square error (SSE) and number of epoch, or iteration, are recorded. The algorithm that yields a low SSE with a reasonable epoch is selected to carry forward.
Once the training algorithm is established, we adjust the number of nodes to possibly improve the SSE and epoch. The number of nodes that yields a low SSE with a reasonable epoch is selected.
To ensure we have a good model, we evaluate the regression plots of network outputs with respect to target for training, validation, and test sets. For a good model fit, most of the data should fall along a 45 degree line, where the network outputs are equal to the targets.
In addition, an error (errors = targets − output) histogram is plotted to obtain additional verification of network performance. For a good model fit, the error distribution should be roughly normal centers around 0.
Comparison Between Conventional and Neural Network Approaches
For the conventional method, the average aggregate reduction is calculated by using all the available data from each process. However, in terms of the neural network model, the dataset is first divided into training, validation, and testing sets. A model is initially developed using the training dataset, and adjusted and validated using the validation and testing dataset.
To characterize how well each model describes the data from which it is derived, both the conventional and neural network models are reapplied to the original dataset, and the following evaluation criteria are used [ ]: 1. Observed vs. Predicted: After an appropriate model is established for each approach, product aggregate level ( Y prod ) is estimated using the models and the feed aggregate ( Y feed ) data. The predicted product aggregate ( \( {\widehat{Y}}_{prod}\Big) \) is then compared with the actual product aggregate ( Y prod ). Deviation from the diagonal and the presence of any significant trend indicate a potential lack of fit. 2. Residual Plot: Ordinary residuals are the difference between the observed ( Y prod ) and model-predicted ( \( {\widehat{Y}}_{prod}\Big) \) values
$$ {e}_i={\widehat{Y}}_{prod,i}-{Y}_{prod,i} $$ where i = 1, 2, 3, 4 … n . Positive residuals indicate that the model overpredicts the observation, whereas negative residuals indicate that model underpredicts the observation. The presence of any obvious trend indicates a potential lack of fit. 3. SSE: Another metric of goodness of fit is the square difference between observed and predicted values, or the sum of square error (SSE)
$$ SSE=\sum \limits_{i=1}^n{\left({Y}_{prod,i}-{\widehat{Y}}_{prod,i}\right)}^2=\sum \limits_i^n{e_i}^2 $$ where a small SSE indicates a better model fit.
Simulation to Define Acceptance Limit
During process development, it is critical to define appropriate acceptance criteria for process intermediate aggregate level. Based on the safety and efficacy testing, we are often given a quality specification for the product. Subsequently, we have to derive an appropriate specification for the feed, which is used to determine whether or not to proceed with the step. If the feed aggregate level is outside of the acceptance limit, then we might not want to proceed with the step, since the product is less likely to meet the pre-defined specification. Although a narrower in-process specification increases the probability of meeting the product specification, it could potentially reject batches that would have otherwise met the final drug specification. Hence, it is critical to establish an accurate in-process specification. 1. Conventional Approach: To capture the variability of aggregate reduction ( Y red ), Monte Carlo simulation is performed using a normal distribution, with the mean and standard deviation of the aggregate reduction from the original dataset. The predicted product aggregate level is computed by subtracting the simulated ( Y red ) from the feed. This process is repeated 300 times, and the mean and 90% confidence interval are generated for each feed aggregate level. Based on the pre-specified product aggregate level, we can predict what the corresponding feed aggregate level is from the mean curve. 2. Neural Network: Each time a neural network is trained, it can result in slightly different solutions due to different initial weight and bias values and different divisions of data into training, validation, and test sets. To account for this variability, the neural model is run on each of the dataset for 300 times, and the mean and 90% confidence interval are computed. Based on the pre-specified product aggregate level, we can predict what the corresponding feed (or product from the previous step) aggregate level is from the mean curve.
If we need to adopt a more conservative approach, we can use the 90% confidence interval curve, instead of the mean curve, to predict the feed aggregate acceptance limit. To evaluate the acceptance limit set by each approach, we compare the mis-specification (type I and type II error) in each case. In addition, we compare the acceptance limits with the limits generated by the internal validated models.
Results
In this study, we try to understand the process capability of a chromatography step, or the aggregate reduction across the step. Figure 5 shows the chromatography feed and product aggregate level from monoclonal antibody purification processes of four different products. Figure 6 shows the aggregate reduction with respect to the feed aggregate level. The aggregate reduction increases at higher feed aggregate level, as most of the higher-order aggregates are cleared by the chromatography step. In process 4, there seems to be an initial decrease in aggregate level at the feed level of 1.5–2.5%. This could be attributed to the composition of the aggregate in the feed stream. For instance, there might be a larger percentage of dimers, which are harder to be removed, present in the feed that has a 2.5% total aggregate. Hence, the reduction of aggregate for this particular feed stream is relatively lower compared to the feed that has a 1.5% total aggregate. Fig. 5 Chromatography feed vs. product aggregate levels in purification processes from four different products. The x -axis presents the feed aggregate level, and the y -axis represents the product aggregate level. Each plot contains 1002 datapoints Fig. 6 Chromatography feed vs. product aggregate reduction levels in all four processes. The x -axis shows the feed aggregate level, and the y -axis shows the aggregate reduction level
Neural Network Training Algorithm and Architecture
To select an appropriate training algorithm for each of the process, all datasets are run with three approximation algorithms (LM, SCG, and BFG), with the initial number of hidden neurons set at default. SSE and number of epoch are used as the screening criteria.
Table 1 shows the algorithm and number of nodes for each process. For all four processes, Levenberg-Marquardt (LM) is selected as the best training algorithm, which results in a low SSE and epoch. LM is indeed the most common algorithm for function approximation in neural network modeling [ ]. After we establish the training algorithm, different numbers of nodes (8, 10, 12, 14, 16, 18, 20 and 22 nodes) are tested, and the selected number of nodes result in low SSE with a resonable number of epoch. Table 1 Neural network algorithm and number of nodes in each process Process Algorithm Number of nodes 1 LM 10 2 LM 14 3 LM 12 4 LM 22
Conventional Approach Model
For the conventional approach, we assume that aggregate reduction is constant, irrespective of the feed aggregate level. Table 2 shows the modeling equation for each of the processes, where \( {\widehat{Y}}_{prod,i} \) is the predicted product aggregate level, Y feed , i is the feed aggregate level, and \( {\overline{Y}}_{red} \) is the average aggregate reduction. Table 2 Conventional model equations Equation \( {\widehat{Y}}_{prod,i}={Y}_{feed,i}-{\overline{Y}}_{red} \) Process \( {\overline{Y}}_{red} \) 1 0.25 2 4.11 3 2.94 4 1.64
Comparison Between Conventional and Neural Network Approach
To evaluate the accuracy of the model that we establish using the conventional and neural network approaches, we analyze the observed vs. predicted plot, residual plot, and SSE. Figure 7 shows the predicted product aggregate level compared to the actual aggregate level, using either the conventional or neural network approach. The red line represents the 45 o line, and the green line is the least squares regression (LSR) line. With the neural network approach, most of the data fall on the 45 o line, and the LSR line overlaps with the 45 o line, suggesting a near-perfect fit. However, with the conventional approach, some of the data, as well as the LSR line, deviate from the 45 o line, suggesting a lack of fit. Fig. 7 Observed vs. model-predicted aggregate level calculated using conventional and neural network approaches. The x -axis shows the predicted product aggregate level, and the y -axis shows the actual product aggregate level. The top panel of each process shows the conventional approach results, whereas the bottom panel shows the neural network approach results. The red line is the 45 o reference line, in which the predicted outputs are equal to the actual aggregate level, and the green line is the least squared regression (LSR) line based on the relationship between the predicted and the actual data. With the neural network approach, the LSR overlaps with the 45 o reference line
In addition to analyzing the observed vs. predicted plot, we evaluate the residual plot. As shown in Fig. 8 , the conventional approach seems to underestimate the product aggregate level at low feed aggregate level, and overestimate at high feed aggregate level. This is because the conventional approach assumes constant aggregate reduction throughout. In fact, aggregate reduction tends to be lower at low feed aggregate level, and higher at high feed aggregate level, as shown in Fig. 6 . Conversely, with the neural network approach, the residuals scatter around the zero reference line (red line), without any significant trend, suggesting a better fit than the conventional approach. Fig. 8 Model-predicted aggregate level vs. residuals from conventional and neural network approaches. The x -axis represents the predicted product aggregate level, and the y -axis represents the residual level, which is the difference between the predicted and the actual product aggregate level. The red line represents a reference line where the residuals are zero, or the predicted product aggregate levels are equal to the actual aggregate level
Finally, another important metrics to evaluate model accuracy is the SSE. As seen in Table 3 , in all four processes, the neural network model predictions result in much lower SSE compared to the conventional method. Table 3 SSE of model using conventional and neural network approaches Process Conventional Neural network 1 91.00 34.37 2 1068.48 52.22 3 1777.49 54.56 4 884.61 14.87
As a result, prediction using the neural network approach seems to be superior to the conventional approach, as suggested by the observed vs. predicted plot, residual plot, and SSE. Rather than assuming the aggregate reduction is constant across all feed aggregate levels, the neural network analyzes each pair of the feed and product aggregate level, and generates a model with appropriate weight to capture the correlation between the feed and product. In addition, the neural network model is able to capture the dynamic of aggregate reduction with respect to feed aggregate level.
Definition of Process Acceptance Criteria
Figure 9 shows the simulated feed and product aggregate levels. The red horizontal line indicates the pre-defined product specification, and the red, blue, and green vertical lines represent the acceptance limits for the feed aggregate level, estimated by the internal simulated model, neural network, and conventional approach, respectively. Compared to the conventional approach, the neural network approach has a lower Type I error, or is less likely to reject batches that in fact meet the product specification. The neural network estimates are also closer to the internal simulated model estimates, as shown in Table 4 . Fig. 9 Feed and product aggregate level, with product specification (red horizontal line), and associated feed acceptance limits derived from internal model (red dashed vertical line), conventional model (green dashed line), and Neural Network model (blue dashed line) Table 4 Feed acceptance limit calculated using the internal model, conventional, and neural network model Process Internal model Conventional Neural network P value Conventional vs. internal Neural network vs. internal Conventional vs. neural network 1 3.46 3.27 3.42 < 0.0001 0.1219 < 0.0001 2 6.71 6.83 6.70 0.0915 0.8881 0.0675 3 8.15 8.02 8.22 0.3146 0.5881 0.1219 4 6.19 5.01 6.27 < 0.0001 0.2605 < 0.0001
To determine whether the difference in the specification established using the internal model compared to the conventional or the neural network model, or the difference between the conventional and the neural network model, is statistically significant, a t test is used and a p value of less than 0.05 indicates statistical significance. Since all the p values are greater than 0.05, there is no statistically significant difference in the specification developed using the internal model and the neural network model. However, statistically significant difference is observed between the conventional and internal specification, in processes 1 and 4. As shown in Fig. 5 , the points are rather scattered in process 1 compared to other processes. In addition, nonlinearity between the feed and product aggregate levels is observed in process 4. These factors can possibly influence the performance in the conventional model, resulting in different specifications.
Table 5 shows the error %, or the percentage of batches that meet the feed acceptance limit but fail the product specification. With the neural network approach, although we have a slightly higher error %, we are able to capture more batches that meet the product specification, and less likely to have Type I error. Since the error % with the neural network approach is less than 10%, which is our internal standard, we believe that the neural network is a better approach since the cost of falsely rejecting a manufacturing batch can be consequential. In addition, depending on what data are available for the feed and aggregate level, using the conventional, or simply taking the average of the aggregate reduction of the available data can create some type of bias. For example, if mostly high feed aggregate data are available, then the average reduction might be overestimated, and the product aggregate level would be underestimated using the conventional approach. Hence, the distribution of the available data can affect the error % of the conventional approach. However, neural network can learn from both high and low feed aggregate data, and derive the relationship between the feed and product aggregate level. Hence, the neural network model is less likely to be impacted by the distribution of data available. Table 5 Comparison of error % between conventional and neural network models Process Convectional Neural network 1 3.46% 5.77% 2 10.17% 8.77% 3 2.16% 3.69% 4 0% 4.27%
Conclusion
Setting appropriate in-process acceptance criteria is important in ensuring success in drug manufacturing, and increasing the likelihood that drug substance or product will meet the final release specification. In order to establish accurate feed acceptance criteria, it is critical to understand process capability, and accurately characterize the relationship between the feed and product aggregate level. In this paper, we compared the performance of the conventional approach, which is widely practiced in industry, and the neural network approach. While the conventional approach is much simpler, it assumes that the impurity reduction is constant, and thus might not be able to provide a good estimate of process capability in cases where impurity reduction is feed dependent. In contrast, neural network model is better able to characterize the relationship between the feed and product aggregate level, and to estimate the feed aggregate acceptance limit based on the product aggregate specification. Our study suggests that it is beneficial to consider using neural network models for improving manufacturing of biopharmaceuticals.