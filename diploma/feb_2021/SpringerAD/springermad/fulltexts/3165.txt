Introduction
The analysis of solid oral dosage forms throughout product development is typically performed by an analytical method based on high-performance liquid chromatography (HPLC). HPLC methods are intended to be robust to changes in product composition and form of the dosage unit such that, throughout the course of drug product development, a single method allows the quantification of the active ingredient(s) in the various formulations and delivery forms. The test results determine the average potency of a batch (bulk assay) and the variability of the individual dosage units’ assay across the batch (content uniformity (CU)). Typically, bulk assay and CU are two critical quality attributes for every oral solid dosage form, whether in a tablet or capsule. Process analytical technologies (PAT) are increasingly used as surrogates for the determination of Assay and CU. Whether they are deployed on the manufacturing floor to monitor in/on-line or used at-line/off-line as alternate method for monitoring, controlling or releasing oral solid dosage forms, they are increasingly prevalent in the pharmaceutical industry [ , , , ]. Spectroscopic solutions can provide a non-destructive means of assessing a larger population of tablets with reduced overhead and in a shorter timeframe.
Transmission near-infrared spectroscopy (tNIR) and more recently transmission Raman spectroscopy (TRS) are two techniques able to analyse tablets quantitatively with successful deployments [ , , ] and acceptance by global health authorities. These techniques have the advantage of requiring limited to no sample preparation, are non-destructive and provide results in a fraction of the time that traditional methods would require. While most applications are deployed in laboratories alongside HPLC systems, some are making their way onto manufacturing floors, allowing real-time release testing [ , ].
Analytical methods follow a set of general principles outlined in a guidance document published by the International Conference on Harmonization (ICH). The ICH document Q2(R1) discusses the general best scientific practices for analytical method validation [ ]. ICH Q2(R1) was last updated in 1994, largely before spectroscopic methods were developed and does not explicitly discuss their use for quantitative assay. Despite the fact that the overall guidance provided within the document can be interpreted for use with spectroscopic methods, the industry has struggled to come to a common understanding on how to apply the guidance. Consequently, with the development of PAT, some regulatory agencies have published guidance documents or posted Q&A topics to specifically help pharmaceutical companies in the development, validation, implementation and lifecycle management of such methods [ , , ]. Other spectroscopic techniques (including TRS) have been assessed against the NIR guidance [ , ] and the regulatory landscape appears to be challenging to manage. Additionally, ICH Q9 and Q12 present quality risk management and lifecycle management for all processes involved in the design, manufacturing, and continuous improvement of pharmaceutical processes [ , ]. The principles presented in ICH Q9, and further developed in a stimulus document for the lifecycle of analytical methods by the United States Pharmacopeia, present a structured articulation for method development and validation processes [ ].
An important requirement for TRS method developments, and for companies wanting to exploit them, is a clear and evidence-based explanation of the regulatory requirements. For Raman Spectroscopy, the guidance documents are rather general, focusing mostly on calibration of equipment (USP 1120, EP 2.2.48, ASTM E2911/E1840/E2529) or basic primers introducing the technique to a general audience [ –22]. Table 1 summarises relevant guidance on analytical method validation and Raman spectroscopy. There is, however, no document that specifically and clearly states how the nature of novel techniques should be considered when undergoing method development and validation. This article aims to show how some of the unique properties of Raman spectroscopy can be applied for model development, validation and regulatory submission and suggest a path to use existing guidance for development of a quantitative transmission Raman method for the Pharmaceutical industry. Table 1 Current versions of references used in developing quantitative TRS methods Ref. Reference Document [ ] ICH Q2 (R1) Validation of Analytical Procedures: Text and Methodology, International Conference on Harmonization (ICH) [ ] FDA Guidance for Industry on Analytical Procedures and Methods Validation for Drugs and Biologics: July 2015 Pharmaceutical Quality/CMC. [ ] FDA Draft Guidance for Industry on Development and Submission of Near Infrared Analytical Procedures, March 2015. [ ] EMEA Guideline: Guideline on the Use of Near Infrared Spectroscopy by the Pharmaceutical Industry and the Data Requirements for New Submissions and Variations. [ ] ICH Q12: Technical and Regulatory Considerations for Pharmaceutical Product Lifecycle Management (under development) [ ] US Pharmacopoeia chapter <1120>: Raman Spectrophotometry
Transmission Raman Spectroscopy for Quantitative Analysis
Spectroscopic Methods
Transmission Raman spectroscopy for tablet or capsules was described in 2006 by Matousek and Parker [ ] building on earlier, more general work of Schrader and Bergmann [ ] and its application to quantitative analysis was quickly explored [ , , , , ]. TRS uses the principle of Raman scattering, which measures a molecular vibrational spectrum. This may be compared with transmission NIR spectroscopy, which measures higher-frequency molecular vibrational overtones using broadband optical absorption. Both techniques differ in characteristics and features, which give rise to different utility. This section discusses features of Raman and transmission Raman for quantitative analysis and important differences when compared to NIR techniques.
Volumetric Sampling
Conventional backscatter Raman (Fig. 1 a) has been used to approximate active ingredient concentrations by surface measurements, either by scanning a tablet’s surface point-by-point or by a single wide-area illumination measurement [ , , ]. Both approaches assume that the surface signals accurately represent the bulk sample; this cannot be assumed to be true with real pharmaceutical formulations where microscale uniformity may not be fully realised (Fig. 2 a, b) [ , , ]. Sample analysis is further challenged where coatings and capsule shells form the surface. The transmission method (Fig. 1 b) provides a better approximation to a bulk-averaged signal since the signal is captured from a larger sampled volume, as shown in Fig. 2 c. By maximising sampling volume, a transmission method will typically reduce the difference between TRS predictions and HPLC reference data compared to a backscatter method [ ], but requires light to propagate through a dense, non-transparent medium of at least the thickness of the tablet or capsule. Fig. 1 Backscatter Raman method ( a ) and transmission Raman spectroscopy ( b ) Fig. 2 Simulation of Raman photons created and captured in different measurement configurations: a conventional Raman (1 mm spot excitation, backscatter collection), b wide area illumination (6 mm spot, backscatter) and c Transmission Raman Spectroscopy (12 mm spot, transmission). Figures courtesy of Prof. Pavel Matousek from related simulations [ ]
Raman Spectra
Raman spectra typically exhibit excellent specificity with many sharp and distinct features that can be assigned readily to individual components, while NIR absorption spectra often contain broader, overlapping features. This makes it easier to interpret Raman spectra and to visualise changes in composition.
The spectrum of a sample (Fig. 3 ) is a composite formed by the scaled sum of their component spectra (Fig. 4 ): $$ Spectrum=a\left[A\right]{Spectrum}_A+b\left[B\right]{Spectrum}_B+c\left[C\right]{Spectrum}_C+\cdots $$ where a, b, c… are proportional to the Raman scattering efficiency, Spectrum A, Spectrum B, Spectrum C are the spectra of each individual component and [A], [B], [C]… are the fraction of each component. Using multivariate data analysis, the prediction of the concentration of a component of interest in a sample does not require knowledge of either a, b, c, … or Spectrum A, Spectrum B, Spectrum C, … as design of experiments can be used to create variability in the spectral data needed to model [A], [B], [C]. This is performed through the use of a chemometrics model. Fig. 3 TRS (top) and t-NIR (bottom) spectra of a 3-API cold and flu tablet. The APIs are acetaminophen (≈ 85%), caffeine (≈ 4%) and phenylephrine (≈ 1%), all % w / w . See Fig. 4 for constituent spectra Fig. 4 Components of the 3-API cold and flu product shown in Fig. 3 . Each material has a vastly different spectral response, which is ideal for specificity and for multivariate data analysis
TRS methods are generally calibrated using formulated weight values, so TRS spectra are directly related to the results of the individual components (as % w / w values), which need to be multiplied by the tablet weight to give the potency (or % label claim).
An NIR spectrum is produced by absorption of a broadband source of light over a range of ca. 4000–12,000 cm −1 (833–2500 nm). NIR suffers from some limitations that can be disadvantageous in modelling analyte concentrations in real-world samples. Through absorption and light scattering losses, tablets greater than 4–6 mm thick can be challenging to measure. Light must also be carefully baffled to prevent stray light reaching the detector (without travelling through the tablet), which makes sample-handling more demanding. Water absorbs strongly across a large portion of the NIR range, so residual moisture content may preclude the use of the optimal spectral features for analysis (though ideal for moisture analysis).
In TRS, the sample is illuminated with a single-wavelength laser and this scatters throughout the tablet. A small fraction of photons scatters inelastically—typically, losing energy to bond and lattice vibrations—and shifting to lower energy wavelengths. Residual laser light, through transmission or scattering around the sample, is removed by optical filters, avoiding the need for a tightly-fitting holder to prevent light leaking around the sample. Absorption of light by the tablet is not desired and might be avoided by choosing an appropriate laser wavelength (e.g. 830 or 1064 nm) [ ]. Because Raman is not an absorption technique, TRS usually works well with thick tablets and capsules.
Active pharmaceutical ingredients (APIs) and excipients commonly have Raman peaks from ca. 20–1700 cm −1 , or ca. 2300 cm −1 , e.g., if a nitrile group is present. Water has broad features at around 3400 cm −1 , so residual moisture can be excluded from analysis. In the region ca. 20–200 cm −1 , strong “phonon” modes may be found for crystalline materials (most APIs have a well-controlled crystal form) and can be used for sensitive solid state quantification of powders or intact dosage forms (e.g. to characterise polymorphic content) [ , , ].
Considerations and Risk Factors for TRS
When developing any method, the factors that could affect performance should be investigated and/or mitigated against. Factors specific to transmission Raman spectroscopy and that could affect model performance are summarised in Table 2 . Table 2 Factors influencing TRS spectra and how they may be addressed in quantitative analysis Factor Effect Mitigation/Comment Fluorescence Fluorescence can arise from APIs or excipients—micro-crystalline cellulose (MCC) is a common cause NIR laser excitation and/or pre-processing can be used to reduce/remove the fluorescence contribution Photo-bleaching Photo-bleaching occurs if a constituent undergoes a (semi-) permanent change due to absorption of the laser light Reduces fluorescence background over time. Optimise pre-processing for background reduction/removal Photo-damage/degradation Photo-damage may occur where there is strong absorption, e.g. black writing, coatings or coloured excipients Power density (laser power and/or excitation spot size) should be reduced to avoid damage Excitation and collection area Excitation volume should be maximised, e.g. by matching laser diameter to sample diameter. Effect of optical collection area on precision can be explored Collection area affects measurement time. Long tablets may benefit from multiple measurements across their length, e.g. by averaging results from the middle and ends Signal acquisition The prediction performance is related to signal, noise and detector response Signal must be adequate to pass the method’s accuracy specification, e.g. a good signal-to-noise ratio but not saturating the detector or collecting signal where the detector’s response becomes non-linear Hardness, Porosity, Granule size These factors affect absolute signal intensity Absolute intensity variations can be reduced/removed by pre-processing Sample thickness This factor affects absolute signal intensity Absolute intensity variations can be reduced/removed by pre-processing Moisture Spectral features around 3400 cm −1 Raman response from unbound water occurs at high frequencies and can be excluded during modelling Coatings and Capsule Shells Potential for fluorescence. Some coatings may reduce light transmission Ensure good signal response from core in method development, check for specificity of API.
Analytical Procedure Principles and Their Application to Quantitative Methods
Univariate Analysis
Raman bands can be highly selective and quantification using a simple univariate calibration is often possible using a selective peak corresponding to the analyte of interest and a selective peak (or group of peaks) of the other sample constituents. When developing a univariate calibration model, peak attributes such as peak height or peak area can be compared with excipient peaks as an internal standard. The advantage of using a peak ratio model based on integrated peak areas is that the model is robust to subtle changes in peak position, baseline variation and spectrum-to-spectrum intensity variation; in addition to reducing sensitivity to variation in the sample physical properties (e.g. tablet thickness, or hardness). In principle, no spectral pre-processing is required as the peak ratio method can eliminate spectrum-to-spectrum intensity variation (as the ratio of analyte peak area to reference peak area should be proportional to analyte concentration). In practice, baseline correction and spectral normalisation are often applied as it makes the comparison of peak heights/areas from different samples easier to interpret. Despite the apparent simplicity and robustness of univariate methods, there are limitations; for example, the univariate peak ratio method requires selective peaks and the method does not allow the detection of spectral outliers (uncalibrated interferents contributing to the test sample).
Multivariate Analysis Methods
Multivariate calibration offers several advantages over univariate calibration. Bro [ ] summarised the advantages of multivariate calibration as noise reduction (via projection of the multivariate signal onto latent variables); handling of interferents and outlier detection. Importantly for spectroscopists, multivariate calibration does not require that the spectrum contains highly selective peaks or features of interest—mathematical selectivity is achieved by the decomposition and regression steps. This is particularly advantageous in complex matrices where peaks for the components may overlap.
Two of the most widely used multivariate calibration methods are principal components regression (PCR) and projection to latent structures (PLS), also known as partial least-squares regression [ ]. These are examples of inverse calibration techniques. For inverse calibration, only reference values for the property of interest are required (even if the sample contains several different components). These methods decompose the spectral data into basis vectors that more efficiently represent the data as a function of spectral variance (principal components—PCR) or spectral co-variance with the property of interest (latent variables—PLS). A key step when building these models is to select the right number of factors (principal components or latent variables) that describe the data and limit noise. This allows parsimonious model-building; fewer factors to explain a significant amount of the variation in the data. Spectral pre-processing can be used to remove or reduce sources of noise. Typical spectral pre-processing steps include feature selection (spectral range), baseline correction, smoothing, derivatives and spectral normalisation. Spectral normalisation plays an important role in reducing or removing sensitivity to physical properties, e.g. tablet thickness, or hardness.
Design of Experiments
To build robust models, care must be taken to generate samples that represent the natural variability of the process. That variability can come from API and excipient lot to lot variation and manufacturing variability, usually expressed through tablet weight, thickness, and hardness. In addition, changes in composition are required to cover a range around the target label claim. The creation of samples with chemical (concentration) and physical (weight, thickness, …) variability is usually managed through a design of experiment that aims to minimise the number of samples but maximise the information provided to the model. Efficient strategies such as central composite designs can be used to reduce the number of samples compared to the more extensive full factorial design while maintaining a good predictive ability [ ].
Calibration and Validation Principles
Figure 5 presents a high-level flow chart of the development of a method. After a set of samples covering a range of chemical and physical variability is manufactured, it is scanned on the spectrometer and sent for reference analysis. An initial chemometrics model is then built using one of the methods described above (univariate or multivariate). The use of spectral pre-treatments and reduced variable ranges is often required. Calibration and cross-validation statistics are then calculated. The model should also be challenged with samples not used in calibration to evaluate its robustness. The optimization of a model is an iterative process that may require many iterations, with repeated modification and augmentation of the calibration set. Fig. 5 Flow chart describing at a high level the calibration process for a TRS model
Once a satisfactory model is obtained that provides fit-for-purpose accuracy and robustness, the model undergoes validation where the figures of merit outlined in ICH Q2(R1) are determined. Table 3 presents these criteria with each being described later. After a method has been validated, it is important to confirm its performance as a function of time. Updates of the model may be necessary. This is covered under the lifecycle management section. Table 3 Figures of merit selection for quantitative method development Figures of Merit Applicability of NIR guidelines Accuracy Yes Precision Potentially not Specificity Yes Linearity Yes Range Yes Robustness Potentially different Lifecycle Management Yes System Suitability Yes, but different criteria
The approach for method development and validation of near-infrared test methods is well described in guidance and literature [ , , , , , ]. The present document can be used as a starting point to design an approach suitable for Transmission Raman Spectroscopy.
Analytical Method Characteristics
Validation acceptance criteria for Raman methods follow the general ICH Q2(R1) guidance for analytical procedures and can use many of the same principles of the NIR spectroscopy guidelines.
To determine method performance validation samples, independent from the calibration samples, must be used. While it is possible to use cross-validation [ ] methods during development to estimate method performance (a set of matrix manipulation where some calibration samples are withdrawn from the calibration set and predicted as “unknown” samples), only the external validation is a true assessment of the method performance and accepted in regulatory submissions. The definition of “independent” can vary depending on the application but typically means that, at a minimum, batches used in the calibration must be different from those used in the validation. Greater independence can be achieved by ensuring that batches used in the calibration were not only different from the validation ones, but also chosen from different manufacturing campaigns and/or used different material supplier lots and/or used different suppliers.
Accuracy
Accuracy measures the agreement between results generated by the Raman method and a reference value. In contrast to traditional method validation where the reference value is known from the sample preparation (e.g. by spiking a solvent solution with a known amount of API, as in HPLC), Raman method validation must use tablets whose exact drug content is not known at the time of analysis.
Instead, non-destructive Raman analysis must be carried out first on a number of samples to determine their respective API % w / w . By also measuring the sample’s weight, each sample’s API content in mg or label claim can be calculated. Those same samples are subsequently tested destructively by the reference method, e.g. by HPLC, to get reference values for the API content in mg (or label claim). This yields pairs of results (API prediction by Raman, API amount by reference method), and allows the determination of the agreement/residuals between the two methods for each dosage unit.
This lack of agreement must then meet pre-determined acceptance criteria that are appropriate for the intended use, e.g.: Fit for purpose standard error of prediction, or Equivalency with the reference method using a two-one-sided-test at a relevant confidence level, or Lack-of-fit test F-statistic showing agreement with the reference method at a relevant confidence level, or All Raman results within a particular label claim range of the matching reference results, or 95% confidence that Raman results within a particular label claim range of the matching reference results and all Raman results are within a larger label claim range of the matching reference results.
Precision
As Raman is quick and non-destructive, precision can be determined by repeatedly analysing samples and determining the relative standard deviation between measurements. It should be performed at various concentration levels. Since precision does not require analysis by the reference method, the workload required to determine the method precision is limited, even when it is determined at each API concentration.
Precision determination should include several samples at each concentration level, scanned potentially by several operators over potentially different days. With formulations exhibiting fluorescence, photo bleaching may impact precision measurements. A suitable pre-processing method should be employed to reduce or eliminate the effect of photo bleaching during method development.
Specificity
Specificity of Raman methods, like that of NIR methods, is demonstrated in a way that is substantially different from traditional methods, e.g. HPLC, since spectroscopic methods are usually not intended to be stability indicating. Spiking of samples with impurities is therefore not performed (nor would it be feasible, as samples are solid dosage forms). However, it is important to note that Raman could be used for stability indication [ ].
Instead, the specificity of the method can be demonstrated by: Comparing the spectral features found by the calibration (loadings or regression vector) to correlate to the API content and the spectral features of the pure API material A spectral quality test that rejects samples outside of the method’s scope Demonstration of accuracy and robustness
Linearity
Linearity can be demonstrated by comparing the Raman results to the reference results (e.g. plotting one as a function of the other) for samples that cover the range of the method, and by analysing the residuals against a predefined criterion.
Range
As is the case for traditional method validation, the samples should cover a range of API concentrations. Therefore, dosage units with different drug concentrations have to be prepared, typically on a pilot/lab scale, except for the nominal API concentration where commercial scale batches can be used.
For the non-nominal API concentrations, spiking a single placebo blend with various amounts of API before compressing it into tablets or encapsulating is a poor way to proceed, as it would introduce extreme correlation between the samples (with variation in the API-to-placebo ratio only) and would not be representative of true conditions; in commercial samples, a non-nominal API content could exhibit different manufacturing behaviours. Consequently, it would be potentially inappropriate to assume that the excipients are well mixed in such a sample. Instead, the amounts of excipients would be non-nominal, like the API, so the ratios of API to excipient A, B, C… would vary, and the ratios of excipients to the other excipients would also vary. Spiking a single well-mixed placebo with API would only provide variation in ratios of API to excipient A, B, C….
It is therefore suggested to prepare the pilot/lab scale samples using a design of experiments with a range of excipient concentrations for each excipient and a range of API concentrations, thereby validating the method over a design space instead of just an API range.
Robustness
As Raman requires no sample preparation and the analysis has few possible sources of variation (no flow rate, buffer concentration, column temperature…), robustness focusses instead on the variation in the sample itself.
Chemical and physical variations do occur in the sample, e.g. ratio of API to excipients and/or ratio of excipients to other excipient, fluorescent baseline, crystallinity, polymorphism, water content, particle size, tablet thickness, tablet weight, sample positioning in instrument, analyst, etc., and their impact on the model should be considered through a risk based approach.
While some variables have little to no effect on Raman analysis, e.g. free water content, others can be addressed through: spectral pre-processing. Differentiation to remove baseline effects, normalisation to remove absolute intensity changes caused by changes in particle size or thickness, testing batches manufactured using different supplier lots of materials (crystallinity, polymorphism, bound water content/pseudo polymorphism), or explicitly testing sources of variability (lab/pilot scale samples made with different API to excipients and/or ratio of excipients to other excipient, analysis on multiple days by multiple analysts with removal and return of the samples to the instrument each time).
Robustness can be combined with other tests to reduce the validation effort: Analysis on multiple days by multiple analysts with removal and return of the samples to the instrument each time is also the Precision test Lab/pilot scale samples made with different API to excipients and/or ratio of excipients to other excipient can be those used for Accuracy at non-nominal API concentrations Most of the other variables can be tested using the commercial batches chosen to test Accuracy at nominal API concentrations
Reference Method/Equivalency Principle
As a secondary method, transmission Raman and all other spectroscopic methods based on the output from another method for calibration, typically HPLC analysis, are subject to a number of sources of errors that will affect the performance of the final method. This error component is in addition to the precision error terms, and other sources of variability. The variance in a prediction or prediction uncertainty \( {{\widehat{\sigma}}^2}_{{\widehat{y}}_{pred},i} \) has been described by Faber and Kowalski [ ] and can be expressed as follows: $$ {{\widehat{\sigma}}^2}_{{\widehat{y}}_{pred},i}\approx \left({h}_{p,i}+\frac{1}{I_{cal}}\right)\left({{\widehat{\sigma}}_{\varepsilon c}}^2+{{\widehat{\sigma}}_{Yc, ref}}^2+{\left\Vert \widehat{\boldsymbol{b}}\right\Vert}^2{{\widehat{\sigma}}_{Xc}}^2\right)+{{\widehat{\sigma}}_{\varepsilon p,i}}^2+{\left\Vert \widehat{\boldsymbol{b}}\right\Vert}^2{{\widehat{\sigma}}_{Xp,i}}^2 $$ where I cal is the calibration sample size, \( \widehat{\boldsymbol{b}} \) is the estimated regression vector of the PLS model, and \( {\widehat{\sigma}}_{Yc, ref} \) is the reference uncertainty. For calibration samples, the pooled standard deviations of the TRS measurement error and that of the prediction residual were denoted by \( {\widehat{\sigma}}_{Xc} \) and \( {\widehat{\sigma}}_{\varepsilon c} \) , respectively. \( {\widehat{\sigma}}_{Xp,i} \) and \( {\widehat{\sigma}}_{\varepsilon p,i} \) symbolise the standard deviations of spectral measurement error and prediction residual for the i th sample in validation set. h p , i is the leverage of the i th sample in validation set.
Some of these terms are estimated during the method validation exercise: reference uncertainty (usually called standard error of the laboratory) and spectral standard deviation (which is an estimate of precision). It indicates that the final prediction error is a function of not only the spectral error but also the contributed error from the reference method (i.e. HPLC).
Upon successful completion of method validation, there is often the increased expectation from Regulators to perform a comparability analysis of the reference method and the alternative method prior to obtaining approval for the applications use for commercial release testing. As described in the “ Accuracy” section , using a reference methodology is an estimate (compared to a reference standard for HPLC), so by comparing the two methods, both analytical method errors contribute to the result. As per the equation above, the error of the TRS method will be larger than the standard error of the laboratory (SEL—the error determined using real samples of the reference method). The success criteria for accuracy and precision must account for it when determining the equivalency criteria of the two methods.
Procedurally, one should ensure that the acceptance criteria for a given test methodology (statistical test) be sufficient to protect the patient. A number of tests have been used to achieve such equivalency test: paired t tests, Schuirmann’s equivalency test. However, it is necessary to define a practically acceptable limit for the term equivalent. For example, if the TRS and HPLC data differ by 2% on a given comparison, its acceptability should be addressed in the method development process.
Lifecycle Management
A plan that considers how and who should maintain any application should be included from the beginning of the development process and be firmly established and documented upon validation and use of the application for prediction [ , ].
Trending of the predicted values and supporting statistics (e.g. Hotelling’s T 2 and Residuals) is essential to actively monitor the model performance [ , ]. Where appropriate, these prediction statistics can be used to establish warning and action limits. An advantage of Raman data is that Hotelling’s and Residuals can both determine that there is something unexpected in the batch and (because of the high number of spectral features) give evidence about where those differences originate. A sample or batch that exceeds the warning/action limits would trigger an action to verify the model performance using, i.e. the primary reference method. This data (spectrum and reference value measured using the primary method) could be stored and used in a future model review and update.
Change management is required to assess factors that may impact the model performance. Very broadly, there are two key types of change that should be considered. The first is a change to the manufacturing process that could lead to a detectable difference in the chemical or physical properties of the test samples (e.g. raw material supplier or grade changes, critical process changes that may impact the analyte properties). Evaluation of the impact of such changes should be documented. When performing such assessments, it may be necessary to practically confirm the impact of change by conducting some confirmation studies.
The second type of change is a critical instrument change that could impact the performance of the Raman instrument. (e.g. replacement of a key system component).
In either case, an assessment may conclude a significant change that requires a model update. If a model update is required, similar processes for development, validation and documentation should be followed. If the model is registered, it is important to understand the impact of any changes to the filed registration and potentially any subsequent file updates.
Instrument Performance Qualification
Instrument performance qualification ensures the instrument’s measurement response is acceptable for analytical use. Some guidance on regular performance checks (daily, before each measurement, etc.) and periodic checks (e.g. annually) is available [ ]. Checks such as laser power have simple metrics, but spectral checks require more complicated methods such as automated peak-position analysis.
Raman spectrometers employ either an interferometric measurement—using a Fourier transform (FT)—or a dispersive spectrograph/camera system. FT instruments can be used for TRS but have practical challenges [ ]. The camera in a dispersive instrument outputs an array of pixel vs. intensity values dispersed along one axis in wavelength by the spectrograph (x-axis), typically converted to frequency (cm −1 ) for Raman analysis. The instrument’s signal response (y-axis) is often strongly wavelength-dependent. The x- and y-axes must be calibrated for accurate quantification methods.
Absolute calibration of the wavelength is recommended by an atomic emission lamp, e.g. mercury-argon. Since measured Raman peak-positions vary with excitation (peaks are “shifted” by a fixed frequency from the laser frequency), the laser wavelength must be stable. In addition, the x-axis shift calibration and check should use a material with a defined Raman spectrum. Correction for natural x-axis variation over time should be performed often, e.g. several times per day. Suitable materials defined in ASTM 1840-96 include polystyrene, cyclohexane and acetaminophen [ ]. Ideally, the standard would be in a form similar to the samples being measured, i.e. a tablet or encapsulated powder; in practice a stable polymer may be used, e.g., polystyrene. The combined use of absolute and relative standards, as well as metrics such as laser power, will vary between instruments and will be recommended by the vendor.
USP 1120 and EP 2.2.48 define peak positions and acceptable error values for several materials and several peak positions should be checked [ , ]. The relative intensities of multiple spectral bands should be assessed by calculating variations in peak areas relative to one of the peaks in the spectrum (< 10% variation [ ]).
The y-axis calibration can be performed by a calibrated broadband light source, e.g. a white light lamp or a fluorescent target. All measurements (calibration and data collection) should avoid saturating the detector (reaching the maximum response) and use only the intensity values in the linear response region. The limit of the linear region, which depends on the camera, may be a significant fraction of the saturation limit, e.g. 2/3. It is often acceptable to breach the saturation or linear limit if that region of the spectrum is not subsequently used for analysis.
System Suitability
Once the instrument has been appropriately qualified by defined Installation/Operational/Performance Qualification procedures, it is necessary to demonstrate that the instrument is suitable for use with the specific method. Such System Suitability Tests (SST) are discussed in USP 1058 where “system suitability tests verify that the system will perform in accordance with the criteria set forth in the procedure” [ ]. They are not directly considered hardware diagnostics but rather ensure that the data collected are appropriate for the method in use, suitable at the time of (and during) use and that the data are valid for the method.
For spectroscopic methods, the spectrum can only be used if the SSTs demonstrate that it is of a suitable standard to be used for the method. SSTs are numerical procedures performed after data collection. Unlike chromatographic methods, Raman methods rely on an a priori calibration model and consequently the most important component of the SST is that the quality of the test spectra are equivalent in nature to the calibration set. Depending on the method, system suitability tests can take various forms. System suitability tests can be performed on the spectra of the samples themselves and/or through the use of stable standards such as Teflon or Polystyrene.
Peak Height, Area or Ratio
For univariate models, ensuring that the absolute laser intensity of the peaks of interest is within an upper and lower limit can be a simple suitability test. Similarly, the ratio of peak heights or areas can be used.
Multivariate Metrics
Multivariate methods provide a number of statistical tests that enable an evaluation of data quality. Hotelling’s T 2 , Q-residual or Mahalanobis distance can be used, along with confidence intervals to assess the suitability of a spectrum [ , ].
The tests mentioned above are not exhaustive and different methods, applications, and samples may require different approaches. However, the aims are similar: ensuring intrinsic data quality at time of use. It is worth noting that samples can have an important effect on the results of a system suitability test and that in case of abnormal results, an evaluation of sample suitability must be conducted as well, potentially involving a destructive method (e.g. HPLC).
Once the test is selected, it is applied at the time of use so that spurious quality data does not impact QC decisions, as in the case of a real-time release deployment. Each and every spectrum will receive an equivalent assessment.
Summary and Conclusion
In this paper, the regulatory approaches and landscape have been explored and should help the analytical chemist understand the application of transmission Raman spectroscopic methods to content uniformity, assay and identification methods. Also, the particular characteristics of transmission Raman spectroscopy for quantification measurement have been discussed in reference to primary methods, such as HPLC, and other secondary techniques, such as NIR.
TRS is a fast and practical technology for replacing wet-chemistry methods with robust and accurate measurements. Methods for lot-release testing following these guidelines have been successfully approved and the cost-savings have been demonstrated in real-world use [ ].
The second of two papers [ ] describes the practical development of methods and how to make robust regulatory submissions.