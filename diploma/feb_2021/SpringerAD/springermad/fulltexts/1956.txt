Introduction
There has been a steady increase in the number of clinical trials in amyotrophic lateral sclerosis (ALS) since the discovery of the SOD1 gene mutation and riluzole trials of the 1990s energized the field (Fig. 1 ). As ALS clinical trials expand in number, complexity, breadth of targets, and stage of development, traditional clinical trial design is individualized for each trial and its specific goals. ALS clinical trialists are repurposing existing drugs and, for the first time, gene and stem cell therapy are coming to trials for people with ALS. Subpopulations of patients with ALS are being identified as potential responders for candidate therapies. Novel analysis of existing outcome measures is offering a more comprehensive view of a therapy’s effect. Diagnostic, predictive, prognostic, and pharmacodynamic biomarkers are in discovery and validation; some may soon be poised for incorporation into clinical trial methodology. A new approach to ALS clinical trial design has emerged, dichotomizing design phases into either a learning (i.e., early trials: phase I and II) or confirmatory phase (i.e., phase 3 trials). Adaptive trial design in both phases can minimize patient risk, study duration, and sample size while improving efficiency and promoting statistical power to herald an exciting era for clinical research in ALS. Fig. 1 Trend in amyotrophic lateral sclerosis clinical trials per year (used with permission) [ ]
Design Improvements Driven by Study Need
In amyotrophic lateral sclerosis (ALS), as much as in any disease area, the standard clinical trial design (i.e., screening, enrollment criteria, randomization 1:1 to placebo or active therapy, and outcome measurement in each group) has been a mainstay of research for decades. Today this design is being modified for each trial based on type of therapy (i.e., symptomatic or disease-modifying), route of delivery, applicable subpopulations, market availability of a therapy, and phase of therapy development, in order to optimize trial performance. Soon, trials might also be designed to better accommodate the mobility issues faced by people with ALS by using new technology for telemedicine.
Navigating Routes of Delivery
ALS researchers are pioneering methods of novel therapy delivery. Study drug administration may be oral, intravenous, intramuscular, intramedullary, or intrathecal. Intrathecal delivery is used to target the central nervous system (CNS) when therapies cannot cross the blood–brain barrier, as is true of antisense oligonucleotides (ASOs) and, likely, stem cell therapies [ ]. Some stem cell therapies are even being delivered directly into the spinal cord [ ]. Intrathecal, and even more so intramedullary, delivery is complicated and invasive, imparting additional study risk and often limiting study size. Still, intramedullary surgical transplantation of stem cells may be required for cell therapies to exert their effect [ ]. Assessing the success of CNS delivery of these novel therapeutics is challenging but critically important, as seen in a trial of intrathecally delivered, neurotrophic factor-secreting, bone marrow-derived mesenchymal stem cells in people with ALS [ ]. Current trials are paving the way for present and future drugs by optimizing intrathecal and intramedullary delivery, and translational researchers are looking for less invasive ways to bypass the blood–brain barrier.
Leveraging Subgroups
Enrollment criteria can be used as a tool in ALS trial design. Since the trial of riluzole in people with advanced ALS failed to demonstrate efficacy [ ], most ALS trials aim to enroll patients early in the disease. Yet this remains a challenge given the relatively long diagnostic delay in ALS [ ]. Beyond this, ALS trials tend to enroll without regard to clinical subtype in order to encourage rapid enrollment and unnecessary enrollment limitations. However, the phenotypic heterogeneity of ALS reduces the signal-to-noise ratio and confers a statistical challenge. In theory, clinically evident patient subgroups (e.g., bulbar vs limb, rapidly vs slowly progressive) may respond differently to therapies, though there is no pathophysiologic evidence for a molecular underpinning to these subpopulations. For this reason, few trials have used these features as enrollment criteria. Some trials may benefit from reducing phenotypic heterogeneity, so there could be exceptions. The recent PROACT prediction prize was awarded to the algorithm best able to predict progression. Initial calculations suggest that using such an algorithm to drive enrollment criteria could improve statistical power of a trial by at least 20% without making enrollment criteria substantively more stringent. There has been a recent trend toward subgroup-targeted therapy based not on phenotype but on genotype. RNA silencing (siRNA) and antisense technologies trials targeting specific genes have, thus far, enrolled patients with the specific mutations [ , ]. This type of subgrouping will likely continue, and while nongene-targeted therapies may not exclude participants by gene status, future trials may well stratify analysis by gene mutation.
Special Considerations for Trials of Repurposed Therapies
In trials of repurposed drugs that are on the market, off-label prescription can threaten trial enrollment. In these cases, trial design must be modified to boost enrollment. Sometimes the elimination of placebo control is possible, but often this is not acceptable for scientific or regulatory reasons. Other design changes might be equally successful, including a time-to-event design, in which trial participants are offered open-label access to a drug if a certain end point is reached (e.g., a four-point drop in the ALS Functional Rating Scale–Revised or 10% drop in vital capacity). Such designs were successfully used in the ALS trials of lithium, a repurposed drug that generated a great deal of patient interest and demand for off-label prescription [ , ].
Incorporating Telemedicine
The clinical care of patients with ALS increasingly incorporates emerging technologies to focus on home-based care, improving access and often quality of care in a progressively debilitated population. ALS clinical trialists have the opportunity to include televisits and home monitoring equipment in trials, and lead the forefront in innovative trial design. These devices will require validation, but this up-front work might improve data quality, reduce frequency of study visits, and increase trial safety.
Phase of Development
The phase of development affects study aims and has a strong influence on trial design. A learning, or early phase, trial focused on safety and dose ranging will require a smaller sample size, stricter safety inclusion criteria, and different primary outcomes measures than a confirmatory, or phase III efficacy trial. Current Food and Drug Administration-accepted, clinically relevant outcome measures in clinical trials include tracheostomy-free survival, strength (e.g., hand-held dynometry [ , , ]), respiratory dysfunction (e.g., vital capacity), and function (e.g., ALS Functional Rating Scale–Revised [ ]). These measures perform well in late-phase trials with many participants and long follow-up periods, but are less robust in early-phase trials, which are small and brief [ ]. The failure of these efficacy outcomes to predict the results of confirmatory trials has led trialists to seek new, more relevant outcome measures and biomarkers of disease progression or therapeutic target engagement for learning trials.
Toward Novel Outcome Measures and Biomarkers in ALS Trials
The development of biomarkers is an important improvement in the design of early-phase trials, and ALS researchers are at the forefront of biomarker innovation. The National Institutes of Health has categorized biomarkers as diagnostic, predictive, prognostic, and pharmacodynamic (PD) [ ]. Each category has a key use in ALS trial design. Diagnostic biomarkers can assist with the identification of eligible patients, potentially facilitating earlier trial enrollment to boost the efficacy of candidate therapy. Predictive biomarkers may be used to enroll subsets of patients with particular disease characteristics expected to respond to therapy. Prognostic biomarkers may be employed to reduce study subject heterogeneity and increase statistical power. Markers of disease progression and drug pharmacodynamics might be useful as study end points in early-phase or learning trials. Ultimately, these markers could be validated and find use as surrogate markers of clinical progression in confirmatory trials, but this use has a longer time horizon given the lengthy certification process for biomarkers.
Biofluid-derived [ , , ], imaging-based, and electrophysiologic ALS biomarkers are all currently in development or validation. Phosphorylated neurofilament heavy chain appears elevated at stable levels throughout the disease [ , , , , , , , ]. Neurofilament light chain in cerebrospinal fluid (CSF) appears to increase as ALS progresses [ , , , , , ]. Urate, which is lower in people with ALS than in controls, could serve a predictive or prognostic role [ , , , , ]. Regulatory T cells, which are reduced in patients with rapidly progressive ALS, may be a predictive marker [ , ]. miR-155 (i.e., micro-RNA), a promising marker of inflammation, is found to be upregulated in patients with ALS and may be predictive or prognostic [ , , ]. These efforts will require concerted effort and considerable resources, but, if successful, will represent important new tools to speed ALS therapy development.
Emerging technologies in ASOs and RNA silencing show promise as novel therapy targeted at specific genes in familial ALS, such as SOD1 and C9ORF72 [ , , ]. Their therapeutic potential was recently demonstrated by the phase I investigation of the intrathecal delivery of ASO ISIS 333611 in SOD1 patients with familial ALS [ ]. Abnormal proteins in the CNS of individuals with ALS causative mutations may provide specific biomarkers in gene-targeted therapy. Repeat expansions in C9ORF72 , called dipeptide repeat proteins, in patients with ALS are presumably generated by non-ATG translation, serve as a critical component of p62 positive inclusions found in the cerebellum and hippocampus, and can also be identified in CSF [ , , ]. The specificity of dipeptide repeat proteins for these patients confers an opportunity for use in trials and could even be a therapeutic target [ ].
In people with SOD1-mediated familial ALS, mutant SOD1 protein may be a diagnostic or prognostic biomarker [ , ]. Misfolded SOD1 could potentially also be a target in sporadic ALS. For now, ASO technology targets all SOD1 mRNA, aiming to reduce levels of both wildtype and mutant SOD1, as the mutation is known to exert its effect through a toxic gain of function. In CSF, SOD1 protein levels have been shown to be higher in people with ALS than in healthy controls [ ], but interindividual variability is high. Within an individual, SOD1 in the CSF is remarkably stable over time, and as such is an encouraging pharmacodynamic biomarker for SOD1 -targeted ASO therapy. And, as the number of ALS-causative mutations continues to grow, gene analysis will serve as a diagnostic biomarker to identify eligible patients for consideration in trials of gene-targeted therapies.
Retigabine: A Case Study for Innovative ALS Clinical Trial Design
The use of induced pluripotent stem cell-derived motor neurons (iPS-MNs) from people with ALS has emerged as a novel preclinical disease model that both facilitates the investigation of human motor neurons in vitro and may be used as biomarkers to identify a subset of people likely to respond to a given therapy [ ]. If so, this innovative technology could be used to screen potential candidates for a clinical trial. Recently, we found that the hyperexcitability of iPS-MNs from people with ALS normalized upon application of a potassium channel activator, retigabine [ ]. Based on this science, a human trial of retigabine for ALS will soon be underway, with outcome measures of neuronal hyperexcitability, including transcranial magnetic stimulation. Additional exploratory outcomes will include the response of iPS-MNs to retigabine.
Electrophysiologic biomarkers also hold promise. The accurate test of limb isometric strength is being developed as a more precise and convenient quantitative strength test [ ], relative to hand-held dynometry and Tufts Quantitative Neuromuscular Exam. Motor unit number estimation has been used in a few trials and may have utility [ , , ], particularly in early trials. Electrical impedance myography has emerged as a promising reproducible and painless technique measuring muscle impedance as a marker of muscle tissue health [ , ]. Further assessment of these outcome measures is underway.
Modern imaging modalities such as diffusion tensor imaging [ , ], magnetic resonance spectroscopy [ , ], functional magnetic resonance imaging [ ], and 18 F-fludeoxyglucose positron emission tomography [ , ] are emerging as potential biomarkers of disease progression. Unique imaging characteristics on magnetic resonance spectroscopy, functional magnetic resonance imaging, and 18 F-fludeoxyglucose positron emission tomography may aid in diagnosis [ , , , ]. Findings on diffusion tensor imaging also correlate with ALS phenotypes [ ], disease severity scales, and disease duration [ ].
Finally, the development of PD biomarkers to measure target engagement of a potential therapy in ALS will be enormously helpful in assessing trial outcomes [ ]. These markers need not be ALS-specific, as they would be designed to highlight target engagement, rather than efficacy. Previous programs to develop ALS therapies, such as topiramate [ ], minocycline [ ], and dexpramipexole [ ], may have benefitted from a PD biomarker. ALS field innovators have risen to this challenge with the design of the upcoming trial of tocilizumab, an anti-inflammatory drug, in ALS in which inflammatory markers are measured throughout the study. Inclusion of such a PD biomarker has the potential to offer insight into potential drug efficacy prior to engaging in a large phase III trial [ ].
Modifications of Traditional Study Design by Phase
While the incorporation of novel outcome measures and biomarkers have the potential to enhance study design, adaptive trial designs in each study phase may also advance ALS therapy development. A new approach to ALS clinical trial design has emerged, dichotomizing design phases into either a learning (i.e., early trials: phase I and II) or confirmatory phase (i.e., phase 3 trials).
Learning Phase
Learning trials focus on the pharmacokinetics and PD of an intervention, relevant toxicity, and relationship to dosage. Single ascending dose (SAD) studies are often followed by multiple ascending dose studies to clarify the most promising dosage level [ ]. Placebo and very low dosage drug exposure are limited. Safety and tolerability are assessed after each dose level.
A SAD study aims to establish a maximum tolerated dose (MTD; usually defined as the next lower dose level after a drug’s toxicity level for reversible toxic effects reaches 33%). The classic 3+3 cohort expansion design is the most commonly employed type of SAD trial, and is more well-defined in the field of oncology than in the ALS literature [ ]. The study cohort will expand to further explore drug tolerability if a dose-limiting toxicity occurs. Alternatively, if no dose-limiting toxicity occurs the dose is escalated. However, this design has both ethical and practical limitations [ ]. A 3+3 design can underestimate the MTD, does nothing to minimize the number of patients exposed to subtherapeutic doses, escalates slowly, and consumes both time and resources. MTD is best identified with common reversible adverse events, but many of the most promising ALS therapies do not cause this type of side effect; gene therapy may confer lifelong exposure after a single dose.
Adaptive trial designs in early ALS learning trials aim to speed drug development while preserving safety. The continual reassessment model (CRM) employs Bayesian adaptive statistics with the goal to more efficiently determine the MTD using real-time data (e.g. frequency of adverse events) to more rapidly escalate dosage levels [ , , , ]. A binary outcome with stopping rules and fixed sample sizes are predetermined. CRM promotes the accuracy and speed of decision making in early trials to reduce costs and conserve resources [ ]. Despite these advantages CRM is less commonly employed as it is statistically complex and raises the concern of excess experimentation at higher dosage levels with more frequent and severe toxicity [ , ]. Additional adaptive early learning phase designs in ALS include a dose-ranging study design [ ], another means to more rapidly achieve higher dosages of the study drug.
Often early-phase trials may aim to demonstrate efficacy through disease modification. Unfortunately, learning phase trials (i.e., phase II trials of small sample size and short study duration) have limited statistical power to demonstrate efficacy. We have referred to this challenge as the paradox of phase II trials in ALS [ ]. Many of the novel ALS learning trial designs are aimed at balancing a need for efficacy data with the remainder of the phase II trial goals. By orienting trial design to detect treatment failure rather than success, learning trials may more appropriately assess therapeutic effect on disease features.
Fortunately, adaptive trial designs, such as response-adaptive randomization and interim stopping rules, allow for modification of the traditional design to improve the efficiency and statistical power in ALS clinical trials [ ]. A futility design involves a predetermined threshold for benefit. A large, costly efficacy trial may be avoided if this threshold is not met, as seen in the coenzyme Q10 trial in ALS [ ]. Futility stopping rules and a time-to-event design in a randomized trial of lithium in ALS ensured speedy enrollment before halting of the trial for futility at the first interim analysis [ ].
Selection design trials also help to streamline drug investigation in ALS learning trials by testing multiple candidate therapies against one another and eliminating placebo arms, as seen in the trial of minocycline and creatine versus celecoxib and creatine in ALS [ ]. This design modification may prove exceedingly useful as the number of potential therapies extends beyond resources available to test each individual drug. Historical placebos have also been used to conserve trial resources by promoting enrollment and boosting statistical power. An open-label phase II trial of lithium in ALS used historical placebo arm subjects from the minocycline trial in ALS obtained from a large pooled database of clinical trial data from about 20 trials in ALS, called the PRO-ACT database [ , ]. Shared clinical datasets such as the PRO-ACT database and NeuroBANK have emerged as powerful tools to support ALS clinical trialists and enable the employment of more efficient trial design.
Confirmatory Phase
The majority of ALS confirmatory trials continue to mimic the standard phase III randomized, placebo-controlled trial design, preferred by regulatory agencies, to determine drug efficacy and safety, and generate evidence from which treatment decisions are based. Intention-to-treat analysis preserves the benefits of randomization to balance known and unknown predictive factors. In order to promote patient enrollment in a phase III trial, randomization schemes weighted toward treatment versus placebo groups, as well as open-label extension, may be used [ ]. Implementation trials involving cluster randomization or a stepped wedge design can assess real-world applicability. Furthermore, the combination of learning and confirmatory adaptive designs (e.g., selection or CRM followed by futility design, nonsuperiority extended to efficacy trial) may further promote ALS trial efficiency and statistical power. However, new outcome measures and statistical models, rather than novel trial designs, per se, are likely to drive phase III trial advances in ALS.
The Combined Assessment of Function and Survival is a novel statistical analysis that accounts for both functional change and survival in a single assessment. Combined Assessment of Function and Survival borrows its premise from similar analyses used in HIV trials, and has the potential to offer a more comprehensive view of a therapy’s effect. It was used in a 2-part phase II study of dexpramipexole (KNS-760704) in ALS [ ], and may have future applications in later-phase trials of ALS, having been accepted by the Food and Drug Administration for registration trials [ , ]. The analysis performs most robustly when a substantial number of survival events are expected during the trial.
The design and employment of multicenter clinical trials in ALS is facilitated by collaborative efforts within existing ALS-specific consortia (e.g., Northeast ALS Consortium, Western ALS Study Group, Canadian ALS Research Network, European Network for a Cure of ALS, International Imaging Consortium), and has played a substantial role in increasing the number and quality of clinical trials over the last 2 decades. In order to improve the traditionally slow process of study initiation, the Northeast ALS Consortium is implementing a central institutional review board and standard contracts for ALS clinical trials [ ]. Consortia collaboration has also led to the establishment of biofluid and tissue repositories, as well as shared clinical datasets to promote the sharing of resources.
Future Perspective
Innovative design modifications accommodate emerging therapies and study needs, and improve upon standard clinical trial design. Trial design will continue to evolve to keep pace with technological advancements and translational discoveries in an effort to minimize patient risk, study duration, and sample size, while improving efficiency and promoting statistical power to herald an exciting era for clinical research in ALS.