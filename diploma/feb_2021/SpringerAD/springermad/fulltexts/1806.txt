The connectome is dynamic
Plasticity is a hallmark of neural circuits. Classic basic research on critical periods has highlighted the strong impact of sensory experience on the structure of brain circuits during early development. This has led to the implementation of corrective therapies in humans already during early childhood, for example for the treatment of strabism. Traditionally, it was believed that following a period of experience-dependent self-organization the structural and functional properties of neural circuits remain essentially stable. Plastic adaptation of neuronal connections may nevertheless occur during adulthood for example in the context of learning and memory formation or in response to a pathological insult contributing to a functional recovery. Importantly, here the impetus for plasticity comes from the environment of the subject or plasticity is a reaction to altered physiology. Recent observations, mostly from chronic imaging studies in rodents, start challenging this traditional view and suggest that the intrinsic mechanisms of self-organization remain operational throughout adulthood. These mechanisms retain neuronal circuits plastic even under basal conditions and after functional maturity has been established. This has implications for the question how neuronal computations are implemented in a dynamic connectome.
The advent of genetic engineering and high-resolution imaging techniques has enabled the marking and chronic monitoring of synapses in living animals over periods from days to months. In particular, transgenic mice expressing the green fluorescent protein (GFP) sparsely in only very few neurons have provided neuroscientists with a “living Golgi stain” enabling the analysis of neuronal morphology over time [ ]. Dendritic spines, tiny protrusions on the dendrites of pyramidal neurons of the neocortex are the morphological correlates of the post-synaptic halves of excitatory synapses. Furthermore, there is good evidence that the size of a dendritic spine can also serve as an estimate of the strength or efficacy of the corresponding synapse. Neuronal structures in the living animal can be imaged using two-photon laser scanning microscopy allowing the detection of subcellular structures in tissue in up to few hundred micrometers depth with minimal phototoxic effects. Longitudinal two-photon laser scanning microscopy through a small chronically implanted window or through a small thinned patch of the skull over the neocortex has revealed that dendritic structures undergo constant remodeling. Within an imaging interval, a significant fraction of dendritic spines have been eliminated, whereas an approximately equally sized fraction have been newly formed (Fig. 1 ). Furthermore, even those spines that can be traced across multiple imaging sessions undergo significant changes in their size, suggesting constant adaptation of the strengths of the corresponding synapses. These observations indicate that cortical circuits change their structure by both reweighting existing connections as well as rewiring by establishing new and pruning of old connections. Fig. 1 In vivo imaging of dendrites and spines. a Top Two-photon image of a dendrite of a pyramidal neuron displaying various dendritic spines, the morphological correlates of excitatory inputs to that neuron. Bottom Same dendrite re-imaged 20 days later. Spines present at both time points are marked with blue arrow heads. Adapted from [ ]. b Life-time plot of 3688 imaged spines. Presence of a spine is indicated by a thin horizontal black line on a given day. For example, spines1–1420 are those observed in the first imaging session; spines1–998 are those observed in at least the first and the second imaging session; spines 1421–1937 are those observed for the first time in the second imaging session. Despite substantial turnover the total number of spines remains remarkably constant throughout the observation period. Adapted from [ ]
Mechanisms of change
Why do cortical circuits display such a surprisingly high level of volatility? After the initial description of long-term potentiation (LTP) [ ], a long-lasting increase in the efficacy of synaptic transmission induced by specific short patterns of neuronal activity, much effort has been devoted to testing if long-lasting changes in synaptic strength of this or similar forms are actually a cellular correlate of learning and memory formation [ ]. Over the years much evidence has been accumulated supporting an important role of synaptic plasticity in learning. For example, in vivo electrophysiological measurements of synaptic connections have revealed adaptations of their strengths during learning. Pharmacological blockade of the synaptic N-methyl-D-aspartate (NMDA) receptors that are important for the induction of LTP also interfere with memory formation. The molecular processes that are mediating the adaptation of synaptic strength, such as the trafficking of specific α-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid (AMPA) receptors to the synapse, are observed during learning.
Interestingly, the same patterns of neuronal activity that induce LTP have been shown to trigger formation of new synaptic spines and increases in the size of pre-existing spines. Analogous observations have been made for long-term depression (LTD), describing a long-term decrease of synaptic efficacy. Thus, there are structural correlates of LTP and LTD, which can be assessed with imaging methods. Importantly, also chronic imaging in transgenic mice during a behavioral task showed that transient increases in spine formation rates are correlated with learning [ , ]. Major findings from a study investigating the impact of auditory cued fear conditioning on spine dynamics in the mouse auditory cortex are summarized in Fig. 2 . Thus, synaptic plasticity has been interpreted as a signature of neuronal adaptation during learning and memory formation. However, basal rates of spine elimination and formation and adaptations have also been observed under conditions where animals were not in need of any form of adaptation of their behavior. Interestingly, synaptic spines maintained a significant level of volatility in cultured brain slices even under pharmacological blockade of any neuronal activity, suggesting a potential intrinsic source of plasticity, that is not directly related to neuronal activity or learning [ ]. In summary, there may be two sources for volatility in cortical circuits: One that is observed during basal conditions and that may not be linked to neuronal activity directly, and one that is induced by behaviorally relevant experiences on top of this basal dynamics resulting in a transient period of disbalance in the rates of spine formation and elimination. Fig. 2 Learning induces a transient increase in spine formation in mouse auditory cortex. a The same dendrite imaged before and after auditory cued fear conditioning (interval: 2 h). b Rates of spine formation in dendrites from mice undergoing conditioning and from control mice (mean ± SEM, n = imaged dendrites). c Schematic summarizing early and late effects of fear conditioning. After a transient period of disbalance in spine formation and elimination the total density of spines is again comparable to the situation prior to conditioning. Adapted from [ ]
Stability despite constant change
Recent technical developments in serial sectioning electron microscopy of brain samples have given rise to the field of connectomics. The connectome, a complete description of the wiring of the neuronal elements within a circuit, holds promise to reveal essential principles how neurons form functional circuits. As electron microscopy can only be applied to fixed tissue, it essentially provides a snap shot of the connectome at a single time point. However, considering the emerging view from chronic imaging studies that the connectome has a highly dynamic nature, it is an important question what aspects of the connectome, if any, are stable. After all, reliable functioning of the nervous system and our ability to recall memories of events that took place decades ago strongly suggest that some aspects of the connectome must be stable for such amounts of time.
First, it is worth highlighting that even if the sizes and efficacies of individual synapses can fluctuate strongly, there is a certain degree of stability at the level of population statistics. The distribution of synaptic efficacies among pyramidal cells in neocortex and hippocampus and the corresponding distributions of dendritic spine sizes seem to maintain a particular shape (Fig. 3 a and b). This shape is close to that of a so-called lognormal distribution, which means that the logarithms of synaptic efficacies approximately follow a Gaussian distribution. This implies that the distribution of efficacies is strongly rightward skewed. Thus, there exists a small population of synapses with very high efficacies much bigger than the mean. What is the origin of this distribution and how is it maintained? Recent experiments using time lapse imaging of dendritic spines have suggested that such distributions can arise from stochastic fluctuations that have a multiplicative component [ ]. Another important finding is that the bigger and stronger synapses are more stable than the smaller and weaker ones [ , , ]. This makes particularly strong synapses a good candidate for the anatomical substrate of those long-term memories which we may maintain for a lifetime. Fig. 3 Lognormal distribution of excitatory synaptic efficacies. a Examples of spines imaged along the dendrites of one neuron in one imaging session. The numbers indicate the size of the spine in arbitrary units ( AU ). Note that the dynamic range of spine sizes exceeds an order of magnitude. b Distribution of the logarithm of the size of dendritic spines. The red line is a normal distribution function fitted to the histogram. Adapted from [ ]. c Histogram of measured excitatory postsynaptic potential (EPSP) sizes from paired recordings of layer 5 pyramidal neurons in rat visual cortex [ ]. d Histogram of synaptic weights developing in a network model combining spike-timing-dependent plasticity, structural plasticity, and different forms of homeostatic plasticity. Adapted from [ ]
Recent computational models have attempted to mechanistically explain both the lognormal-like distribution of synaptic efficacies and the characteristic pattern of fluctuations of synaptic efficacies observed experimentally [ , ], including the relatively greater stability of strong synapses. The authors found that the combination of spike-timing-dependent plasticity (STDP), a simple form of structural plasticity, and different homeostatic plasticity mechanisms in model networks readily produces the lognormal-like statistics of synaptic efficacies (Fig. 3 d). Furthermore, the model also successfully accounted for the pattern of synaptic fluctuations observed in a chronic imaging study (Fig. 4 ). Finally, the model predicted that the life times of newly created synapses should follow a so-called power law distribution, implying that most newly created synapses survive for only a short amount of time, but a few synapses grow strong and stabilize and live for extremely long periods of time. Recent evidence is consistent with this idea of a power law distribution ([ ]; Fig. 5 ) although the estimated power law exponent did not match the original theoretical prediction [ ]. This has prompted further theoretical work to better understand how the power law exponent depends on different parameters of the model, giving rise to the insight that a broad range of exponents (including the experimentally estimated one) can be obtained in the model, e. g., by varying the relative amounts of potentiation vs. depression in the STDP rule [ ]. Fig. 4 Characteristic pattern of fluctuations of dendritic spine sizes. a Relative changes of spine volumes over one day in CA1 pyramidal neurons in cultured slices of rat hippocampus [ ]. b Relative changes of synaptic weights in a network model combining spike-timing-dependent plasticity, structural plasticity, and different forms of homeostatic plasticity. Adapted from [ ] Fig. 5 Life-time dynamics of spines follow a power law. a Survival plot of newly formed spines. Circles represent the ratio of spines present one, two, three, and four imaging sessions. Dotted line indicates best exponential fit (time constant 5.2 days). Red line represents predicted survival plot based on a model in which spine loss following a power law balances the observed rates of spine formation resulting in a stationary spine density. Exponent is 1.384. b Same power law model predicts life times of spines present at the beginning of an imaging experiment, assuming a mixed age composition based on the same power law. Adapted from [ ]
In this context it is also interesting to note that the connectome exhibits a number of non-random features. A network in which connections are added or removed with certain probabilities in a completely random fashion such that these additions and removals are independent of the presence or absence of any other connections in the network leads to what is called a random network or so-called Erdös-Rényi graph . But networks in neocortex and hippocampus have been shown to exhibit a number of non-random features, which are at odds with a random network model and suggest that certain network structures are somehow stabilized. These include an abundance of bidirectional connections, a high degree of clustering, and a prevalence of certain graph motifs [ , ]. Interestingly, recent modeling work has demonstrated that these properties arise in the same network model used to account for lognormal-like efficacy distributions and patterns of efficacy fluctuations [ ].
Acquiring function and keeping it stable
The high degree of synaptic turnover discussed above may appear to be mostly a nuisance—threatening the stability of representations and memories. But are there also benefits to having such a dynamic connectome? By now it is well established that learning is associated with structural changes in cortical circuits [ ]. However, creating synaptic connections de novo is a time consuming process. Furthermore, how could two neurons “know” that they should establish a new connection with each other, other than through “talking” to each other, which already requires the presence of a synapse: a chicken and egg problem. The solution to this conundrum, we speculate, is that by constantly establishing a pool of new, tentative synaptic connections, the neocortex creates and maintains a rich and diverse “library” of potential functionality. Plasticity mechanisms involved in learning, such as the above-mentioned STDP may then quickly amplify and stabilize patterns of synaptic connections that appear to be useful and worth memorizing. Once amplified, these patterns must be protected from quickly being destroyed and the corresponding memory forgotten. Very strong connection patterns may be able to stabilize themselves by inducing exactly those firing patterns in the network that will in turn reinforce these connection patterns—a well-known effect of spike-timing dependent plasticity and other variants of Hebbian plasticity in computational models (Fig. 6 ). However, alternative mechanisms that could maintain stable function in a dynamic network are also conceivable. The number of possible network configurations undergoes a combinatorial explosion even in only a small network of few neurons. It is therefore conceivable that a whole subspace of network configurations can give rise to the same activity patterns and thus circuit function. Fig. 6 A simplified model of state transitions of synapses associated with changes in their tenacity. Synapses can undergo bidirectional plasticity that is associated with physiological and morphological changes. The largest fraction of synapses are actually not realized and remain dormant as ‘potential synapses’—a dendrite and axon within short distance that could be potentially within reach of a dendritic spine [ ]. Initial synaptic contacts may be formed randomly as ‘silent synapses’ lacking AMPA receptors. Coincident pre- and postsynaptic activity may induce the stabilization of the synapse leading to the incorporation of AMPA receptors. Further stimuli inducing strengthening of the synapse may lead to further increases in tenacity. Note that the finding that life-times of dendritic spines can be described well with a power-law indicates that there likely exists a larger number of states, or even a continuum across the few prototypical states illustrated in the scheme
Most of the observations on the dynamics of synaptic connections have been made on excitatory synapses. Recent methodological developments have enabled the monitoring of inhibitory synapses and suggest a certain degree of volatility in the inhibitory connectome as well. Interestingly, learning during behaviorally relevant experiences seems to induce transient and coordinated shifts in the balance of excitatory and inhibitory synapses. It will be interesting to learn how these periods of disbalance are coordinated to enable learning-related reconfigurations without diverging into pathological conditions of exuberant excitability.
Conclusion
We have reviewed evidence that the brain’s connectome at the local circuit scale is very dynamic with connections constantly being created and destroyed at surprisingly high rates. Various mechanisms are thought to contribute to this high degree of turnover. We have argued that this source of constant change can peacefully co-exist with long-term stability of structure and function. Experimental evidence and theoretical models indicate that one solution for the maintenance of stable function in volatile cortical circuits could be a stable “backbone” of strong synapses within a dynamic reservoir of weaker and more tentative connections. The latter may be important for our ability to quickly learn associations between sensory events—or even for making associations in a “heureka” moment long after the basic facts were known. It is clear that a better understanding of this emerging topic in neuroscience will only be achieved in a close interaction of experiment and theory.