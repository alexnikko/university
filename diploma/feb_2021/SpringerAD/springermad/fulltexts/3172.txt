Introduction
Innovations and advances in manufacturing technology and analytical testing have led to improvement and change of pharmaceutical processes. Changes in Chemistry, Manufacturing and Controls (CMC) are inevitable due to process economics, new findings, and technology advances. Such changes are necessary and beneficial to the pharmaceutical industry as they can bring higher-quality drugs to market more efficiently and expeditiously [ ]. A comparability study is the demonstration of a high degree of similarity between products manufactured before and after change [ ]. Nowadays, comparability study has become a routine exercise throughout the life cycle of biotechnological products.
Regulatory agencies, including the EMA and US FDA, have published several guidance documents following the ICH principles of demonstrating process comparability [ , , , , ]. Comparability does not mean the products are identical, but that their physicochemical and biological properties are sufficiently similar to ensure no adverse impact on quality, safety and efficacy [ , ]. Incomparability of products may result in further pharmacological and nonclinical studies or even clinical studies. Because the manufacturing of drugs, especially biological products, are highly complex and process-dependent, a carefully planned comparability protocol is critical for a successful comparability exercise [ ].
Schlegal and Bobinnec [ ] described a five-step procedure to develop comparability protocols for biotechnological products. They recommended that the protocol should describe all process changes, critical quality attributes (CQA) and analytical methods, historical lot release and product characterization data, and pre-defined acceptance criteria. Among them, selection of relevant analytical methods and determination of acceptance criteria for comparability may be the most challenging step in a comparability exercise. FDA requires that ‚Äúrelevant and clearly defined acceptance criteria to be met demonstrating that the change was successful should be specified for each characterization test and study.‚Äù
Encouraged by the regulatory agencies [ , ], a variety of statistical methods have been used to evaluate the variability and comparability of products before and after process change. The commonly used statistical methods include the two-sample t test, statistical tolerance, and equivalence test [ ]. In contrast to the two-sample t test, the equivalence test is designed to demonstrate the difference between two process parameters or CQAs is within a practically meaningful margin. Therefore, the equivalence test is the preferred method for establishing analytical similarity in the comparability study [ ]. The equivalence margin for analytical similarity is a critical component of the acceptance criteria in comparability assessment. To establish objective acceptance criteria, the selected analytical methods are preferred to be quantitative.
When changes are made to analytical methods, the comparability is defined as the similarities of method performance characteristics, e.g., accuracy, precision, and specificity [ ]. The statistical methods for evaluating the analytical method comparability have been discussed by Chambers et al. [ ] and Chatfield et al. [ ]. The determination of acceptance criteria for analytical method comparability and equivalence studies has been discussed by Chatfield and Borman [ ] and de Fontenay [ ]. Although the statistical equivalence test can be used to assess the comparability of process change, it is more challenging to determine the appropriate acceptance criteria for CMC change [ ]. First, large-scale production batches may cost millions of dollars, it is not feasible to generate a large number of batches simply for the purpose of comparability assessment. Second, the acceptance criteria may take into account accumulated understanding and scientific knowledge about the product characteristics, manufacturing process variation, and analytical method capability. Ultimately, the reassurance that the process change is acceptable should come from a risk assessment. As a part of the initiative, Pharmaceutical Current Good Manufacturing Practices (CGMPs) for the 21st Century, FDA encouraged the implementation of risk-based approaches that focus both industry and agency attention on critical areas [ ]. The pharmaceutical companies should use the knowledge and experience of process and product to assessing the risk of process change that have negative impact on quality, safety and efficacy. Based on the risk assessment, the manufacturer may evaluate how extensive the comparability studies should be.
In this article, a risk-based method is proposed for setting acceptance criteria for process comparability study. The risk is defined as the probability of out-of-specification for the materials from the new process. The Bayesian formulation allows the incorporation of historical knowledge of product and processes. The determination of necessary sample sizes is also discussed to ensure sufficient power of successfully passing the comparability assessment.
Equivalence Test for Process Comparability
Equivalence tests are often used to evaluate the comparability of two analytical methods and two manufacturing processes. The goal of the mean equivalence test is demonstrated with high confidence the means from two processes do not differ by a pre-defined equivalence margin (acceptance criteria) Œî.
Let Y k denote the random variable of CQA from Process k , k = 1,2. Process 1 is the old process is Process 1 and Process 2 is the new process. From Process k , n k samples are selected for analytical testing. Let y k j denote the test result for the j th sample from Process k , j = 1,..., n k and k = 1,2. $$y_{kj}=\mu_{k}+\varepsilon_{kj}, \;\; \varepsilon_{kj}\sim N\left( 0,{\sigma_{k}^{2}}\right),$$ where Œº k is the overall mean of quality attributes from Process k and Œµ k j ‚Äôs are normally distributed random variables for the assay results. The variation of the observed CQA values may come from two different resources, e.g., the process variability and the measurement error of the testing method (assay variability). If the same sample is measured multiple times, a variance component analysis can be applied to the repeated assay measurements to calculate the variance contribution from assay variability and process variation. Here, we consider the situation where a single assay result is obtained for each sample. In some situations, repeated measurements are available for each sample and the reportable value is the average of the replicates.
The null hypothesis of the mean equivalence test is such that the difference between the mean quality attributes from the two processes exceeds a pre-specified margin Œî: $$H_{0}: |\mu_{1} - \mu_{2} |\ge {\Delta} \text{ versus } H_{1}: |\mu_{1}-\mu_{2}|<{\Delta},$$ where Œº 1 represents the pre-change mean, and Œº 2 represents the post-change mean. For continuous measurements with common variance, the most popular test statistic is the t statistic: $$ T=\frac{\bar Y_{2}-\bar Y_{1}}{S_{p}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}}, $$ (1) where \(S_{p}=\sqrt {\frac {n_{1}{S_{1}^{2}}+n_{2}{S_{2}^{2}}}{n_{1}+n_{2}-2}}\) is the pooled standard deviation, \(\bar Y_{k}\) and S k 2 are the sample mean and sample variance for assay results from process k , k = 1,2. If one assumes equal variance for the two groups, the 90% confidence intervals of the mean difference Œº 2 ‚àí Œº 1 is given by $$ (\bar Y_{2}-\bar Y_{1})\pm t_{0.95,n_{1}+n_{2}-2}S_{p}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}. $$ (2) With a type I error rate of 5%, statistical equivalency is achieved if the 90% confidence limits for the mean difference fall inside the equivalency region (‚àí Œî,Œî). This test is also called the two one-sided test (TOST) [ ]. For simplicity of exposition, a symmetric equivalence region (‚àíŒî,Œî) is used in the statistical derivation. In the actual application, one may consider an asymmetric region (Œî 1 , Œî 2 ).
The amount of data collected should ensure the equivalence test is adequately powered. When only limited data is available, e.g., the process yields are great enough during early development or the manufacturing cost for each process is so expensive such that only a small number of batches are available for the comparison, the TOST may be unable to declare equivalency even when process means are identical. The use of the TOST and its extension is frequently applied when assessing mean equivalence. However, the establishment of acceptance criteria is not always clearly understood.
Bayesian Method for Setting Acceptance Criteria for Process Comparability
The goal of the process comparability study is to show with high confidence that the CQA values from the processes are comparable. In other words, the null hypothesis of non-equivalence will be rejected with a small type 1 error. The setting of appropriate acceptance criteria Œî for process comparability assessments can be challenging but is key to ensuring analytical similarity of the products. They are a vital prerequisite to deciding the design and sample size of the comparability study.
Several statistical approaches have been proposed for the determination of acceptance criteria. One approach is based on the method or process variability of the historical data. The tolerance intervals or prediction intervals of the historical data are used to set the acceptance criteria [ ]. For example, de Fontenay [ ] proposed the acceptance criteria by ensuring less that 5% of the studies would pass the criteria if the mean difference is unacceptably high. Gsponer [ ] used the prediction intervals as the basis for equivalence acceptance criteria. Chatfield and Borman [ ] provided the risk-based acceptance criteria for analytical method equivalence assessment. They assumed that the analytical method variability, measured as the standard deviation (SD), was reliable and kept as a fixed value. The estimates of analytical method variability and process variation may be variable, especially when the process data are limited in early development stages.
The Bayesian method provides a natural way for combining prior information with study design when planning a comparability study. Bayesian statistics starts with a prior belief, which is updated with the new evidence to yield a posterior belief [ ]. The prior beliefs are expressed as prior distributions for the parameters. For process comparability, the prior information about process parameters, e.g., mean shift and precision, may be obtained from assay validation studies and previous small scale processes. The new evidence may come from the planned process comparability data, which is expressed as a likelihood function of the observed data . The posterior beliefs are expressed as the posterior distribution by combining the current data with prior information. When good prior information exists, the Bayesian approach may provide more informative decision. Given the limited data at pharmaceutical comparability study, the Bayesian method provides a promising way for utilizing prior information.
Data
To establish acceptance criteria for the comparability study, the manufacturer should utilize as much data as possible, including all assay results from historical lots representative of the pre-change process (process 1). The acceptance criteria may also be based on scientific knowledge and relevant development data. Let \(\mathcal {H}=\{z_{1}, \cdots , z_{m}\}\) denote the historical data from process 1. A sufficient number of historical lots are necessary to characterize the inherent variability of the old process. The pre-defined acceptance criteria Œî is derived using the historical data set \(\mathcal {H}\) .
Comparability would be better evaluated by direct, side-by-side comparison of results from both processes simultaneously. Let \(\boldsymbol {y}_{k}=\{y_{k1},...,y_{kn_{k}}\}\) be the newly collected assay results from Process k , k = 1,2. The TOST will be performed as described in the ‚Äú Equivalence Test for Process Comparability ‚Äù section. The 90% confidence interval of the mean difference based on y 1 and y 2 will be compared against the acceptance criteria Œî.
Note that { z 1 ,..., z m } and \(\{y_{11},...,y_{1n_{1}}\}\) both are two independent sets of representative results from Process 1 and follow the same distributions. Therefore, we assume that $$\begin{array}{@{}rcl@{}} z_{1},...,z_{m}, \; y_{11},...,y_{1n_{1}} &\sim& N\left( \mu_{1},{\sigma_{1}^{2}}\right), \\ y_{21},...,y_{2n_{2}}&\sim&N\left( \mu_{2},{\sigma_{2}^{2}}\right). \end{array} $$ Without additional information, we assume the old and new processes have the same variability œÉ Y 2 = œÉ 12 = œÉ 22.
Setting the Acceptance Criteria by Controlling the Patients‚Äô Risk
A release limit or range ( L , U ) is often applied to the CQAs in order to ensure the quality of the drug, thus protecting the patients‚Äô risk [ , ]. The acceptance criteria Œî may be established as the allowable shift from old process (process 1) to the new process (process 2) so that the probability of out-of-specification (OOS) at lot release is low.
The observed historical data from process 1 follow a normal distribution $$ z_{j}\sim N\left( \mu_{1},{\sigma_{Y}^{2}}\right), j=1,...,m. $$ (3) If the mean change between the two processes is Œ¥ , i.e., Œº 2 ‚àí Œº 1 = Œ¥ , then the distributions of process 1 and 2 data in the comparability study may follow: $$Y_{1}\sim N\left( \mu_{1},{\sigma_{Y}^{2}}\right) \text{ and } Y_{2}\sim N\left( \mu_{1}+\delta,{\sigma_{Y}^{2}}\right).$$ The Bayesian formulation may be used to derive the posterior distribution of attribute values from Process 2. Let ùúÉ = ( Œº 1 , œÉ Y 2) denote the unknown parameters in the model. The posterior distribution of Y 2 is a function of Œ¥ , which can be calculated as $$ f(Y_{2}|\delta,\mathcal{H})=\int f(Y_{2}|{\boldsymbol{\theta}},\delta)f({\boldsymbol{\theta}}|\mathcal{H})\mathrm{d}{\boldsymbol{\theta}}, $$ (4) where \(f({\boldsymbol {\theta }}|\mathcal {H})\propto L(z_{1},...,z_{m}|{\boldsymbol {\theta }})\pi ({\boldsymbol {\theta }})\) is the posterior distribution of ùúÉ , L ( z 1 ,.., z m | ùúÉ ) is the likelihood function for historical data \(\mathcal {H}\) and œÄ ( ùúÉ ) is the prior distribution for the parameter ùúÉ .
For simplicity, independent priors are used $$\mu_{1} \sim N\left( \xi_{\mu},\sigma_{\mu}^{2}\right) \text{ and } {\sigma_{Y}^{2}}\sim \text{Inverse Gamma}(a,b).$$ For weakly informative priors, one can set the hyperparameters Œæ Œº = 0, œÉ Œº 2 = 10000, a = b = 0.001.
The posterior predictive distribution of Y 2 can be derived using the Bayesian Markov chain Monte Carlo (MCMC) using WinBugs [ ] or OpenBUGS [ ]. The probability of OOS at lot release can be calculated based on the posterior predictive distribution \(f(Y_{2}|\delta ,\mathcal {H})\) : $$ \alpha_{\delta}=\text{Pr }(Y_{2}\not\in (L,U)|\delta, \mathcal{H})=1-{{\int}_{L}^{U}} f(Y_{2}|\delta,\mathcal{H})\mathrm{d}Y_{2}. $$ (5) The acceptance criteria Œî can be determined such that the OOS probability Œ± Œî is less than 0.05.
Power Analysis
The failure to reject the null hypothesis of process comparability may be due to two possible causes. The first one is because the true mean difference is indeed greater than the acceptance criteria Œî, which is regarded as the true failure. The other one is failing to reject the null hypothesis of non-equivalence even though the true difference between the two processes is less than Œî. The latter one reflects the manufacturer‚Äôs risk, which may be due to large process or assay variability and lack of power. The power of claiming equivalence test is a function of sample sizes and true difference Œ¥ .
The power of the TOST is calculated as the probability of the 90% confidence interval of the mean difference Œº 2 ‚àí Œº 1 being within the acceptance criteria (‚àíŒî,Œî). The usual power calculation for equivalence test TOST usually assumes that the SD value œÉ Y is known and fixed. In the process comparability study, however, the estimate of œÉ Y based on limited historical data from process 1 is usually highly variable. Alternatively, the power can be calculated as the posterior probability of the 90% confidence interval being within the acceptance region. Let \(\bar Y_{k}\) be the mean on the potential n k attribute values \((y_{k1},...,y_{kn_{k}})\) from Process k , k = 1,2. Conditional on the true mean different Œ¥ = Œº 2 ‚àí Œº 1 , the 90% confidence interval of the mean difference ( L Œ¥ , U Œ¥ ) is calculated as Eq. 2 . Let ŒΩ = n 1 + n 2 ‚àí 2 be the degrees of freedom of the t -statistic in Eq. 1 and let $$ T_{L}=\frac{\bar Y_{2}-\bar Y_{1}+{\Delta}}{S_{p}\sqrt{\frac 1 {n_{1}}+\frac 1 {n_{2}}}} \text{ and } T_{U}=\frac{\bar Y_{2}-\bar Y_{1}-{\Delta}}{S_{p}\sqrt{\frac 1 {n_{1}}+\frac 1 {n_{2}}}}. $$ (6) For given alternatives Œ¥ = Œº 2 ‚àí Œº 1 , œÉ Y , ŒΩ , the power of the TOST is $$\begin{array}{@{}rcl@{}} p(\delta,\sigma_{Y},\nu)&=&P\{(L_{\delta},U_{\delta})\subset (-{\Delta},{\Delta})|\delta,\sigma_{Y},\nu\}\\ &=&P(T_{L}\ge t_{0.95,\nu} \text{ and } T_{U}\le -t_{0.95,\nu}|\delta,\sigma_{Y},\nu). \end{array} $$ The vector ( T L , T U ) follows a bivariate noncentral t distribution with ŒΩ degrees of freedom and noncentrality parameters [ ] $$d_{L}=\frac{\delta+{\Delta}}{\sigma_{Y}\sqrt{\frac 1 {n_{1}}+\frac 1 {n_{2}}}} \text{ and } d_{U}=\frac{\delta-{\Delta}}{\sigma_{Y}\sqrt{\frac 1 {n_{1}}+\frac 1 {n_{2}}}}.$$ The power calculation of the TOST has been implemented in R functions power.TOST in the PowerTOST package or power.equivalence.md in the MBESS package.
Given the numbers of lots in the comparability study, n 1 and n 2 and the true mean difference Œ¥ , the posterior probability of claiming equivalence (power) can be calculated as $$\begin{array}{@{}rcl@{}} \beta(n_{1},n_{2},\delta)\!&=&Pr(\text{rejecting non-equivalence }|n_{1},n_{2},\delta)\\ &=&\int \!\text{Pr }\{(L_{\delta},U_{\delta})\!\subset\! (\!-{\Delta},{\Delta})\}|\delta,\sigma_{Y},\nu)f(\sigma_{Y}|\mathcal{H})\mathrm{d}\sigma_{Y}\\ \end{array} $$ (7) The posterior estimate of power Œ≤ can be estimated by monte-carlo integration based on the MCMC samples.
Sample Size Calculation
Without loss of generality, we assume that number of lots from the old and new processes n 1 = n 2 = n . The sample size n can be determined such as the power of the equivalence test Œ≤ ( n , Œ¥ ) ‚â• 0.90.
Prior Distributions and Parameter Constraints
Domain-specific scientific knowledge may be used to set the priors and impose certain constraints to the parameters. For example, percent purity should be a fraction close to 100%. It is reasonable to assume that the responses Y 1 , Y 2 from the two processes follow truncated normal distributions with truncation interval (80 % ,100 % ) in Eq. 3 . For relative potency, one can set the truncation interval (50 % ,150 % ) based on the system suitability range.
The prior distributions of the parameters, e.g., process and assay variability, can be constructed using historical data and expert opinions. For example, the intermediate precision (variance) of assay variability may come from analytical method validation studies [ , ] or from the manual of the instruments. The estimate of assay variability usually follows a chi-square distribution based on the analysis of variance (ANOVA) for the validation data.
Example
An experimental biological product needs to be manufactured by the final process for commercialization. Although the current manufacturing process for clinical trials and the new commercial production process are using the same basic process, there are a few minor changes in the downstream process and packaging to improve commercial readiness. An initial risk assessment was performed on the differences in a preliminary study and concluded that the overall risk of the minor changes are low. However, an analytical comparability exercise needs to be performed to ensure that the drug products manufactured by the two processes are comparable. A list of lot release tests and characterization tests were chosen based on the criticality to the drug quality.
Here, two quality attributes, the relative potency and the purity (%), are considered. The historical data from eight clinical lots are shown in Table 1 . The mean and standard deviation (SD) of % purity is 95.92 and 0.72, respectively. The one-sided lower specification limit for % purity is ‚â• 90% and the two-sided specification limits for relative potency is 75‚Äì125%. Let Œ¥ = Œº 2 ‚àí Œº 1 be the mean difference of the attributes from the two processes. Because an increase in purity is considered a process improvement, a one-sided acceptance criteria (Œî, ‚àû ) shall be used. For relative potency, the acceptance criteria is defined as an interval (Œî 1 , Œî 2 ). Table 1 Historical data of purity and relative potency for deriving the acceptance criteria Attribute Specification Lot 1 Lot 2 Lot 3 Lot 4 Lot 5 Lot 6 Lot 7 Lot 8 Mean SD Purity % ‚â• 90 % 95.7 95.6 95.2 95.5 95.3 96.5 96.3 97.3 95.92 0.72 Potency % 75‚Äì125% 95 110 105 105 106 109 110 106 105.8 4.83
Figure 1 shows the OOS probability as a function of Œ¥ (left figure) and the posterior density function of the new process data at acceptable region of the mean difference (right figure). When the value of Œ¥ decreases, the OOS probability gets higher. The acceptance region is determined as Œî ‚â•‚àí 4.3 as the corresponding OOS probability is 0.05. In the right figure, the attributes values from the old process are shown in circles. The left tail of the posterior density function corresponds to the 5% chance of being out of the lower specification of 90%.
Fig. 1
The OOS probability with respect to mean difference Œ¥ and the posterior density function of the new process data at acceptable change Œ¥ = ‚àí 4.3 for % purity
A similar figure for relative potency is shown in Fig. 2 . Because relative potency has a two-sided specification limit, the patients‚Äô risk increases as the mean process change Œ¥ shifts in both directions. The acceptance region is defined as the interval of allowable shift with OOS probability less than 0.05. For relative potency, the acceptance criteria (‚àí 19.9,8.7). The right figure in Fig. 2 shows that, if the mean potency change is ‚àí19.9, the posterior probability of failing the specifications of 75‚Äì125% is 5% for the new process. The sample R and OpenBUGS codes for generating the posterior samples and determining the acceptance criteria are shown in the Appendix . Fig. 2 The OOS probability with respect to mean difference Œ¥ and the posterior density function of the new process data at acceptable change Œ¥ = ‚àí 19.9 for relative potency
On the other hand, the manufacturer would still like to reduce the risk of unnecessary failure of the comparability study if the process difference Œ¥ = Œº 2 ‚àí Œº 1 is indeed within the acceptance region. Figure 3 shows the posterior estimate of the power of the equivalence test ( 7 ) when n 1 = n 2 = n . The top two lines are the powers for testing the equivalence of purity at Œ¥ = 0 and Œ¥ = ‚àí 2. We see that n = 4 lots from each process have more then 90% power to demonstrate the equivalence of purity. The bottom two lines are the powers for the equivalence test for relative potency. In contrast, the powers for testing equivalence of potency are rather low. When the difference of potency between the two processes is only Œ¥ = 2, the power is still below 80% at n = 10. Therefore, it is challenging to demonstrate the equivalence of relative potency. It is necessary to improve the performance including the precision and accuracy of the potency assay in order for a better power. Otherwise, the manufacture may take the risk of OOS to a value higher than 5%. Fig. 3 Power of the equivalence tests with respect to number of lots in each process
Discussion
In this article, a risk-based method is proposed for setting the acceptance criteria for process comparability studies. Both historical data and expert opinions can be incorporated as prior information under the Bayesian framework. The patients‚Äô risk and the manufacturer‚Äôs risk are explicitly quantified and controlled with the proposed method. Here, we focus on the mean equivalence of quantitative quality attributes. In addition to mean equivalence, it is of interest to compare the variance of the new process to that of the old process [ ]. Therefore, a joint comparison of both mean and variance would provide high confidence on the process comparability.
In addition to the quantitative tests like purity and potency, some quality attributes are classified into ordinal or nominal categories, e.g., the color and clarity of the drug product, existence of visible particles. So far, there is not available statistical methods to assess the comparability of qualitative attributes. Furthermore, the multiple quality attributes may be correlated as they are all measures of drug quality. Joint modeling of correlated quality attributes may improve the efficiency of the parameter estimates and produce more precise equivalence margins.
Assessment of process comparability is likely to benefit from stability testing for a drug substance and/or drug product [ ]. Accelerated stability testing studies offer a quick assessment for the comparability of stability before and after a process change. Burdick and Sidor [ ] proposed an equivalence acceptance criteria of accelerated stability data based on variability of degradation. A risk-based analysis may be used for the comparability of accelerated stability data as well. Furthermore, the proposed method may be applied to analytical method bridging studies [ ] and analytical similarity of biosimilar programs [ ] with limited reference products.
However, the Bayesian approach is also subject to several drawbacks. One of the main criticisms is the use of priors. First, it is difficult to construct a valid subjective prior from expert opinions and previous information [ ]. Second, the analysis results and the decision may be sensitive to the specification of priors. Therefore, the construction of informative priors is a delicate problem [ ]. A sensitivity analysis is useful to determine the impact of prior distribution on the analysis results. To enable an ‚Äúobjective‚Äù analysis, the acceptance criteria and the comparability protocol should be determined before conducting the comparability exercise. In addition, there is a lack of main stream available software that can run the Bayesian analysis in a validated environment, especially in the cGMPs.